{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ee172b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports & settings\n",
    "import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from scipy.stats import norm\n",
    "warnings.filterwarnings('ignore'); plt.rcParams['figure.figsize']=(6,4)\n",
    "import tensorflow as tf          #  ← add this near the other imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f69f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Load CSV\n",
    "df = pd.read_csv('option data variable.csv', parse_dates=['date','exdate'])\n",
    "df.dropna(inplace=True);  df['strike_price'] /= 1_000\n",
    "\n",
    "# 2) Feature engineering\n",
    "df['mid_price']   = (df['best_bid'] + df['best_offer'])/2\n",
    "df['days_to_exp'] = (df['exdate'] - df['date']).dt.days\n",
    "df['is_call']     = (df['cp_flag']=='C').astype(int)\n",
    "df['log_mny']     = np.log(df['underlying_price']/df['strike_price'])\n",
    "df['log_mny2']    = df['log_mny']**2          # curvature term\n",
    "\n",
    "X_COLS = ['underlying_price','strike_price','impl_volatility',\n",
    "          'risk_free_rate','days_to_exp','is_call','log_mny','log_mny2']\n",
    "Y_COLS = ['mid_price','delta','gamma','vega','theta']\n",
    "\n",
    "df = df.dropna(subset=X_COLS + Y_COLS).sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8debbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Chronological split (calls / puts → 98/1/1)\n",
    "def chrono_split(g, frac=.98):\n",
    "    n=len(g); i1=int(n*frac); i2=i1+(n-i1)//2\n",
    "    return g.iloc[:i1], g.iloc[i1:i2], g.iloc[i2:]\n",
    "call_tr,call_val,call_te = chrono_split(df[df.is_call==1])\n",
    "put_tr, put_val, put_te  = chrono_split(df[df.is_call==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5c28708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Scaling helpers\n",
    "X_scaler = StandardScaler().fit(pd.concat([call_tr,put_tr])[X_COLS])\n",
    "y_scal_call = StandardScaler().fit(call_tr[Y_COLS])\n",
    "y_scal_put  = StandardScaler().fit(put_tr[Y_COLS])\n",
    "\n",
    "def prep(g, xs, ys): return xs.transform(g[X_COLS]), ys.transform(g[Y_COLS])\n",
    "cXtr,cYtr = prep(call_tr,X_scaler,y_scal_call)\n",
    "cXva,cYva = prep(call_val,X_scaler,y_scal_call)\n",
    "cXte,cYte = prep(call_te ,X_scaler,y_scal_call)\n",
    "pXtr,pYtr = prep(put_tr ,X_scaler,y_scal_put )\n",
    "pXva,pYva = prep(put_val,X_scaler,y_scal_put )\n",
    "pXte,pYte = prep(put_te ,X_scaler,y_scal_put )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0896578",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Model factory (deeper + Γ head)\n",
    "def build_mlp(indim, base_units=512, base_layers=5, dropout=.25):\n",
    "    x = Input(shape=(indim,))\n",
    "    h = Dense(base_units)(x); h = LeakyReLU()(h)\n",
    "    for _ in range(base_layers-1):\n",
    "        h = Dense(base_units)(h); h=BatchNormalization()(h)\n",
    "        h = LeakyReLU()(h); h = Dropout(dropout)(h)\n",
    "    common = h\n",
    "    # shared outputs: price, Δ, ν, θ  (indices 0,1,3,4)\n",
    "    shared_out = Dense(4, name='shared')(common)\n",
    "    # separate tiny head for Γ (index 2)\n",
    "    gamma_out  = Dense(1, name='gamma_head')(common)\n",
    "    out = tf.keras.layers.Concatenate()([shared_out[:,:2], gamma_out,\n",
    "                                         shared_out[:,2:]])\n",
    "    model = tf.keras.Model(x, out)\n",
    "    # weighted loss (3× on gamma)\n",
    "    w = tf.constant([1.,1.,3.,1.,1.], dtype='float32')\n",
    "    def w_mse(y,t): return tf.reduce_mean(w*tf.square(t-y), axis=-1)\n",
    "    model.compile('adam', loss=w_mse)\n",
    "    return model\n",
    "\n",
    "# cosine LR schedule\n",
    "def cos_decay(epoch, lr, total=50): return 1e-3 * 0.5*(1+np.cos(np.pi*epoch/total))\n",
    "sched = LearningRateScheduler(cos_decay, verbose=0)\n",
    "cbs = [EarlyStopping(patience=12,restore_best_weights=True),\n",
    "       ReduceLROnPlateau(factor=.5,patience=6), sched]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29938bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2121/2121 [==============================] - 37s 15ms/step - loss: 0.3094 - val_loss: 0.2427 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.1636 - val_loss: 0.3437 - lr: 9.9901e-04\n",
      "Epoch 3/50\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.1426 - val_loss: 0.2116 - lr: 9.9606e-04\n",
      "Epoch 4/50\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.1313 - val_loss: 0.1936 - lr: 9.9114e-04\n",
      "Epoch 5/50\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.1217 - val_loss: 0.1219 - lr: 9.8429e-04\n",
      "Epoch 6/50\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.1154 - val_loss: 0.1856 - lr: 9.7553e-04\n",
      "Epoch 7/50\n",
      "2121/2121 [==============================] - 29s 13ms/step - loss: 0.1100 - val_loss: 0.1487 - lr: 9.6489e-04\n",
      "Epoch 8/50\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.1066 - val_loss: 0.1888 - lr: 9.5241e-04\n",
      "Epoch 9/50\n",
      "2121/2121 [==============================] - 32s 15ms/step - loss: 0.1014 - val_loss: 0.1232 - lr: 9.3815e-04\n",
      "Epoch 10/50\n",
      "2121/2121 [==============================] - 34s 16ms/step - loss: 0.1007 - val_loss: 0.1745 - lr: 9.2216e-04\n",
      "Epoch 11/50\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.0962 - val_loss: 1.1247 - lr: 4.5225e-04\n",
      "Epoch 12/50\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.0928 - val_loss: 0.2497 - lr: 8.8526e-04\n",
      "Epoch 13/50\n",
      "2121/2121 [==============================] - 29s 14ms/step - loss: 0.0916 - val_loss: 0.1786 - lr: 8.6448e-04\n",
      "Epoch 14/50\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.0881 - val_loss: 0.4075 - lr: 8.4227e-04\n",
      "Epoch 15/50\n",
      "2121/2121 [==============================] - 33s 15ms/step - loss: 0.0878 - val_loss: 0.2798 - lr: 8.1871e-04\n",
      "Epoch 16/50\n",
      "2121/2121 [==============================] - 33s 15ms/step - loss: 0.0848 - val_loss: 0.0897 - lr: 7.9389e-04\n",
      "Epoch 17/50\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.0836 - val_loss: 0.1722 - lr: 7.6791e-04\n",
      "Epoch 18/50\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.0812 - val_loss: 0.2466 - lr: 7.4088e-04\n",
      "Epoch 19/50\n",
      "2121/2121 [==============================] - 31s 14ms/step - loss: 0.0794 - val_loss: 0.1583 - lr: 7.1289e-04\n",
      "Epoch 20/50\n",
      "2121/2121 [==============================] - 33s 16ms/step - loss: 0.0780 - val_loss: 0.1042 - lr: 6.8406e-04\n",
      "Epoch 21/50\n",
      "2121/2121 [==============================] - 31s 15ms/step - loss: 0.0773 - val_loss: 0.1366 - lr: 6.5451e-04\n",
      "Epoch 22/50\n",
      "2121/2121 [==============================] - 113s 53ms/step - loss: 0.0770 - val_loss: 0.5715 - lr: 3.1217e-04\n",
      "Epoch 23/50\n",
      "2121/2121 [==============================] - 40s 19ms/step - loss: 0.0743 - val_loss: 0.2738 - lr: 5.9369e-04\n",
      "Epoch 24/50\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.0729 - val_loss: 0.0846 - lr: 5.6267e-04\n",
      "Epoch 25/50\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.0707 - val_loss: 0.1646 - lr: 5.3140e-04\n",
      "Epoch 26/50\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.0686 - val_loss: 0.0962 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.0674 - val_loss: 0.0886 - lr: 4.6860e-04\n",
      "Epoch 28/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0663 - val_loss: 0.0626 - lr: 4.3733e-04\n",
      "Epoch 29/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0649 - val_loss: 0.1053 - lr: 4.0631e-04\n",
      "Epoch 30/50\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.0633 - val_loss: 0.0744 - lr: 3.7566e-04\n",
      "Epoch 31/50\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.0617 - val_loss: 0.1111 - lr: 3.4549e-04\n",
      "Epoch 32/50\n",
      "2121/2121 [==============================] - 30s 14ms/step - loss: 0.0608 - val_loss: 0.1073 - lr: 3.1594e-04\n",
      "Epoch 33/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0588 - val_loss: 0.0521 - lr: 2.8711e-04\n",
      "Epoch 34/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0570 - val_loss: 0.0785 - lr: 2.5912e-04\n",
      "Epoch 35/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0564 - val_loss: 0.0646 - lr: 2.3209e-04\n",
      "Epoch 36/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0547 - val_loss: 0.0596 - lr: 2.0611e-04\n",
      "Epoch 37/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0532 - val_loss: 0.0640 - lr: 1.8129e-04\n",
      "Epoch 38/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0517 - val_loss: 0.0718 - lr: 1.5773e-04\n",
      "Epoch 39/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0508 - val_loss: 0.0751 - lr: 6.7758e-05\n",
      "Epoch 40/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0501 - val_loss: 0.0433 - lr: 1.1474e-04\n",
      "Epoch 41/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0489 - val_loss: 0.0539 - lr: 9.5492e-05\n",
      "Epoch 42/50\n",
      "2121/2121 [==============================] - 27s 13ms/step - loss: 0.0477 - val_loss: 0.0829 - lr: 7.7836e-05\n",
      "Epoch 43/50\n",
      "2121/2121 [==============================] - 28s 13ms/step - loss: 0.0468 - val_loss: 0.0488 - lr: 6.1847e-05\n",
      "Epoch 44/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0460 - val_loss: 0.0594 - lr: 4.7586e-05\n",
      "Epoch 45/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0457 - val_loss: 0.0436 - lr: 3.5112e-05\n",
      "Epoch 46/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0445 - val_loss: 0.0461 - lr: 1.2236e-05\n",
      "Epoch 47/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0441 - val_loss: 0.0470 - lr: 1.5708e-05\n",
      "Epoch 48/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0442 - val_loss: 0.0449 - lr: 8.8564e-06\n",
      "Epoch 49/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0437 - val_loss: 0.0453 - lr: 3.9426e-06\n",
      "Epoch 50/50\n",
      "2121/2121 [==============================] - 26s 12ms/step - loss: 0.0436 - val_loss: 0.0448 - lr: 9.8664e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e38c7cdc70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Train CALL model\n",
    "call_model = build_mlp(cXtr.shape[1]); call_model.fit(\n",
    "    cXtr,cYtr, validation_data=(cXva,cYva),\n",
    "    epochs=50, batch_size=4096, callbacks=cbs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3632394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2014/2014 [==============================] - 27s 12ms/step - loss: 0.3325 - val_loss: 0.2442 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1857 - val_loss: 0.2479 - lr: 9.9901e-04\n",
      "Epoch 3/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1616 - val_loss: 0.1909 - lr: 9.9606e-04\n",
      "Epoch 4/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1476 - val_loss: 0.3475 - lr: 9.9114e-04\n",
      "Epoch 5/50\n",
      "2014/2014 [==============================] - 23s 12ms/step - loss: 0.1381 - val_loss: 0.2225 - lr: 9.8429e-04\n",
      "Epoch 6/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1357 - val_loss: 0.1216 - lr: 9.7553e-04\n",
      "Epoch 7/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1265 - val_loss: 0.2825 - lr: 9.6489e-04\n",
      "Epoch 8/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1229 - val_loss: 0.1920 - lr: 9.5241e-04\n",
      "Epoch 9/50\n",
      "2014/2014 [==============================] - 23s 12ms/step - loss: 0.1199 - val_loss: 0.1512 - lr: 9.3815e-04\n",
      "Epoch 10/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1165 - val_loss: 0.3771 - lr: 9.2216e-04\n",
      "Epoch 11/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1143 - val_loss: 0.1083 - lr: 9.0451e-04\n",
      "Epoch 12/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1078 - val_loss: 0.1680 - lr: 8.8526e-04\n",
      "Epoch 13/50\n",
      "2014/2014 [==============================] - 23s 12ms/step - loss: 0.1067 - val_loss: 0.2286 - lr: 8.6448e-04\n",
      "Epoch 14/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1032 - val_loss: 0.1416 - lr: 8.4227e-04\n",
      "Epoch 15/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.1009 - val_loss: 0.2754 - lr: 8.1871e-04\n",
      "Epoch 16/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0990 - val_loss: 0.1141 - lr: 7.9389e-04\n",
      "Epoch 17/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0966 - val_loss: 0.2754 - lr: 3.8396e-04\n",
      "Epoch 18/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0961 - val_loss: 0.2693 - lr: 7.4088e-04\n",
      "Epoch 19/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0933 - val_loss: 0.0859 - lr: 7.1289e-04\n",
      "Epoch 20/50\n",
      "2014/2014 [==============================] - 23s 12ms/step - loss: 0.0916 - val_loss: 0.0907 - lr: 6.8406e-04\n",
      "Epoch 21/50\n",
      "2014/2014 [==============================] - 23s 12ms/step - loss: 0.0890 - val_loss: 0.1482 - lr: 6.5451e-04\n",
      "Epoch 22/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0877 - val_loss: 0.0943 - lr: 6.2434e-04\n",
      "Epoch 23/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0858 - val_loss: 0.1475 - lr: 5.9369e-04\n",
      "Epoch 24/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0847 - val_loss: 0.0580 - lr: 5.6267e-04\n",
      "Epoch 25/50\n",
      "2014/2014 [==============================] - 25s 12ms/step - loss: 0.0829 - val_loss: 0.1016 - lr: 5.3140e-04\n",
      "Epoch 26/50\n",
      "2014/2014 [==============================] - 29s 15ms/step - loss: 0.0803 - val_loss: 0.1387 - lr: 5.0000e-04\n",
      "Epoch 27/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0811 - val_loss: 0.1863 - lr: 4.6860e-04\n",
      "Epoch 28/50\n",
      "2014/2014 [==============================] - 25s 12ms/step - loss: 0.0781 - val_loss: 0.0804 - lr: 4.3733e-04\n",
      "Epoch 29/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0777 - val_loss: 0.0611 - lr: 4.0631e-04\n",
      "Epoch 30/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0751 - val_loss: 0.1293 - lr: 1.8783e-04\n",
      "Epoch 31/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0741 - val_loss: 0.1171 - lr: 3.4549e-04\n",
      "Epoch 32/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0700 - val_loss: 0.1096 - lr: 3.1594e-04\n",
      "Epoch 33/50\n",
      "2014/2014 [==============================] - 24s 12ms/step - loss: 0.0697 - val_loss: 0.0657 - lr: 2.8711e-04\n",
      "Epoch 34/50\n",
      "2014/2014 [==============================] - 25s 12ms/step - loss: 0.0679 - val_loss: 0.0392 - lr: 2.5912e-04\n",
      "Epoch 35/50\n",
      "2014/2014 [==============================] - 27s 13ms/step - loss: 0.0668 - val_loss: 0.0555 - lr: 2.3209e-04\n",
      "Epoch 36/50\n",
      "2014/2014 [==============================] - 28s 14ms/step - loss: 0.0646 - val_loss: 0.0855 - lr: 2.0611e-04\n",
      "Epoch 37/50\n",
      "2014/2014 [==============================] - 27s 14ms/step - loss: 0.0632 - val_loss: 0.0441 - lr: 1.8129e-04\n",
      "Epoch 38/50\n",
      "2014/2014 [==============================] - 26s 13ms/step - loss: 0.0618 - val_loss: 0.0437 - lr: 1.5773e-04\n",
      "Epoch 39/50\n",
      "2014/2014 [==============================] - 29s 14ms/step - loss: 0.0599 - val_loss: 0.0540 - lr: 1.3552e-04\n",
      "Epoch 40/50\n",
      "2014/2014 [==============================] - 25s 13ms/step - loss: 0.0591 - val_loss: 0.0368 - lr: 1.1474e-04\n",
      "Epoch 41/50\n",
      "2014/2014 [==============================] - 27s 13ms/step - loss: 0.0578 - val_loss: 0.0384 - lr: 9.5492e-05\n",
      "Epoch 42/50\n",
      "2014/2014 [==============================] - 30s 15ms/step - loss: 0.0565 - val_loss: 0.0388 - lr: 7.7836e-05\n",
      "Epoch 43/50\n",
      "2014/2014 [==============================] - 54s 27ms/step - loss: 0.0551 - val_loss: 0.0313 - lr: 6.1847e-05\n",
      "Epoch 44/50\n",
      "2014/2014 [==============================] - 105s 50ms/step - loss: 0.0541 - val_loss: 0.0318 - lr: 4.7586e-05\n",
      "Epoch 45/50\n",
      "2014/2014 [==============================] - 40s 20ms/step - loss: 0.0530 - val_loss: 0.0383 - lr: 3.5112e-05\n",
      "Epoch 46/50\n",
      "2014/2014 [==============================] - 33s 17ms/step - loss: 0.0526 - val_loss: 0.0317 - lr: 2.4472e-05\n",
      "Epoch 47/50\n",
      "2014/2014 [==============================] - 33s 16ms/step - loss: 0.0520 - val_loss: 0.0299 - lr: 1.5708e-05\n",
      "Epoch 48/50\n",
      "2014/2014 [==============================] - 33s 16ms/step - loss: 0.0523 - val_loss: 0.0327 - lr: 8.8564e-06\n",
      "Epoch 49/50\n",
      "2014/2014 [==============================] - 33s 17ms/step - loss: 0.0509 - val_loss: 0.0306 - lr: 3.9426e-06\n",
      "Epoch 50/50\n",
      "2014/2014 [==============================] - 33s 17ms/step - loss: 0.0512 - val_loss: 0.0302 - lr: 9.8664e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e3b6d12940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Train PUT model\n",
    "put_model = build_mlp(pXtr.shape[1]);  put_model.fit(\n",
    "    pXtr,pYtr, validation_data=(pXva,pYva),\n",
    "    epochs=50, batch_size=4096, callbacks=cbs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a7452e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2770/2770 [==============================] - 9s 3ms/step\n",
      "2631/2631 [==============================] - 9s 3ms/step\n",
      "\n",
      "CALL MODEL\n",
      "mid_price   MSE=3.210906  MAE=1.115193  R²=0.9989\n",
      "delta       MSE=0.000680  MAE=0.016332  R²=0.9953\n",
      "gamma       MSE=0.000425  MAE=0.003176  R²=0.9433\n",
      "vega        MSE=6.931519  MAE=1.517139  R²=0.9963\n",
      "theta       MSE=76.969024  MAE=2.793950  R²=0.9587\n",
      "\n",
      "PUT MODEL\n",
      "mid_price   MSE=0.801911  MAE=0.557420  R²=0.9990\n",
      "delta       MSE=0.000848  MAE=0.017602  R²=0.9933\n",
      "gamma       MSE=0.000281  MAE=0.004079  R²=0.9705\n",
      "vega        MSE=10.755052  MAE=1.588852  R²=0.9931\n",
      "theta       MSE=40.769907  MAE=2.354789  R²=0.9496\n"
     ]
    }
   ],
   "source": [
    "# 8) Inverse-scale predictions\n",
    "c_pred = y_scal_call.inverse_transform(call_model.predict(cXte))\n",
    "c_true = y_scal_call.inverse_transform(cYte)\n",
    "p_pred = y_scal_put .inverse_transform( put_model.predict(pXte))\n",
    "p_true = y_scal_put .inverse_transform(pYte)\n",
    "\n",
    "# 9) Metrics\n",
    "def report(t,p,tag):\n",
    "    print(f'\\n{tag} MODEL'); \n",
    "    for i,g in enumerate(Y_COLS):\n",
    "        print(f'{g:10s}  MSE={mean_squared_error(t[:,i],p[:,i]):.6f}  '\n",
    "              f'MAE={mean_absolute_error(t[:,i],p[:,i]):.6f}  '\n",
    "              f'R²={r2_score(t[:,i],p[:,i]):.4f}')\n",
    "report(c_true,c_pred,'CALL'); report(p_true,p_pred,'PUT')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
