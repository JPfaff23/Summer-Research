{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91aafc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      "WRDS recommends setting up a .pgpass file.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ebe8a2da7041b7bc8cc3bc2f713daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Year 2021:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3572eedc534d568ea6c9c300632338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Year 2022:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaafd9eb25ea47b9b5ecb2ee9637585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Year 2023:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Parquet size: 9.47 GB\n"
     ]
    }
   ],
   "source": [
    "import wrds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas_datareader.data as web\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# ─── CONFIGURATION ──────────────────────────────────────────────\n",
    "YEARS        = range(2021, 2024)      # years to fetch\n",
    "NUM_SECIDS   = 2000                   # number of SECIDs to sample\n",
    "CHUNK_SIZE   = 200                    # SECIDs per chunk\n",
    "COLUMNS_OP   = [\n",
    "    'date','secid','strike_price','best_bid','best_offer',\n",
    "    'impl_volatility','delta','gamma','vega','theta','exdate','cp_flag'\n",
    "]\n",
    "OUTFILE      = 'option_data_2021-2023_2000secids.parquet'\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "\n",
    "def chunk_list(lst, size):\n",
    "    for i in range(0, len(lst), size):\n",
    "        yield lst[i:i + size]\n",
    "\n",
    "# 1) Sample SECIDs\n",
    "db = wrds.Connection()\n",
    "secid_df = db.raw_sql(\"SELECT DISTINCT secid FROM optionm.opprcd2023\")\n",
    "all_secids = secid_df['secid'].tolist()\n",
    "np.random.seed(42)\n",
    "sampled = np.random.choice(all_secids, NUM_SECIDS, replace=False)\n",
    "db.close()\n",
    "\n",
    "# 2) Pre-load risk-free rates\n",
    "treasury = (\n",
    "    web.DataReader('DGS3MO', 'fred', datetime(2021,1,1), datetime(2023,12,31))\n",
    "      .rename(columns={'DGS3MO':'risk_free_rate'})\n",
    "      .reset_index()\n",
    ")\n",
    "treasury['risk_free_rate'] /= 100\n",
    "treasury['date'] = pd.to_datetime(treasury['DATE'])\n",
    "treasury = treasury[['date','risk_free_rate']]\n",
    "\n",
    "# 3) Stream fetch & write to Parquet (options + underlying)\n",
    "writer = None\n",
    "db     = wrds.Connection()\n",
    "\n",
    "for year in YEARS:\n",
    "    for chunk in tqdm(list(chunk_list(sampled, CHUNK_SIZE)), desc=f\"Year {year}\"):\n",
    "        secids_sql = ','.join(f\"'{s}'\" for s in chunk)\n",
    "\n",
    "        # Fetch option data\n",
    "        sql_op = f\"\"\"\n",
    "            SELECT {', '.join(COLUMNS_OP)}\n",
    "            FROM optionm.opprcd{year}\n",
    "            WHERE secid IN ({secids_sql})\n",
    "        \"\"\"\n",
    "        df_op = db.raw_sql(sql_op)\n",
    "        if df_op.empty:\n",
    "            continue\n",
    "        df_op.dropna(inplace=True)\n",
    "        df_op['date']   = pd.to_datetime(df_op['date'])\n",
    "        df_op['exdate'] = pd.to_datetime(df_op['exdate'])\n",
    "        df_op['mid_price'] = (df_op['best_bid'] + df_op['best_offer']) / 2\n",
    "        df_op = df_op.merge(treasury, on='date', how='left').ffill()\n",
    "\n",
    "        # Fetch underlying price data\n",
    "        sql_und = f\"\"\"\n",
    "            SELECT secid, date, low, high, close, open\n",
    "            FROM optionm.secprd{year}\n",
    "            WHERE secid IN ({secids_sql})\n",
    "        \"\"\"\n",
    "        df_und = db.raw_sql(sql_und)\n",
    "        if df_und.empty:\n",
    "            continue\n",
    "        df_und['date'] = pd.to_datetime(df_und['date'])\n",
    "        df_und['underlying_price'] = df_und[['low','high','close','open']].mean(axis=1)\n",
    "        df_und = df_und[['secid','date','underlying_price']]\n",
    "\n",
    "        # Merge options + underlying\n",
    "        df = pd.merge(df_op, df_und, on=['secid','date'], how='inner')\n",
    "        df.dropna(subset=['underlying_price'], inplace=True)\n",
    "\n",
    "        # Write to Parquet\n",
    "        table = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(OUTFILE, table.schema)\n",
    "        writer.write_table(table)\n",
    "\n",
    "db.close()\n",
    "writer.close()\n",
    "\n",
    "# 4) Report file size\n",
    "size_bytes = os.path.getsize(OUTFILE)\n",
    "for unit in ['B','KB','MB','GB']:\n",
    "    if size_bytes < 1024:\n",
    "        break\n",
    "    size_bytes /= 1024\n",
    "print(f\"Final Parquet size: {size_bytes:.2f} {unit}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
