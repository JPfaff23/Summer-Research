{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6dd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports (add tensorflow)\n",
    "import warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf                                   # ← new\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from scipy.stats import norm; warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d754859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Load\n",
    "df = pd.read_parquet('option_data_2021-2023_2000secids.parquet')\n",
    "df['date']   = pd.to_datetime(df['date'])\n",
    "df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "df.dropna(inplace=True); df['strike_price'] /= 1_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0776ff32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m X_COLS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munderlying_price\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrike_price\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpl_volatility\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrisk_free_rate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_to_exp\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_call\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_mny\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_mny2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m Y_COLS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmid_price\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelta\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvega\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_COLS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY_COLS\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\frame.py:7219\u001b[0m, in \u001b[0;36mDataFrame.sort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 7219\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   7221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n\u001b[0;32m   7224\u001b[0m     new_data\u001b[38;5;241m.\u001b[39mset_axis(\n\u001b[0;32m   7225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis), default_index(\u001b[38;5;28mlen\u001b[39m(indexer))\n\u001b[0;32m   7226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    689\u001b[0m             indexer,\n\u001b[0;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    693\u001b[0m             ),\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Features (add log-moneyness)\n",
    "df['mid_price']   = (df['best_bid'] + df['best_offer'])/2\n",
    "df['days_to_exp'] = (df['exdate'] - df['date']).dt.days\n",
    "df['is_call']     = (df['cp_flag']=='C').astype(int)\n",
    "df['log_mny']     = np.log(df['underlying_price']/df['strike_price'])\n",
    "df['log_mny2']    = df['log_mny']**2\n",
    "\n",
    "X_COLS = ['underlying_price','strike_price','impl_volatility',\n",
    "          'risk_free_rate','days_to_exp','is_call','log_mny','log_mny2']\n",
    "Y_COLS = ['mid_price','delta','gamma','vega','theta']\n",
    "\n",
    "df = df.dropna(subset=X_COLS + Y_COLS).sort_values('date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29728c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>secid</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>impl_volatility</th>\n",
       "      <th>delta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>vega</th>\n",
       "      <th>theta</th>\n",
       "      <th>exdate</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>risk_free_rate</th>\n",
       "      <th>underlying_price</th>\n",
       "      <th>days_to_exp</th>\n",
       "      <th>is_call</th>\n",
       "      <th>log_mny</th>\n",
       "      <th>log_mny2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>100958.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.40</td>\n",
       "      <td>67.80</td>\n",
       "      <td>2.448840</td>\n",
       "      <td>0.981652</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.778052</td>\n",
       "      <td>-87.206940</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>C</td>\n",
       "      <td>65.600</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>168.6525</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.522670</td>\n",
       "      <td>0.273184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>109820.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>75.99</td>\n",
       "      <td>76.44</td>\n",
       "      <td>0.813343</td>\n",
       "      <td>-0.999039</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.088453</td>\n",
       "      <td>-6.412182</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>P</td>\n",
       "      <td>76.215</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>371.0925</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.181623</td>\n",
       "      <td>0.032987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>109820.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>80.99</td>\n",
       "      <td>81.44</td>\n",
       "      <td>0.857416</td>\n",
       "      <td>-0.999084</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.084587</td>\n",
       "      <td>-6.471672</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>P</td>\n",
       "      <td>81.215</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>371.0925</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.192796</td>\n",
       "      <td>0.037170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>109820.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>90.99</td>\n",
       "      <td>91.44</td>\n",
       "      <td>0.943541</td>\n",
       "      <td>-0.999160</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.078019</td>\n",
       "      <td>-6.581821</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>P</td>\n",
       "      <td>91.215</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>371.0925</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.214775</td>\n",
       "      <td>0.046128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>109820.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>100.99</td>\n",
       "      <td>101.44</td>\n",
       "      <td>1.027151</td>\n",
       "      <td>-0.999221</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.072966</td>\n",
       "      <td>-6.682199</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>P</td>\n",
       "      <td>101.215</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>371.0925</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.236281</td>\n",
       "      <td>0.055829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     secid  strike_price  best_bid  best_offer  impl_volatility  \\\n",
       "0 2021-01-04  100958.0         100.0     63.40       67.80         2.448840   \n",
       "1 2021-01-04  109820.0         445.0     75.99       76.44         0.813343   \n",
       "2 2021-01-04  109820.0         450.0     80.99       81.44         0.857416   \n",
       "3 2021-01-04  109820.0         460.0     90.99       91.44         0.943541   \n",
       "4 2021-01-04  109820.0         470.0    100.99      101.44         1.027151   \n",
       "\n",
       "      delta     gamma      vega      theta     exdate cp_flag  mid_price  \\\n",
       "0  0.981652  0.001063  0.778052 -87.206940 2021-01-08       C     65.600   \n",
       "1 -0.999039  0.000152  0.088453  -6.412182 2021-01-06       P     76.215   \n",
       "2 -0.999084  0.000138  0.084587  -6.471672 2021-01-06       P     81.215   \n",
       "3 -0.999160  0.000116  0.078019  -6.581821 2021-01-06       P     91.215   \n",
       "4 -0.999221  0.000100  0.072966  -6.682199 2021-01-06       P    101.215   \n",
       "\n",
       "   risk_free_rate  underlying_price  days_to_exp  is_call   log_mny  log_mny2  \n",
       "0          0.0009          168.6525            4        1  0.522670  0.273184  \n",
       "1          0.0009          371.0925            2        0 -0.181623  0.032987  \n",
       "2          0.0009          371.0925            2        0 -0.192796  0.037170  \n",
       "3          0.0009          371.0925            2        0 -0.214775  0.046128  \n",
       "4          0.0009          371.0925            2        0 -0.236281  0.055829  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Chronological split (unchanged) ...\n",
    "df_call, df_put = df[df.is_call==1], df[df.is_call==0]\n",
    "split = lambda g: (g.iloc[:int(.98*len(g))],\n",
    "                   g.iloc[int(.98*len(g)):int(.985*len(g))],\n",
    "                   g.iloc[int(.985*len(g)):])\n",
    "\n",
    "call_tr, call_val, call_te = split(df_call)\n",
    "put_tr , put_val , put_te  = split(df_put)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Scaling (unchanged) ...\n",
    "x_scal = StandardScaler().fit(pd.concat([call_tr,put_tr])[X_COLS])\n",
    "ysc_c  = StandardScaler().fit(call_tr[Y_COLS])\n",
    "ysc_p  = StandardScaler().fit(put_tr[Y_COLS])\n",
    "\n",
    "prep = lambda g,xs,ys: (xs.transform(g[X_COLS]), ys.transform(g[Y_COLS]))\n",
    "cXtr,cYtr = prep(call_tr,x_scal,ysc_c); cXva,cYva = prep(call_val,x_scal,ysc_c); cXte,cYte = prep(call_te,x_scal,ysc_c)\n",
    "pXtr,pYtr = prep(put_tr ,x_scal,ysc_p); pXva,pYva = prep(put_val ,x_scal,ysc_p); pXte,pYte = prep(put_te ,x_scal,ysc_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) MLP factory (extra layer + θ-weight in loss)\n",
    "def build_mlp(indim, hidden=512, layers=6, dropout=.3, theta_w=2.0):\n",
    "    x = Input(shape=(indim,)); h = Dense(hidden)(x); h=LeakyReLU()(h)\n",
    "    for _ in range(layers-1):\n",
    "        h=Dense(hidden)(h); h=BatchNormalization()(h); h=LeakyReLU()(h); h=Dropout(dropout)(h)\n",
    "    out = Dense(len(Y_COLS))(h)\n",
    "    w = tf.constant([1.,1.,1.,1.,theta_w], dtype='float32')\n",
    "    loss = lambda y_t,y_p: tf.reduce_mean(w * tf.square(y_t - y_p), axis=-1)\n",
    "    m = tf.keras.Model(x,out); m.compile('adam', loss=loss); return m\n",
    "\n",
    "CB = [EarlyStopping(patience=15,restore_best_weights=True),\n",
    "      ReduceLROnPlateau(factor=.5,patience=7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a9c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "7871/7871 [==============================] - 106s 13ms/step - loss: 0.1769 - val_loss: 0.2283 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "7871/7871 [==============================] - 101s 13ms/step - loss: 0.1167 - val_loss: 0.2119 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "7871/7871 [==============================] - 103s 13ms/step - loss: 0.1029 - val_loss: 0.1526 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "7871/7871 [==============================] - 103s 13ms/step - loss: 0.0959 - val_loss: 0.2143 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "7871/7871 [==============================] - 102s 13ms/step - loss: 0.0902 - val_loss: 0.1778 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "7871/7871 [==============================] - 102s 13ms/step - loss: 0.0873 - val_loss: 0.1332 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "7871/7871 [==============================] - 106s 13ms/step - loss: 0.0838 - val_loss: 0.1063 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "7871/7871 [==============================] - 103s 13ms/step - loss: 0.0813 - val_loss: 0.2242 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "7871/7871 [==============================] - 104s 13ms/step - loss: 0.0794 - val_loss: 0.1605 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "7871/7871 [==============================] - 102s 13ms/step - loss: 0.0774 - val_loss: 0.1089 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "7871/7871 [==============================] - 101s 13ms/step - loss: 0.0767 - val_loss: 0.1076 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "7871/7871 [==============================] - 104s 13ms/step - loss: 0.0749 - val_loss: 0.1327 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "7871/7871 [==============================] - 102s 13ms/step - loss: 0.0728 - val_loss: 0.1278 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "7871/7871 [==============================] - 100s 13ms/step - loss: 0.0726 - val_loss: 0.1009 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "7871/7871 [==============================] - 100s 13ms/step - loss: 0.0714 - val_loss: 0.0882 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "7871/7871 [==============================] - 101s 13ms/step - loss: 0.0704 - val_loss: 0.1145 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "7871/7871 [==============================] - 101s 13ms/step - loss: 0.0697 - val_loss: 0.1009 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "7871/7871 [==============================] - 103s 13ms/step - loss: 0.0685 - val_loss: 0.0972 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "7871/7871 [==============================] - 105s 13ms/step - loss: 0.0676 - val_loss: 0.1350 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "7871/7871 [==============================] - 102s 13ms/step - loss: 0.0669 - val_loss: 0.1009 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "7871/7871 [==============================] - 105s 13ms/step - loss: 0.0664 - val_loss: 0.1475 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "7871/7871 [==============================] - 95s 12ms/step - loss: 0.0660 - val_loss: 0.0773 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "7871/7871 [==============================] - 96s 12ms/step - loss: 0.0651 - val_loss: 0.1050 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0649 - val_loss: 0.0852 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0647 - val_loss: 0.1071 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0637 - val_loss: 0.0989 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0637 - val_loss: 0.0838 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0628 - val_loss: 0.1204 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0620 - val_loss: 0.0695 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0621 - val_loss: 0.0946 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "7871/7871 [==============================] - 96s 12ms/step - loss: 0.0614 - val_loss: 0.2284 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "7871/7871 [==============================] - 96s 12ms/step - loss: 0.0616 - val_loss: 0.1023 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0609 - val_loss: 0.0954 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0603 - val_loss: 0.0762 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0598 - val_loss: 0.0865 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0598 - val_loss: 0.0689 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0596 - val_loss: 0.0705 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0599 - val_loss: 0.1361 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0590 - val_loss: 0.0769 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "7871/7871 [==============================] - 97s 12ms/step - loss: 0.0586 - val_loss: 0.0788 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0586 - val_loss: 0.0947 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0582 - val_loss: 0.0803 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0579 - val_loss: 0.1227 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0507 - val_loss: 0.0643 - lr: 5.0000e-04\n",
      "Epoch 45/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0494 - val_loss: 0.0641 - lr: 5.0000e-04\n",
      "Epoch 46/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0493 - val_loss: 0.0583 - lr: 5.0000e-04\n",
      "Epoch 47/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0493 - val_loss: 0.0589 - lr: 5.0000e-04\n",
      "Epoch 48/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0490 - val_loss: 0.0629 - lr: 5.0000e-04\n",
      "Epoch 49/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0488 - val_loss: 0.0532 - lr: 5.0000e-04\n",
      "Epoch 50/60\n",
      "7871/7871 [==============================] - 98s 13ms/step - loss: 0.0483 - val_loss: 0.0595 - lr: 5.0000e-04\n",
      "Epoch 51/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0483 - val_loss: 0.0608 - lr: 5.0000e-04\n",
      "Epoch 52/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0484 - val_loss: 0.0519 - lr: 5.0000e-04\n",
      "Epoch 53/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0479 - val_loss: 0.0545 - lr: 5.0000e-04\n",
      "Epoch 54/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0480 - val_loss: 0.0527 - lr: 5.0000e-04\n",
      "Epoch 55/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0479 - val_loss: 0.0739 - lr: 5.0000e-04\n",
      "Epoch 56/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0483 - val_loss: 0.0595 - lr: 5.0000e-04\n",
      "Epoch 57/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0475 - val_loss: 0.0475 - lr: 5.0000e-04\n",
      "Epoch 58/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0475 - val_loss: 0.0638 - lr: 5.0000e-04\n",
      "Epoch 59/60\n",
      "7871/7871 [==============================] - 99s 13ms/step - loss: 0.0472 - val_loss: 0.0638 - lr: 5.0000e-04\n",
      "Epoch 60/60\n",
      "7871/7871 [==============================] - 98s 12ms/step - loss: 0.0479 - val_loss: 0.0857 - lr: 5.0000e-04\n",
      "Epoch 1/60\n",
      "7341/7341 [==============================] - 95s 13ms/step - loss: 0.1858 - val_loss: 0.2060 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.1220 - val_loss: 0.1344 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "7341/7341 [==============================] - 92s 12ms/step - loss: 0.1074 - val_loss: 0.1728 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "7341/7341 [==============================] - 95s 13ms/step - loss: 0.1001 - val_loss: 0.1782 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0951 - val_loss: 0.1043 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0912 - val_loss: 0.1139 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0889 - val_loss: 0.1334 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0858 - val_loss: 0.1523 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0834 - val_loss: 0.0940 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0819 - val_loss: 0.1110 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0796 - val_loss: 0.1026 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "7341/7341 [==============================] - 92s 12ms/step - loss: 0.0791 - val_loss: 0.0951 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0768 - val_loss: 0.0683 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0758 - val_loss: 0.0764 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "7341/7341 [==============================] - 92s 12ms/step - loss: 0.0751 - val_loss: 0.0675 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0740 - val_loss: 0.0570 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "7341/7341 [==============================] - 92s 12ms/step - loss: 0.0725 - val_loss: 0.0803 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0728 - val_loss: 0.0919 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0711 - val_loss: 0.0729 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0706 - val_loss: 0.0702 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0698 - val_loss: 0.0892 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0695 - val_loss: 0.0756 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0685 - val_loss: 0.0626 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0597 - val_loss: 0.0552 - lr: 5.0000e-04\n",
      "Epoch 25/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0586 - val_loss: 0.0680 - lr: 5.0000e-04\n",
      "Epoch 26/60\n",
      "7341/7341 [==============================] - 94s 13ms/step - loss: 0.0579 - val_loss: 0.0789 - lr: 5.0000e-04\n",
      "Epoch 27/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0579 - val_loss: 0.0509 - lr: 5.0000e-04\n",
      "Epoch 28/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0572 - val_loss: 0.0579 - lr: 5.0000e-04\n",
      "Epoch 29/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0571 - val_loss: 0.0723 - lr: 5.0000e-04\n",
      "Epoch 30/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0570 - val_loss: 0.0622 - lr: 5.0000e-04\n",
      "Epoch 31/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0565 - val_loss: 0.0531 - lr: 5.0000e-04\n",
      "Epoch 32/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0565 - val_loss: 0.0690 - lr: 5.0000e-04\n",
      "Epoch 33/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0562 - val_loss: 0.0816 - lr: 5.0000e-04\n",
      "Epoch 34/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0560 - val_loss: 0.0777 - lr: 5.0000e-04\n",
      "Epoch 35/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0507 - val_loss: 0.0439 - lr: 2.5000e-04\n",
      "Epoch 36/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0502 - val_loss: 0.0593 - lr: 2.5000e-04\n",
      "Epoch 37/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0504 - val_loss: 0.0484 - lr: 2.5000e-04\n",
      "Epoch 38/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0498 - val_loss: 0.0399 - lr: 2.5000e-04\n",
      "Epoch 39/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0496 - val_loss: 0.0458 - lr: 2.5000e-04\n",
      "Epoch 40/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0493 - val_loss: 0.0417 - lr: 2.5000e-04\n",
      "Epoch 41/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0494 - val_loss: 0.0638 - lr: 2.5000e-04\n",
      "Epoch 42/60\n",
      "7341/7341 [==============================] - 93s 13ms/step - loss: 0.0493 - val_loss: 0.0442 - lr: 2.5000e-04\n",
      "Epoch 43/60\n",
      "7341/7341 [==============================] - 95s 13ms/step - loss: 0.0492 - val_loss: 0.0445 - lr: 2.5000e-04\n",
      "Epoch 44/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0487 - val_loss: 0.0460 - lr: 2.5000e-04\n",
      "Epoch 45/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0488 - val_loss: 0.0492 - lr: 2.5000e-04\n",
      "Epoch 46/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0459 - val_loss: 0.0388 - lr: 1.2500e-04\n",
      "Epoch 47/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0454 - val_loss: 0.0471 - lr: 1.2500e-04\n",
      "Epoch 48/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0454 - val_loss: 0.0403 - lr: 1.2500e-04\n",
      "Epoch 49/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0453 - val_loss: 0.0453 - lr: 1.2500e-04\n",
      "Epoch 50/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0453 - val_loss: 0.0401 - lr: 1.2500e-04\n",
      "Epoch 51/60\n",
      "7341/7341 [==============================] - 90s 12ms/step - loss: 0.0452 - val_loss: 0.0436 - lr: 1.2500e-04\n",
      "Epoch 52/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0453 - val_loss: 0.0428 - lr: 1.2500e-04\n",
      "Epoch 53/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0450 - val_loss: 0.0393 - lr: 1.2500e-04\n",
      "Epoch 54/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0433 - val_loss: 0.0501 - lr: 6.2500e-05\n",
      "Epoch 55/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0435 - val_loss: 0.0369 - lr: 6.2500e-05\n",
      "Epoch 56/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0431 - val_loss: 0.0395 - lr: 6.2500e-05\n",
      "Epoch 57/60\n",
      "7341/7341 [==============================] - 91s 12ms/step - loss: 0.0429 - val_loss: 0.0341 - lr: 6.2500e-05\n",
      "Epoch 58/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0429 - val_loss: 0.0404 - lr: 6.2500e-05\n",
      "Epoch 59/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0432 - val_loss: 0.0399 - lr: 6.2500e-05\n",
      "Epoch 60/60\n",
      "7341/7341 [==============================] - 92s 13ms/step - loss: 0.0432 - val_loss: 0.0425 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f352a55910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 6) Train\n",
    "call_m = build_mlp(cXtr.shape[1]); call_m.fit(cXtr,cYtr,validation_data=(cXva,cYva),\n",
    "                                             epochs=60,batch_size=4096,callbacks=CB,verbose=1)\n",
    "put_m  = build_mlp(pXtr.shape[1]); put_m.fit(pXtr,pYtr,validation_data=(pXva,pYva),\n",
    "                                             epochs=60,batch_size=4096,callbacks=CB,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0fbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15421/15421 [==============================] - 53s 3ms/step\n",
      "14383/14383 [==============================] - 49s 3ms/step\n",
      "\n",
      "CALL MODEL\n",
      "mid_price   MSE=23.973160  MAE=1.926977  R²=0.9963\n",
      "delta       MSE=0.000587  MAE=0.015549  R²=0.9956\n",
      "gamma       MSE=0.000471  MAE=0.004274  R²=0.9293\n",
      "vega        MSE=20.023605  MAE=1.616324  R²=0.9954\n",
      "theta       MSE=239.236980  MAE=3.278028  R²=0.9490\n",
      "\n",
      "PUT MODEL\n",
      "mid_price   MSE=6.109004  MAE=1.058331  R²=0.9975\n",
      "delta       MSE=0.000656  MAE=0.015936  R²=0.9948\n",
      "gamma       MSE=0.000214  MAE=0.004150  R²=0.9708\n",
      "vega        MSE=34.721731  MAE=1.945969  R²=0.9902\n",
      "theta       MSE=64.822635  MAE=2.151741  R²=0.9679\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7) Evaluate\n",
    "c_pred = ysc_c.inverse_transform(call_m.predict(cXte)); c_true = ysc_c.inverse_transform(cYte)\n",
    "p_pred = ysc_p.inverse_transform( put_m.predict(pXte)); p_true = ysc_p.inverse_transform(pYte)\n",
    "\n",
    "for tag,t,p in [('CALL',c_true,c_pred),('PUT',p_true,p_pred)]:\n",
    "    print(f'\\n{tag} MODEL'); \n",
    "    for i,g in enumerate(Y_COLS):\n",
    "        print(f'{g:10s}  MSE={mean_squared_error(t[:,i],p[:,i]):.6f}  '\n",
    "              f'MAE={mean_absolute_error(t[:,i],p[:,i]):.6f}  '\n",
    "              f'R²={r2_score(t[:,i],p[:,i]):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedffd79",
   "metadata": {},
   "source": [
    "15421/15421 [==============================] - 53s 3ms/step\n",
    "14383/14383 [==============================] - 49s 3ms/step\n",
    "\n",
    "CALL MODEL\n",
    "mid_price   MSE=23.973160  MAE=1.926977  R²=0.9963\n",
    "delta       MSE=0.000587  MAE=0.015549  R²=0.9956\n",
    "gamma       MSE=0.000471  MAE=0.004274  R²=0.9293\n",
    "vega        MSE=20.023605  MAE=1.616324  R²=0.9954\n",
    "theta       MSE=239.236980  MAE=3.278028  R²=0.9490\n",
    "\n",
    "PUT MODEL\n",
    "mid_price   MSE=6.109004  MAE=1.058331  R²=0.9975\n",
    "delta       MSE=0.000656  MAE=0.015936  R²=0.9948\n",
    "gamma       MSE=0.000214  MAE=0.004150  R²=0.9708\n",
    "vega        MSE=34.721731  MAE=1.945969  R²=0.9902\n",
    "theta       MSE=64.822635  MAE=2.151741  R²=0.9679"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32107095",
   "metadata": {},
   "source": [
    "# WITH SSR LARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10410069",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import tensorflow as tf\n",
    "from keras import Input, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Dropout, Concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0) Load and preprocess raw data\n",
    "# ----------------------------------------------------------------------------\n",
    "df = pd.read_parquet('option_data_2021-2023_2000secids.parquet')\n",
    "df['date']   = pd.to_datetime(df['date'])\n",
    "df['exdate'] = pd.to_datetime(df['exdate'])\n",
    "df.rename(columns={'exdate':'maturity'}, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df['strike_price'] /= 1_000\n",
    "\n",
    "# core features\n",
    "df['mid_price']   = (df['best_bid'] + df['best_offer']) / 2\n",
    "df['days_to_exp'] = (df['maturity'] - df['date']).dt.days\n",
    "df['is_call']     = (df['cp_flag']=='C').astype(int)\n",
    "df['log_mny']     = np.log(df['underlying_price']/df['strike_price'])\n",
    "df['log_mny2']    = df['log_mny']**2\n",
    "\n",
    "# helper for SSR labels\n",
    "df['F'] = df['underlying_price'] * np.exp(df['risk_free_rate'] * df['days_to_exp'] / 252)\n",
    "df['k'] = np.log(df['strike_price'] / df['F'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bbe75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Compute SSR labels and enrich features\n",
    "# ----------------------------------------------------------------------------\n",
    "def get_atm(group):\n",
    "    idx = (group['strike_price'] - group['F']).abs().idxmin()\n",
    "    return pd.Series({\n",
    "        'date': group.at[idx,'date'],\n",
    "        'maturity': group.at[idx,'maturity'],\n",
    "        'underlying_price': group.at[idx,'underlying_price'],\n",
    "        'atm_iv': group.at[idx,'impl_volatility']\n",
    "    })\n",
    "atm = df.groupby(['date','maturity']).apply(get_atm).reset_index(drop=True)\n",
    "atm = atm.sort_values(['maturity','date'])\n",
    "atm['dlnS'] = np.log(atm['underlying_price']).groupby(atm['maturity']).diff()\n",
    "atm['dIV']  = atm['atm_iv'].groupby(atm['maturity']).diff()\n",
    "atm['num']  = atm['dIV']/atm['dlnS']\n",
    "\n",
    "def skew_slope(group):\n",
    "    sub = group[np.abs(group['k'])<0.05]\n",
    "    if len(sub)<5: return np.nan\n",
    "    return np.polyfit(sub['k'], sub['impl_volatility'], 1)[0]\n",
    "skew = df.groupby(['date','maturity']).apply(skew_slope).reset_index(name='skew')\n",
    "\n",
    "sr = pd.merge(atm, skew, on=['date','maturity'], how='inner')\n",
    "sr['SSR_raw'] = sr['num']/sr['skew']\n",
    "sr['SSR'] = sr['SSR_raw'].clip(-5,5)\n",
    "# enrich df with SSR label and key vol features\n",
    "df = pd.merge(df, sr[['date','maturity','SSR','atm_iv','skew']], on=['date','maturity'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71b6da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) Feature & target setup\n",
    "# ----------------------------------------------------------------------------\n",
    "X_COLS = [\n",
    "    'underlying_price','strike_price','impl_volatility',\n",
    "    'risk_free_rate','days_to_exp','is_call','log_mny','log_mny2',\n",
    "    'atm_iv','skew'\n",
    "]\n",
    "GREEKS = ['mid_price','delta','gamma','vega','theta']\n",
    "Y_COLS = GREEKS + ['SSR']\n",
    "\n",
    "df.dropna(subset=X_COLS+Y_COLS, inplace=True)\n",
    "df_call, df_put = df[df['is_call']==1], df[df['is_call']==0]\n",
    "split=lambda g: (g.iloc[:int(.98*len(g))], g.iloc[int(.98*len(g)):int(.985*len(g))], g.iloc[int(.985*len(g)):])\n",
    "call_tr, call_va, call_te = split(df_call)\n",
    "put_tr, put_va, put_te    = split(df_put)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78f7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Separate scaling for greeks & SSR & features\n",
    "# ----------------------------------------------------------------------------\n",
    "greek_scaler = StandardScaler().fit(pd.concat([call_tr[GREEKS], put_tr[GREEKS]]))\n",
    "ssr_scaler   = StandardScaler().fit(pd.concat([call_tr[['SSR']],  put_tr[['SSR']]]))\n",
    "feature_scaler = StandardScaler().fit(pd.concat([call_tr[X_COLS], put_tr[X_COLS]]))\n",
    "\n",
    "def prep(df_, xs, gs, ss):\n",
    "    X  = xs.transform(df_[X_COLS])\n",
    "    Yg = gs.transform(df_[GREEKS])\n",
    "    Ys = ss.transform(df_[['SSR']])\n",
    "    return X, np.hstack([Yg, Ys])\n",
    "\n",
    "cXtr, cYtr = prep(call_tr,  feature_scaler, greek_scaler, ssr_scaler)\n",
    "cXva, cYva = prep(call_va,  feature_scaler, greek_scaler, ssr_scaler)\n",
    "cXte, cYte = prep(call_te,  feature_scaler, greek_scaler, ssr_scaler)\n",
    "pXtr, pYtr = prep(put_tr,   feature_scaler, greek_scaler, ssr_scaler)\n",
    "pXva, pYva = prep(put_va,   feature_scaler, greek_scaler, ssr_scaler)\n",
    "pXte, pYte = prep(put_te,   feature_scaler, greek_scaler, ssr_scaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32c7ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) Multi-task MLP: separate greeks & SSR heads\n",
    "# ----------------------------------------------------------------------------\n",
    "def build_mlp_mt(indim, hidden=2048, layers=10, dropout=0.3, theta_w=2.0, ssr_w=10.0):\n",
    "    x = Input(shape=(indim,))\n",
    "    h = Dense(hidden)(x); h = LeakyReLU()(h)\n",
    "    for _ in range(layers-1):\n",
    "        h = Dense(hidden)(h); h = BatchNormalization()(h)\n",
    "        h = LeakyReLU()(h); h = Dropout(dropout)(h)\n",
    "    out_g = Dense(len(GREEKS), name='greeks')(h)\n",
    "    out_s = Dense(1, name='ssr')(h)\n",
    "    model = Model(x, [out_g, out_s])\n",
    "    model.compile('adam', loss={'greeks':'mse','ssr':'mse'}, loss_weights={'greeks':1.0,'ssr':ssr_w})\n",
    "    return model\n",
    "\n",
    "CB = [EarlyStopping(patience=15, restore_best_weights=True), ReduceLROnPlateau(factor=0.5, patience=7)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31b48a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "3915/3915 [==============================] - 437s 110ms/step - loss: 10.8909 - greeks_loss: 0.4791 - ssr_loss: 1.0412 - val_loss: 9.9440 - val_greeks_loss: 0.1097 - val_ssr_loss: 0.9834 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "3915/3915 [==============================] - 430s 110ms/step - loss: 7.7997 - greeks_loss: 0.2001 - ssr_loss: 0.7599 - val_loss: 7.4414 - val_greeks_loss: 0.0952 - val_ssr_loss: 0.7346 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "3915/3915 [==============================] - 429s 110ms/step - loss: 5.8688 - greeks_loss: 0.1863 - ssr_loss: 0.5682 - val_loss: 4.5290 - val_greeks_loss: 0.0707 - val_ssr_loss: 0.4458 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "3915/3915 [==============================] - 425s 109ms/step - loss: 4.5248 - greeks_loss: 0.1774 - ssr_loss: 0.4347 - val_loss: 3.2824 - val_greeks_loss: 0.0634 - val_ssr_loss: 0.3219 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "3915/3915 [==============================] - 429s 110ms/step - loss: 3.6734 - greeks_loss: 0.1706 - ssr_loss: 0.3503 - val_loss: 2.2991 - val_greeks_loss: 0.0658 - val_ssr_loss: 0.2233 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "3915/3915 [==============================] - 426s 109ms/step - loss: 3.1239 - greeks_loss: 0.1646 - ssr_loss: 0.2959 - val_loss: 2.2165 - val_greeks_loss: 0.0722 - val_ssr_loss: 0.2144 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 2.7487 - greeks_loss: 0.1592 - ssr_loss: 0.2590 - val_loss: 1.4398 - val_greeks_loss: 0.0510 - val_ssr_loss: 0.1389 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 2.4842 - greeks_loss: 0.1550 - ssr_loss: 0.2329 - val_loss: 1.2283 - val_greeks_loss: 0.0515 - val_ssr_loss: 0.1177 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 2.2738 - greeks_loss: 0.1517 - ssr_loss: 0.2122 - val_loss: 1.1027 - val_greeks_loss: 0.0481 - val_ssr_loss: 0.1055 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 2.1048 - greeks_loss: 0.1479 - ssr_loss: 0.1957 - val_loss: 1.1036 - val_greeks_loss: 0.0527 - val_ssr_loss: 0.1051 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 1.9632 - greeks_loss: 0.1454 - ssr_loss: 0.1818 - val_loss: 0.9277 - val_greeks_loss: 0.0529 - val_ssr_loss: 0.0875 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 1.8510 - greeks_loss: 0.1423 - ssr_loss: 0.1709 - val_loss: 0.9975 - val_greeks_loss: 0.0549 - val_ssr_loss: 0.0943 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "3915/3915 [==============================] - 419s 107ms/step - loss: 1.7610 - greeks_loss: 0.1401 - ssr_loss: 0.1621 - val_loss: 0.7997 - val_greeks_loss: 0.0506 - val_ssr_loss: 0.0749 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.6786 - greeks_loss: 0.1375 - ssr_loss: 0.1541 - val_loss: 0.7530 - val_greeks_loss: 0.0502 - val_ssr_loss: 0.0703 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "3915/3915 [==============================] - 425s 109ms/step - loss: 1.6148 - greeks_loss: 0.1350 - ssr_loss: 0.1480 - val_loss: 0.6530 - val_greeks_loss: 0.0380 - val_ssr_loss: 0.0615 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "3915/3915 [==============================] - 424s 108ms/step - loss: 1.5587 - greeks_loss: 0.1344 - ssr_loss: 0.1424 - val_loss: 0.6876 - val_greeks_loss: 0.0519 - val_ssr_loss: 0.0636 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "3915/3915 [==============================] - 430s 110ms/step - loss: 1.5009 - greeks_loss: 0.1324 - ssr_loss: 0.1368 - val_loss: 0.6161 - val_greeks_loss: 0.0450 - val_ssr_loss: 0.0571 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "3915/3915 [==============================] - 420s 107ms/step - loss: 1.4579 - greeks_loss: 0.1306 - ssr_loss: 0.1327 - val_loss: 0.6505 - val_greeks_loss: 0.0425 - val_ssr_loss: 0.0608 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "3915/3915 [==============================] - 420s 107ms/step - loss: 1.4149 - greeks_loss: 0.1290 - ssr_loss: 0.1286 - val_loss: 0.6367 - val_greeks_loss: 0.0357 - val_ssr_loss: 0.0601 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "3915/3915 [==============================] - 425s 109ms/step - loss: 1.3797 - greeks_loss: 0.1274 - ssr_loss: 0.1252 - val_loss: 0.5934 - val_greeks_loss: 0.0617 - val_ssr_loss: 0.0532 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "3915/3915 [==============================] - 436s 111ms/step - loss: 1.3488 - greeks_loss: 0.1269 - ssr_loss: 0.1222 - val_loss: 0.6455 - val_greeks_loss: 0.0543 - val_ssr_loss: 0.0591 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "3915/3915 [==============================] - 435s 111ms/step - loss: 1.3149 - greeks_loss: 0.1245 - ssr_loss: 0.1190 - val_loss: 0.5829 - val_greeks_loss: 0.0386 - val_ssr_loss: 0.0544 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "3915/3915 [==============================] - 434s 111ms/step - loss: 1.2887 - greeks_loss: 0.1243 - ssr_loss: 0.1164 - val_loss: 0.5204 - val_greeks_loss: 0.0476 - val_ssr_loss: 0.0473 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "3915/3915 [==============================] - 435s 111ms/step - loss: 1.2617 - greeks_loss: 0.1226 - ssr_loss: 0.1139 - val_loss: 0.5360 - val_greeks_loss: 0.0513 - val_ssr_loss: 0.0485 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "3915/3915 [==============================] - 435s 111ms/step - loss: 1.2362 - greeks_loss: 0.1217 - ssr_loss: 0.1114 - val_loss: 0.4997 - val_greeks_loss: 0.0430 - val_ssr_loss: 0.0457 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "3915/3915 [==============================] - 435s 111ms/step - loss: 1.2146 - greeks_loss: 0.1211 - ssr_loss: 0.1093 - val_loss: 0.5344 - val_greeks_loss: 0.0337 - val_ssr_loss: 0.0501 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "3915/3915 [==============================] - 434s 111ms/step - loss: 1.1933 - greeks_loss: 0.1204 - ssr_loss: 0.1073 - val_loss: 0.4963 - val_greeks_loss: 0.0523 - val_ssr_loss: 0.0444 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.1748 - greeks_loss: 0.1192 - ssr_loss: 0.1056 - val_loss: 0.4504 - val_greeks_loss: 0.0385 - val_ssr_loss: 0.0412 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.1565 - greeks_loss: 0.1187 - ssr_loss: 0.1038 - val_loss: 0.4540 - val_greeks_loss: 0.0414 - val_ssr_loss: 0.0413 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.1391 - greeks_loss: 0.1177 - ssr_loss: 0.1021 - val_loss: 0.4321 - val_greeks_loss: 0.0476 - val_ssr_loss: 0.0384 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.1234 - greeks_loss: 0.1164 - ssr_loss: 0.1007 - val_loss: 0.3838 - val_greeks_loss: 0.0364 - val_ssr_loss: 0.0347 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.1069 - greeks_loss: 0.1155 - ssr_loss: 0.0991 - val_loss: 0.4377 - val_greeks_loss: 0.0384 - val_ssr_loss: 0.0399 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.0909 - greeks_loss: 0.1149 - ssr_loss: 0.0976 - val_loss: 0.4102 - val_greeks_loss: 0.0382 - val_ssr_loss: 0.0372 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.0795 - greeks_loss: 0.1143 - ssr_loss: 0.0965 - val_loss: 0.4271 - val_greeks_loss: 0.0554 - val_ssr_loss: 0.0372 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.0635 - greeks_loss: 0.1133 - ssr_loss: 0.0950 - val_loss: 0.4172 - val_greeks_loss: 0.0323 - val_ssr_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.0508 - greeks_loss: 0.1122 - ssr_loss: 0.0939 - val_loss: 0.4739 - val_greeks_loss: 0.0476 - val_ssr_loss: 0.0426 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.0416 - greeks_loss: 0.1128 - ssr_loss: 0.0929 - val_loss: 0.3759 - val_greeks_loss: 0.0468 - val_ssr_loss: 0.0329 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.0284 - greeks_loss: 0.1113 - ssr_loss: 0.0917 - val_loss: 0.4459 - val_greeks_loss: 0.0368 - val_ssr_loss: 0.0409 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 1.0165 - greeks_loss: 0.1110 - ssr_loss: 0.0905 - val_loss: 0.3989 - val_greeks_loss: 0.0350 - val_ssr_loss: 0.0364 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 1.0066 - greeks_loss: 0.1103 - ssr_loss: 0.0896 - val_loss: 0.3308 - val_greeks_loss: 0.0449 - val_ssr_loss: 0.0286 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9965 - greeks_loss: 0.1103 - ssr_loss: 0.0886 - val_loss: 0.3432 - val_greeks_loss: 0.0389 - val_ssr_loss: 0.0304 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9853 - greeks_loss: 0.1090 - ssr_loss: 0.0876 - val_loss: 0.3913 - val_greeks_loss: 0.0316 - val_ssr_loss: 0.0360 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9757 - greeks_loss: 0.1090 - ssr_loss: 0.0867 - val_loss: 0.5441 - val_greeks_loss: 0.0391 - val_ssr_loss: 0.0505 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9678 - greeks_loss: 0.1084 - ssr_loss: 0.0859 - val_loss: 0.3188 - val_greeks_loss: 0.0348 - val_ssr_loss: 0.0284 - lr: 0.0010\n",
      "Epoch 45/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9580 - greeks_loss: 0.1084 - ssr_loss: 0.0850 - val_loss: 0.3595 - val_greeks_loss: 0.0470 - val_ssr_loss: 0.0313 - lr: 0.0010\n",
      "Epoch 46/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9506 - greeks_loss: 0.1071 - ssr_loss: 0.0844 - val_loss: 0.3665 - val_greeks_loss: 0.0436 - val_ssr_loss: 0.0323 - lr: 0.0010\n",
      "Epoch 47/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9394 - greeks_loss: 0.1062 - ssr_loss: 0.0833 - val_loss: 0.3446 - val_greeks_loss: 0.0426 - val_ssr_loss: 0.0302 - lr: 0.0010\n",
      "Epoch 48/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9334 - greeks_loss: 0.1059 - ssr_loss: 0.0828 - val_loss: 0.3172 - val_greeks_loss: 0.0292 - val_ssr_loss: 0.0288 - lr: 0.0010\n",
      "Epoch 49/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.9269 - greeks_loss: 0.1059 - ssr_loss: 0.0821 - val_loss: 0.3412 - val_greeks_loss: 0.0482 - val_ssr_loss: 0.0293 - lr: 0.0010\n",
      "Epoch 50/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9199 - greeks_loss: 0.1056 - ssr_loss: 0.0814 - val_loss: 0.3352 - val_greeks_loss: 0.0345 - val_ssr_loss: 0.0301 - lr: 0.0010\n",
      "Epoch 51/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9121 - greeks_loss: 0.1054 - ssr_loss: 0.0807 - val_loss: 0.3604 - val_greeks_loss: 0.0379 - val_ssr_loss: 0.0323 - lr: 0.0010\n",
      "Epoch 52/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.9045 - greeks_loss: 0.1042 - ssr_loss: 0.0800 - val_loss: 0.3736 - val_greeks_loss: 0.0369 - val_ssr_loss: 0.0337 - lr: 0.0010\n",
      "Epoch 53/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.8967 - greeks_loss: 0.1038 - ssr_loss: 0.0793 - val_loss: 0.3341 - val_greeks_loss: 0.0336 - val_ssr_loss: 0.0300 - lr: 0.0010\n",
      "Epoch 54/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8912 - greeks_loss: 0.1043 - ssr_loss: 0.0787 - val_loss: 0.3420 - val_greeks_loss: 0.0352 - val_ssr_loss: 0.0307 - lr: 0.0010\n",
      "Epoch 55/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8869 - greeks_loss: 0.1037 - ssr_loss: 0.0783 - val_loss: 0.2877 - val_greeks_loss: 0.0364 - val_ssr_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 56/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8790 - greeks_loss: 0.1030 - ssr_loss: 0.0776 - val_loss: 0.4086 - val_greeks_loss: 0.0298 - val_ssr_loss: 0.0379 - lr: 0.0010\n",
      "Epoch 57/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8752 - greeks_loss: 0.1030 - ssr_loss: 0.0772 - val_loss: 0.2938 - val_greeks_loss: 0.0386 - val_ssr_loss: 0.0255 - lr: 0.0010\n",
      "Epoch 58/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8670 - greeks_loss: 0.1025 - ssr_loss: 0.0765 - val_loss: 0.3023 - val_greeks_loss: 0.0433 - val_ssr_loss: 0.0259 - lr: 0.0010\n",
      "Epoch 59/60\n",
      "3915/3915 [==============================] - 432s 110ms/step - loss: 0.8615 - greeks_loss: 0.1019 - ssr_loss: 0.0760 - val_loss: 0.3198 - val_greeks_loss: 0.0380 - val_ssr_loss: 0.0282 - lr: 0.0010\n",
      "Epoch 60/60\n",
      "3915/3915 [==============================] - 431s 110ms/step - loss: 0.8555 - greeks_loss: 0.1013 - ssr_loss: 0.0754 - val_loss: 0.2906 - val_greeks_loss: 0.0399 - val_ssr_loss: 0.0251 - lr: 0.0010\n",
      "Epoch 1/60\n",
      "3651/3651 [==============================] - 408s 110ms/step - loss: 12.4813 - greeks_loss: 0.5141 - ssr_loss: 1.1967 - val_loss: 10.3683 - val_greeks_loss: 0.0945 - val_ssr_loss: 1.0274 - lr: 0.0010\n",
      "Epoch 2/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 8.3694 - greeks_loss: 0.2274 - ssr_loss: 0.8142 - val_loss: 9.4216 - val_greeks_loss: 0.1061 - val_ssr_loss: 0.9315 - lr: 0.0010\n",
      "Epoch 3/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 7.0301 - greeks_loss: 0.1962 - ssr_loss: 0.6834 - val_loss: 7.1665 - val_greeks_loss: 0.0893 - val_ssr_loss: 0.7077 - lr: 0.0010\n",
      "Epoch 4/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 5.6221 - greeks_loss: 0.1881 - ssr_loss: 0.5434 - val_loss: 5.0018 - val_greeks_loss: 0.0898 - val_ssr_loss: 0.4912 - lr: 0.0010\n",
      "Epoch 5/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 4.5433 - greeks_loss: 0.1802 - ssr_loss: 0.4363 - val_loss: 3.4457 - val_greeks_loss: 0.0903 - val_ssr_loss: 0.3355 - lr: 0.0010\n",
      "Epoch 6/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 3.8223 - greeks_loss: 0.1732 - ssr_loss: 0.3649 - val_loss: 2.7365 - val_greeks_loss: 0.0605 - val_ssr_loss: 0.2676 - lr: 0.0010\n",
      "Epoch 7/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 3.3084 - greeks_loss: 0.1667 - ssr_loss: 0.3142 - val_loss: 2.3815 - val_greeks_loss: 0.0583 - val_ssr_loss: 0.2323 - lr: 0.0010\n",
      "Epoch 8/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 2.9469 - greeks_loss: 0.1633 - ssr_loss: 0.2784 - val_loss: 2.1647 - val_greeks_loss: 0.0579 - val_ssr_loss: 0.2107 - lr: 0.0010\n",
      "Epoch 9/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 2.6662 - greeks_loss: 0.1591 - ssr_loss: 0.2507 - val_loss: 1.7937 - val_greeks_loss: 0.0571 - val_ssr_loss: 0.1737 - lr: 0.0010\n",
      "Epoch 10/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 2.4464 - greeks_loss: 0.1561 - ssr_loss: 0.2290 - val_loss: 1.7196 - val_greeks_loss: 0.0625 - val_ssr_loss: 0.1657 - lr: 0.0010\n",
      "Epoch 11/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 2.2698 - greeks_loss: 0.1531 - ssr_loss: 0.2117 - val_loss: 1.3162 - val_greeks_loss: 0.0539 - val_ssr_loss: 0.1262 - lr: 0.0010\n",
      "Epoch 12/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 2.1294 - greeks_loss: 0.1496 - ssr_loss: 0.1980 - val_loss: 1.4714 - val_greeks_loss: 0.0544 - val_ssr_loss: 0.1417 - lr: 0.0010\n",
      "Epoch 13/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 2.0063 - greeks_loss: 0.1481 - ssr_loss: 0.1858 - val_loss: 1.3574 - val_greeks_loss: 0.0515 - val_ssr_loss: 0.1306 - lr: 0.0010\n",
      "Epoch 14/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.9061 - greeks_loss: 0.1453 - ssr_loss: 0.1761 - val_loss: 0.9515 - val_greeks_loss: 0.0534 - val_ssr_loss: 0.0898 - lr: 0.0010\n",
      "Epoch 15/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.8171 - greeks_loss: 0.1435 - ssr_loss: 0.1674 - val_loss: 1.0046 - val_greeks_loss: 0.0588 - val_ssr_loss: 0.0946 - lr: 0.0010\n",
      "Epoch 16/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.7440 - greeks_loss: 0.1416 - ssr_loss: 0.1602 - val_loss: 1.2504 - val_greeks_loss: 0.0463 - val_ssr_loss: 0.1204 - lr: 0.0010\n",
      "Epoch 17/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.6811 - greeks_loss: 0.1393 - ssr_loss: 0.1542 - val_loss: 0.8338 - val_greeks_loss: 0.0520 - val_ssr_loss: 0.0782 - lr: 0.0010\n",
      "Epoch 18/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.6240 - greeks_loss: 0.1379 - ssr_loss: 0.1486 - val_loss: 1.0541 - val_greeks_loss: 0.0451 - val_ssr_loss: 0.1009 - lr: 0.0010\n",
      "Epoch 19/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.5704 - greeks_loss: 0.1355 - ssr_loss: 0.1435 - val_loss: 0.7590 - val_greeks_loss: 0.0476 - val_ssr_loss: 0.0711 - lr: 0.0010\n",
      "Epoch 20/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.5266 - greeks_loss: 0.1353 - ssr_loss: 0.1391 - val_loss: 0.9469 - val_greeks_loss: 0.0458 - val_ssr_loss: 0.0901 - lr: 0.0010\n",
      "Epoch 21/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.4872 - greeks_loss: 0.1331 - ssr_loss: 0.1354 - val_loss: 0.8109 - val_greeks_loss: 0.0436 - val_ssr_loss: 0.0767 - lr: 0.0010\n",
      "Epoch 22/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.4465 - greeks_loss: 0.1319 - ssr_loss: 0.1315 - val_loss: 0.7293 - val_greeks_loss: 0.0386 - val_ssr_loss: 0.0691 - lr: 0.0010\n",
      "Epoch 23/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.4184 - greeks_loss: 0.1310 - ssr_loss: 0.1287 - val_loss: 0.6612 - val_greeks_loss: 0.0532 - val_ssr_loss: 0.0608 - lr: 0.0010\n",
      "Epoch 24/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.3847 - greeks_loss: 0.1299 - ssr_loss: 0.1255 - val_loss: 0.6077 - val_greeks_loss: 0.0488 - val_ssr_loss: 0.0559 - lr: 0.0010\n",
      "Epoch 25/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.3560 - greeks_loss: 0.1284 - ssr_loss: 0.1228 - val_loss: 0.6584 - val_greeks_loss: 0.0532 - val_ssr_loss: 0.0605 - lr: 0.0010\n",
      "Epoch 26/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.3295 - greeks_loss: 0.1272 - ssr_loss: 0.1202 - val_loss: 0.6493 - val_greeks_loss: 0.0402 - val_ssr_loss: 0.0609 - lr: 0.0010\n",
      "Epoch 27/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.3081 - greeks_loss: 0.1271 - ssr_loss: 0.1181 - val_loss: 0.9735 - val_greeks_loss: 0.0533 - val_ssr_loss: 0.0920 - lr: 0.0010\n",
      "Epoch 28/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.2826 - greeks_loss: 0.1257 - ssr_loss: 0.1157 - val_loss: 0.6165 - val_greeks_loss: 0.0366 - val_ssr_loss: 0.0580 - lr: 0.0010\n",
      "Epoch 29/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.2663 - greeks_loss: 0.1245 - ssr_loss: 0.1142 - val_loss: 0.5793 - val_greeks_loss: 0.0487 - val_ssr_loss: 0.0531 - lr: 0.0010\n",
      "Epoch 30/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.2425 - greeks_loss: 0.1236 - ssr_loss: 0.1119 - val_loss: 0.6416 - val_greeks_loss: 0.0514 - val_ssr_loss: 0.0590 - lr: 0.0010\n",
      "Epoch 31/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.2229 - greeks_loss: 0.1228 - ssr_loss: 0.1100 - val_loss: 0.5843 - val_greeks_loss: 0.0380 - val_ssr_loss: 0.0546 - lr: 0.0010\n",
      "Epoch 32/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.2056 - greeks_loss: 0.1230 - ssr_loss: 0.1083 - val_loss: 0.5871 - val_greeks_loss: 0.0397 - val_ssr_loss: 0.0547 - lr: 0.0010\n",
      "Epoch 33/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.1852 - greeks_loss: 0.1211 - ssr_loss: 0.1064 - val_loss: 0.6527 - val_greeks_loss: 0.0621 - val_ssr_loss: 0.0591 - lr: 0.0010\n",
      "Epoch 34/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.1734 - greeks_loss: 0.1202 - ssr_loss: 0.1053 - val_loss: 0.5507 - val_greeks_loss: 0.0395 - val_ssr_loss: 0.0511 - lr: 0.0010\n",
      "Epoch 35/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.1595 - greeks_loss: 0.1202 - ssr_loss: 0.1039 - val_loss: 0.6347 - val_greeks_loss: 0.0466 - val_ssr_loss: 0.0588 - lr: 0.0010\n",
      "Epoch 36/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.1429 - greeks_loss: 0.1190 - ssr_loss: 0.1024 - val_loss: 0.4755 - val_greeks_loss: 0.0414 - val_ssr_loss: 0.0434 - lr: 0.0010\n",
      "Epoch 37/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.1274 - greeks_loss: 0.1188 - ssr_loss: 0.1009 - val_loss: 0.4791 - val_greeks_loss: 0.0441 - val_ssr_loss: 0.0435 - lr: 0.0010\n",
      "Epoch 38/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.1152 - greeks_loss: 0.1178 - ssr_loss: 0.0997 - val_loss: 0.4992 - val_greeks_loss: 0.0364 - val_ssr_loss: 0.0463 - lr: 0.0010\n",
      "Epoch 39/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.1011 - greeks_loss: 0.1173 - ssr_loss: 0.0984 - val_loss: 0.4910 - val_greeks_loss: 0.0375 - val_ssr_loss: 0.0454 - lr: 0.0010\n",
      "Epoch 40/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.0908 - greeks_loss: 0.1172 - ssr_loss: 0.0974 - val_loss: 0.5088 - val_greeks_loss: 0.0428 - val_ssr_loss: 0.0466 - lr: 0.0010\n",
      "Epoch 41/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.0793 - greeks_loss: 0.1161 - ssr_loss: 0.0963 - val_loss: 0.4467 - val_greeks_loss: 0.0349 - val_ssr_loss: 0.0412 - lr: 0.0010\n",
      "Epoch 42/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.0664 - greeks_loss: 0.1153 - ssr_loss: 0.0951 - val_loss: 0.5554 - val_greeks_loss: 0.0526 - val_ssr_loss: 0.0503 - lr: 0.0010\n",
      "Epoch 43/60\n",
      "3651/3651 [==============================] - 401s 110ms/step - loss: 1.0572 - greeks_loss: 0.1153 - ssr_loss: 0.0942 - val_loss: 0.4780 - val_greeks_loss: 0.0364 - val_ssr_loss: 0.0442 - lr: 0.0010\n",
      "Epoch 44/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.0459 - greeks_loss: 0.1148 - ssr_loss: 0.0931 - val_loss: 0.6605 - val_greeks_loss: 0.0335 - val_ssr_loss: 0.0627 - lr: 0.0010\n",
      "Epoch 45/60\n",
      "3651/3651 [==============================] - 402s 110ms/step - loss: 1.0376 - greeks_loss: 0.1142 - ssr_loss: 0.0923 - val_loss: 0.4777 - val_greeks_loss: 0.0419 - val_ssr_loss: 0.0436 - lr: 0.0010\n",
      "Epoch 46/60\n",
      "3651/3651 [==============================] - 400s 110ms/step - loss: 1.0243 - greeks_loss: 0.1129 - ssr_loss: 0.0911 - val_loss: 0.5413 - val_greeks_loss: 0.0328 - val_ssr_loss: 0.0509 - lr: 0.0010\n",
      "Epoch 47/60\n",
      "3651/3651 [==============================] - 398s 109ms/step - loss: 1.0190 - greeks_loss: 0.1125 - ssr_loss: 0.0906 - val_loss: 0.4406 - val_greeks_loss: 0.0421 - val_ssr_loss: 0.0399 - lr: 0.0010\n",
      "Epoch 48/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 1.0084 - greeks_loss: 0.1126 - ssr_loss: 0.0896 - val_loss: 0.4291 - val_greeks_loss: 0.0511 - val_ssr_loss: 0.0378 - lr: 0.0010\n",
      "Epoch 49/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9998 - greeks_loss: 0.1117 - ssr_loss: 0.0888 - val_loss: 0.4350 - val_greeks_loss: 0.0355 - val_ssr_loss: 0.0400 - lr: 0.0010\n",
      "Epoch 50/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9907 - greeks_loss: 0.1112 - ssr_loss: 0.0879 - val_loss: 0.4202 - val_greeks_loss: 0.0351 - val_ssr_loss: 0.0385 - lr: 0.0010\n",
      "Epoch 51/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9832 - greeks_loss: 0.1114 - ssr_loss: 0.0872 - val_loss: 0.3534 - val_greeks_loss: 0.0455 - val_ssr_loss: 0.0308 - lr: 0.0010\n",
      "Epoch 52/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9769 - greeks_loss: 0.1102 - ssr_loss: 0.0867 - val_loss: 0.5749 - val_greeks_loss: 0.0406 - val_ssr_loss: 0.0534 - lr: 0.0010\n",
      "Epoch 53/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9727 - greeks_loss: 0.1106 - ssr_loss: 0.0862 - val_loss: 0.4437 - val_greeks_loss: 0.0382 - val_ssr_loss: 0.0406 - lr: 0.0010\n",
      "Epoch 54/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9621 - greeks_loss: 0.1097 - ssr_loss: 0.0852 - val_loss: 0.4156 - val_greeks_loss: 0.0388 - val_ssr_loss: 0.0377 - lr: 0.0010\n",
      "Epoch 55/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9542 - greeks_loss: 0.1088 - ssr_loss: 0.0845 - val_loss: 0.4762 - val_greeks_loss: 0.0445 - val_ssr_loss: 0.0432 - lr: 0.0010\n",
      "Epoch 56/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9492 - greeks_loss: 0.1093 - ssr_loss: 0.0840 - val_loss: 0.7242 - val_greeks_loss: 0.0385 - val_ssr_loss: 0.0686 - lr: 0.0010\n",
      "Epoch 57/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9399 - greeks_loss: 0.1088 - ssr_loss: 0.0831 - val_loss: 0.4346 - val_greeks_loss: 0.0346 - val_ssr_loss: 0.0400 - lr: 0.0010\n",
      "Epoch 58/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.9331 - greeks_loss: 0.1081 - ssr_loss: 0.0825 - val_loss: 0.4586 - val_greeks_loss: 0.0321 - val_ssr_loss: 0.0427 - lr: 0.0010\n",
      "Epoch 59/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.8257 - greeks_loss: 0.0993 - ssr_loss: 0.0726 - val_loss: 0.3560 - val_greeks_loss: 0.0296 - val_ssr_loss: 0.0326 - lr: 5.0000e-04\n",
      "Epoch 60/60\n",
      "3651/3651 [==============================] - 399s 109ms/step - loss: 0.8172 - greeks_loss: 0.0979 - ssr_loss: 0.0719 - val_loss: 0.4075 - val_greeks_loss: 0.0310 - val_ssr_loss: 0.0377 - lr: 5.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aaee064790>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) Train multi-task network\n",
    "# ----------------------------------------------------------------------------\n",
    "call_m = build_mlp_mt(cXtr.shape[1])\n",
    "call_m.fit(cXtr, [cYtr[:,:5], cYtr[:,5:]], validation_data=(cXva, [cYva[:,:5], cYva[:,5:]]),\n",
    "           epochs=60, batch_size=8192, callbacks=CB, verbose=1)\n",
    "put_m  = build_mlp_mt(pXtr.shape[1])\n",
    "put_m.fit(pXtr,  [pYtr[:,:5], pYtr[:,5:]], validation_data=(pXva, [pYva[:,:5], pYva[:,5:]]),\n",
    "          epochs=60, batch_size=8192, callbacks=CB, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb770ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15339/15339 [==============================] - 70s 5ms/step\n",
      "\n",
      "CALL MODEL Performance:\n",
      "mid_price   MSE=22.520345  MAE=3.214529  R²=0.8866\n",
      "delta       MSE=0.005262  MAE=0.049099  R²=0.9579\n",
      "gamma       MSE=0.002050  MAE=0.016222  R²=0.8431\n",
      "vega        MSE=14.032539  MAE=2.718047  R²=0.7032\n",
      "theta       MSE=52.067368  MAE=3.174945  R²=0.8541\n",
      "SSR         MSE=0.183972  MAE=0.220200  R²=0.9765\n",
      "14303/14303 [==============================] - 67s 5ms/step\n",
      "\n",
      "PUT MODEL Performance:\n",
      "mid_price   MSE=9.349951  MAE=1.995313  R²=0.9445\n",
      "delta       MSE=0.003025  MAE=0.037927  R²=0.9753\n",
      "gamma       MSE=0.002292  MAE=0.017304  R²=0.8397\n",
      "vega        MSE=12.837138  MAE=2.632674  R²=0.8332\n",
      "theta       MSE=56.644219  MAE=3.139970  R²=0.8669\n",
      "SSR         MSE=0.213453  MAE=0.255303  R²=0.9726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Evaluate including SSR with detailed reports\n",
    "# ----------------------------------------------------------------------------\n",
    "def evaluate_mt(model, X, Y, gs, ss, tag):\n",
    "    pred_g, pred_s = model.predict(X, verbose=1)\n",
    "    true_g = gs.inverse_transform(Y[:,:5])\n",
    "    true_s = ss.inverse_transform(Y[:,5:])\n",
    "    pred_g = gs.inverse_transform(pred_g)\n",
    "    pred_s = ss.inverse_transform(pred_s)\n",
    "\n",
    "    print(f\"\\n{tag} MODEL Performance:\")\n",
    "    for i, name in enumerate(GREEKS):\n",
    "        mse = mean_squared_error(true_g[:,i], pred_g[:,i])\n",
    "        mae = mean_absolute_error(true_g[:,i], pred_g[:,i])\n",
    "        r2  = r2_score(true_g[:,i], pred_g[:,i])\n",
    "        print(f\"{name:10s}  MSE={mse:.6f}  MAE={mae:.6f}  R²={r2:.4f}\")\n",
    "    mse_s = mean_squared_error(true_s[:,0], pred_s[:,0])\n",
    "    mae_s = mean_absolute_error(true_s[:,0], pred_s[:,0])\n",
    "    r2_s  = r2_score(true_s[:,0], pred_s[:,0])\n",
    "    print(f\"{'SSR':10s}  MSE={mse_s:.6f}  MAE={mae_s:.6f}  R²={r2_s:.4f}\")\n",
    "\n",
    "evaluate_mt(call_m, cXte, cYte, greek_scaler, ssr_scaler, 'CALL')\n",
    "evaluate_mt(put_m,  pXte, pYte, greek_scaler, ssr_scaler, 'PUT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685adc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4af9991",
   "metadata": {},
   "source": [
    "512 hidden layers, 6 layers, 4096 batch size, ssr_w = 10.0 \n",
    "15339/15339 [==============================] - 53s 3ms/step\n",
    "\n",
    "CALL MODEL Performance:\n",
    "mid_price   MSE=23.012303  MAE=3.484929  R²=0.8841\n",
    "delta       MSE=0.008162  MAE=0.067397  R²=0.9346\n",
    "gamma       MSE=0.002408  MAE=0.016505  R²=0.8158\n",
    "vega        MSE=21.252476  MAE=3.430168  R²=0.5505\n",
    "theta       MSE=122.277664  MAE=4.450807  R²=0.6574\n",
    "SSR         MSE=0.878807  MAE=0.586897  R²=0.8876\n",
    "14303/14303 [==============================] - 49s 3ms/step\n",
    "\n",
    "PUT MODEL Performance:\n",
    "mid_price   MSE=20.846676  MAE=3.418753  R²=0.8762\n",
    "delta       MSE=0.007359  MAE=0.063661  R²=0.9400\n",
    "gamma       MSE=0.003449  MAE=0.021250  R²=0.7587\n",
    "vega        MSE=26.763761  MAE=3.828162  R²=0.6522\n",
    "theta       MSE=74.410447  MAE=4.479405  R²=0.8252\n",
    "SSR         MSE=0.848236  MAE=0.565792  R²=0.8912"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be6d3c",
   "metadata": {},
   "source": [
    "2048 hidden layers, 8 layers, 8192 batch size, ssr_w = 10.0 \n",
    "15339/15339 [==============================] - 70s 5ms/step\n",
    "\n",
    "CALL MODEL Performance:\n",
    "mid_price   MSE=22.520345  MAE=3.214529  R²=0.8866\n",
    "delta       MSE=0.005262  MAE=0.049099  R²=0.9579\n",
    "gamma       MSE=0.002050  MAE=0.016222  R²=0.8431\n",
    "vega        MSE=14.032539  MAE=2.718047  R²=0.7032\n",
    "theta       MSE=52.067368  MAE=3.174945  R²=0.8541\n",
    "SSR         MSE=0.183972  MAE=0.220200  R²=0.9765\n",
    "14303/14303 [==============================] - 67s 5ms/step\n",
    "\n",
    "PUT MODEL Performance:\n",
    "mid_price   MSE=9.349951  MAE=1.995313  R²=0.9445\n",
    "delta       MSE=0.003025  MAE=0.037927  R²=0.9753\n",
    "gamma       MSE=0.002292  MAE=0.017304  R²=0.8397\n",
    "vega        MSE=12.837138  MAE=2.632674  R²=0.8332\n",
    "theta       MSE=56.644219  MAE=3.139970  R²=0.8669\n",
    "SSR         MSE=0.213453  MAE=0.255303  R²=0.9726"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
