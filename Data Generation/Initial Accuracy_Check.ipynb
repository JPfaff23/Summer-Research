{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e44ec06",
   "metadata": {},
   "source": [
    "# Accuracy across 20 rows at 10M and 100M paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRICE diagnostics:\n",
      "\n",
      "mean_10M           29.98516\n",
      "se_mean_10M        0.004453\n",
      "mean_100M         29.987016\n",
      "se_mean_100M       0.001404\n",
      "diff              -0.001856\n",
      "pooled_se          0.004669\n",
      "z                 -0.397579\n",
      "significant?          False\n",
      "same_3dp?             False\n",
      "accurate_10M?         False\n",
      "accurate_100M?        False\n",
      "Name: price, dtype: object\n",
      "\n",
      "Full comparison table:\n",
      "\n",
      "           mean_10M  se_mean_10M   mean_100M  se_mean_100M        diff  \\\n",
      "metric                                                                   \n",
      "delta_0    0.083708     0.141697   -0.013803      0.045151    0.097511   \n",
      "delta_1    0.324215     0.191464    0.195029      0.060553    0.129186   \n",
      "delta_2   -0.107936     0.198003    0.079814      0.062779   -0.187751   \n",
      "gamma_0  -49.100968    34.012989  -15.084881     10.731792  -34.016087   \n",
      "gamma_1  -55.424309    60.239530    3.618279     19.039738  -59.042588   \n",
      "gamma_2  -52.284884    51.743458  -13.938086     16.265926  -38.346799   \n",
      "price     29.985160     0.004453   29.987016      0.001404   -0.001856   \n",
      "rho     -453.079163  1045.504152 -454.378321    330.990226    1.299159   \n",
      "theta   -117.658991   138.959274  -27.928886     43.962098  -89.730105   \n",
      "vega_0   123.592706   104.126052  -37.953586     32.971870  161.546292   \n",
      "vega_1   -30.266762   244.846646   34.328495     77.440507  -64.595257   \n",
      "vega_2  -236.579953   174.829830  -43.469035     55.278477 -193.110918   \n",
      "\n",
      "          pooled_se         z  significant?  same_3dp?  accurate_10M?  \\\n",
      "metric                                                                  \n",
      "delta_0    0.148716  0.655681         False      False          False   \n",
      "delta_1    0.200811  0.643320         False      False          False   \n",
      "delta_2    0.207717 -0.903879         False      False          False   \n",
      "gamma_0   35.665877 -0.953743         False      False          False   \n",
      "gamma_1   63.176836 -0.934561         False      False          False   \n",
      "gamma_2   54.239891 -0.706985         False      False          False   \n",
      "price      0.004669 -0.397579         False      False          False   \n",
      "rho     1096.646462  0.001185         False      False          False   \n",
      "theta    145.747542 -0.615654         False      False          False   \n",
      "vega_0   109.221696  1.479068         False      False          False   \n",
      "vega_1   256.801309 -0.251538         False      False          False   \n",
      "vega_2   183.360790 -1.053175         False      False          False   \n",
      "\n",
      "         accurate_100M?  \n",
      "metric                   \n",
      "delta_0           False  \n",
      "delta_1           False  \n",
      "delta_2           False  \n",
      "gamma_0           False  \n",
      "gamma_1           False  \n",
      "gamma_2           False  \n",
      "price             False  \n",
      "rho               False  \n",
      "theta             False  \n",
      "vega_0            False  \n",
      "vega_1            False  \n",
      "vega_2            False  \n",
      "\n",
      "ACCURACY SUMMARY:\n",
      "\n",
      "Metrics matching 3dp       : None\n",
      "Metrics failing  3dp       : delta_0, delta_1, delta_2, gamma_0, gamma_1, gamma_2, price, rho, theta, vega_0, vega_1, vega_2\n",
      "Significantly different    : None\n",
      "Accurate at 3dp (10M run)  : None\n",
      "Accurate at 3dp (100M run) : None\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "Checks:\n",
    "1. Statistical significance between 10M and 100M runs using MC-SE of the *mean*.\n",
    "2. Whether the two runs match to 3 dp (|Δmean| < tol).\n",
    "3. Whether each run’s own SE is small enough (SE_of_mean < tol).\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# ── edit these paths if needed ──────────────────────────────────\n",
    "FILE_10M  = \"Data/Test10.parquet\"\n",
    "FILE_100M = \"Data/Test100.parquet\"\n",
    "\n",
    "\n",
    "# ── knobs ───────────────────────────────────────────────────────\n",
    "ABS_TOL = 5e-4       # tolerance on mean difference for 3dp\n",
    "Z_CRIT  = 1.96       # two-tailed z-critical for α = 0.05\n",
    "\n",
    "\n",
    "def load_dfs():\n",
    "    df10 = pd.read_parquet(FILE_10M)\n",
    "    df100 = pd.read_parquet(FILE_100M)\n",
    "    return df10, df100\n",
    "\n",
    "\n",
    "def metrics_from_df(df):\n",
    "    \"\"\"\n",
    "    Identify all metrics that have a matching SE column in the dataframe.\n",
    "    \"\"\"\n",
    "    metrics = set()\n",
    "    for col in df.columns:\n",
    "        m = re.match(r\"(.+)_se(?:_(\\d+))?\", col)\n",
    "        if m:\n",
    "            prefix, idx = m.group(1), m.group(2)\n",
    "            metric = f\"{prefix}_{idx}\" if idx else prefix\n",
    "            metrics.add(metric)\n",
    "    return sorted(metrics)\n",
    "\n",
    "\n",
    "def compute_run_se_of_mean(se_series):\n",
    "    \"\"\"\n",
    "    Compute SE of the mean across rows:\n",
    "      SE_mean = sqrt(sum(se_i**2)) / N_rows\n",
    "    \"\"\"\n",
    "    return np.sqrt((se_series.values**2).sum()) / len(se_series)\n",
    "\n",
    "\n",
    "def compare(df_a, df_b, tol=ABS_TOL, zcrit=Z_CRIT):\n",
    "    mets = metrics_from_df(df_a)\n",
    "    rows = []\n",
    "    for m in mets:\n",
    "        # determine se column name\n",
    "        if '_' in m:\n",
    "            base, idx = m.rsplit('_',1)\n",
    "            se_col = f\"{base}_se_{idx}\"\n",
    "        else:\n",
    "            se_col = f\"{m}_se\"\n",
    "\n",
    "        try:\n",
    "            # compute means\n",
    "            ma = df_a[m].mean()\n",
    "            mb = df_b[m].mean()\n",
    "            # compute SE of mean\n",
    "            sea = compute_run_se_of_mean(df_a[se_col])\n",
    "            seb = compute_run_se_of_mean(df_b[se_col])\n",
    "        except Exception:\n",
    "            # missing columns or other error: skip\n",
    "            continue\n",
    "\n",
    "        # skip if any is not finite\n",
    "        if not all(np.isfinite([ma, mb, sea, seb])):\n",
    "            continue\n",
    "\n",
    "        # z-test for mean difference\n",
    "        diff       = ma - mb\n",
    "        pooled_se  = sqrt(sea**2 + seb**2)\n",
    "        zscore     = diff / pooled_se\n",
    "        significant= abs(zscore) > zcrit\n",
    "\n",
    "        # 3dp agreement\n",
    "        same_3dp   = abs(diff) < tol\n",
    "        # intrinsic accuracy\n",
    "        acc_a      = sea < tol\n",
    "        acc_b      = seb < tol\n",
    "\n",
    "        rows.append({\n",
    "            \"metric\":         m,\n",
    "            \"mean_10M\":       ma,\n",
    "            \"se_mean_10M\":    sea,\n",
    "            \"mean_100M\":      mb,\n",
    "            \"se_mean_100M\":   seb,\n",
    "            \"diff\":           diff,\n",
    "            \"pooled_se\":      pooled_se,\n",
    "            \"z\":              zscore,\n",
    "            \"significant?\":   significant,\n",
    "            \"same_3dp?\":      same_3dp,\n",
    "            \"accurate_10M?\":  acc_a,\n",
    "            \"accurate_100M?\": acc_b,\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"metric\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    df10, df100 = load_dfs()\n",
    "    cmp = compare(df10, df100)\n",
    "\n",
    "    # PRICE diagnostics\n",
    "    print(\"\\nPRICE diagnostics:\\n\")\n",
    "    print(cmp.loc[\"price\", [\n",
    "        \"mean_10M\",\"se_mean_10M\",\n",
    "        \"mean_100M\",\"se_mean_100M\",\n",
    "        \"diff\",\"pooled_se\",\"z\",\n",
    "        \"significant?\",\"same_3dp?\",\n",
    "        \"accurate_10M?\",\"accurate_100M?\"\n",
    "    ]])\n",
    "\n",
    "    # Full comparison table\n",
    "    pd.set_option(\"display.float_format\", \"{:0.6f}\".format)\n",
    "    print(\"\\nFull comparison table:\\n\")\n",
    "    print(cmp)\n",
    "\n",
    "    # Accuracy summary\n",
    "    print(\"\\nACCURACY SUMMARY:\\n\")\n",
    "    match3 = cmp.index[cmp[\"same_3dp?\"]].tolist()\n",
    "    fail3  = cmp.index[~cmp[\"same_3dp?\"]].tolist()\n",
    "    sig    = cmp.index[cmp[\"significant?\"]].tolist()\n",
    "    acc10  = cmp.index[cmp[\"accurate_10M?\"]].tolist()\n",
    "    acc100 = cmp.index[cmp[\"accurate_100M?\"]].tolist()\n",
    "\n",
    "    print(f\"Metrics matching 3dp       : {', '.join(match3) or 'None'}\")\n",
    "    print(f\"Metrics failing  3dp       : {', '.join(fail3) or 'None'}\")\n",
    "    print(f\"Significantly different    : {', '.join(sig) or 'None'}\")\n",
    "    print(f\"Accurate at 3dp (10M run)  : {', '.join(acc10) or 'None'}\")\n",
    "    print(f\"Accurate at 3dp (100M run) : {', '.join(acc100) or 'None'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2518ea",
   "metadata": {},
   "source": [
    "# Ferguson and Green Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae59449",
   "metadata": {},
   "source": [
    "## Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886117c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch\n",
    "from WOF import fg_sample, price_mc, SEED_BASE\n",
    "\n",
    "# 1) Fix your seeds for full reproducibility\n",
    "np.random.seed(SEED_BASE)\n",
    "torch.manual_seed(SEED_BASE)\n",
    "\n",
    "# 2) Draw one scenario and compute price + SE\n",
    "params = fg_sample()\n",
    "price, se = price_mc(\n",
    "    params,\n",
    "    n_paths= 100_000_000,\n",
    "    n_steps=64,\n",
    "    return_se=True\n",
    ")\n",
    "\n",
    "# 3) Define your accuracy thresholds (in absolute price‐error units)\n",
    "thresholds = {\n",
    "    \"1 cent (0.01)\":    0.01,\n",
    "    \"0.1 cent (0.001)\": 0.001,\n",
    "    \"0.01 cent (0.0001)\": 0.0001,\n",
    "}\n",
    "\n",
    "# 4) Print results\n",
    "print(f\"price = {price:.6f},  SE = {se:.6f}\\n\")\n",
    "for label, tol in thresholds.items():\n",
    "    status = \"PASS\" if se < tol else \"FAIL\"\n",
    "    print(f\"{label:15}: {status}  (SE = {se:.6f} {'<' if status=='PASS' else '>'} {tol:.6f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb756232",
   "metadata": {},
   "source": [
    "Able to replicate the Ferguson and Green of 1 cent accuracy with both 10 Mil and 100 Mil paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c64ff",
   "metadata": {},
   "source": [
    "## Variance Reduction Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fdbe9",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Find an effective method to drastically reduce the Monte Carlo standard error (variance) for a robust test dataset of worst‑of option payoffs.\n",
    "\n",
    "---\n",
    "\n",
    "## Methods Attempted\n",
    "\n",
    "1. **Sobol/QMC**\n",
    "   Owen‑scrambled Sobol quasi‑Monte Carlo for low‑discrepancy sampling.\n",
    "\n",
    "2. **Antithetic Variates**\n",
    "   Pairing each Sobol point with its antithetic counterpart.\n",
    "\n",
    "3. **Brownian Bridge**\n",
    "   Reordering the time increments to concentrate variance in early steps.\n",
    "\n",
    "4. **Exponential Tilting (Importance Sampling)**\n",
    "   Tilting the asset Brownian drifts to overweight scenarios where the payoff is nonzero, with likelihood‑ratio correction.\n",
    "\n",
    "5. **Control Variate: Sum of Vanilla Calls**\n",
    "   Adding the sum of individual call payoffs as a crude variate (β=1).\n",
    "\n",
    "6. **Regression‑based Control Variate**\n",
    "   Estimating the optimal β via sample covariance/variance between the target payoff and the call‑sum variate.\n",
    "\n",
    "7. **Geometric‑Basket Control Variate**\n",
    "   Using the analytic geometric‑basket call payoff as a highly correlated variate.\n",
    "\n",
    "8. **Multi‑Level Monte Carlo (MLMC)**\n",
    "   Telescoping coarse and fine time‑step estimates to reduce both bias and variance.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Results\n",
    "\n",
    "* **Base Monte Carlo** with 100 million Sobol+antithetic+bridge paths: SE ≈ 0.00299.\n",
    "* **Regression CV** (sum‑of‑calls): SE ≈ 0.00299 (minimal gain over β=1).\n",
    "* **Geometric‑Basket CV**: moderate improvement but still SE ≳ 0.0025.\n",
    "* **Exponential Tilting + Regression CV**: introduced NaNs at high path counts; once stabilized, SE ≳ 0.0029.\n",
    "\n",
    "*No combination so far has achieved SE ≤ 0.001 on 100 M paths.*\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "* **Fine‑tune Importance Sampling**: search for optimal tilt vector θ to maximize variance reduction.\n",
    "* **Implement MLMC**: start with a two‑level scheme (e.g. 16 vs 64 timesteps) to cut cost and variance.\n",
    "* **Explore Stratification**: stratify by asset index or payoff buckets in conjunction with Sobol.\n",
    "* **Hybrid Methods**: combine tailored tilting, MLMC, and geometric CV for multiplicative gains.\n",
    "\n",
    "*By iterating on these advanced techniques, we aim for another 5×–10× reduction in SE.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef734f8",
   "metadata": {},
   "source": [
    "Have Failed to Replicate this best to probably also switch test set to AAD for Greeks to minimize variance, as well as probably tune down the Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e6efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 56.346448, SE = 0.002206\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "make_worst_of_dataset_fast_streaming.py\n",
    "  • multi-GPU, single-process Monte-Carlo in FP32\n",
    "  • Owen-scrambled Sobol, antithetic, Brownian bridge\n",
    "  • Streaming Welford algorithm for regression control variate\n",
    "  • Geometric-basket control variate with analytic price\n",
    "  • Chunk-safe up to 100 M paths on 4×12 GiB GPUs\n",
    "  • O(1) RAM / no large tensor concatenations\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Beta, Normal\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark       = True\n",
    "\n",
    "# Constants\n",
    "N_ASSETS   = 3\n",
    "R_RATE     = 0.03\n",
    "SEED_BASE  = 42\n",
    "CHUNK_PATH = 1_000_000    # paths per chunk per GPU\n",
    "\n",
    "# Devices\n",
    "NGPU    = torch.cuda.device_count()\n",
    "DEVICES = [torch.device(f\"cuda:{i}\") for i in range(NGPU)]\n",
    "if NGPU == 0:\n",
    "    sys.exit(\"No CUDA GPU visible – aborting.\")\n",
    "\n",
    "# Correlation sampler\n",
    "\n",
    "def cvine_corr(d, a=5.0, b=2.0):\n",
    "    beta = Beta(torch.tensor([a], device=\"cuda\"), torch.tensor([b], device=\"cuda\"))\n",
    "    P    = torch.eye(d, device=\"cuda\")\n",
    "    for k in range(d-1):\n",
    "        for i in range(k+1, d):\n",
    "            rho = 2*beta.sample().item() - 1.0\n",
    "            for m in range(k-1, -1, -1):\n",
    "                rho = rho*math.sqrt((1-P[m,i]**2)*(1-P[m,k]**2)) + P[m,i]*P[m,k]\n",
    "            P[k,i] = P[i,k] = rho\n",
    "    ev,evec = torch.linalg.eigh(P)\n",
    "    return evec @ torch.diag(torch.clamp(ev,min=1e-6)) @ evec.T\n",
    "\n",
    "# Sample generator\n",
    "\n",
    "def fg_sample():\n",
    "    z = np.random.normal(0.5, 0.5, N_ASSETS)\n",
    "    return dict(\n",
    "        S0    = (100*np.exp(z)).astype(np.float32),\n",
    "        sigma = np.random.uniform(0.0,1.0,N_ASSETS).astype(np.float32),\n",
    "        T     = float((np.random.randint(1,44)**2)/252.0),\n",
    "        rho   = cvine_corr(N_ASSETS).cpu().numpy().astype(np.float32),\n",
    "        K     = 100.0,\n",
    "        r     = R_RATE\n",
    "    )\n",
    "\n",
    "# Brownian bridge\n",
    "\n",
    "def brownian_bridge(Z):\n",
    "    order = [Z.shape[1]-1] + list(range(Z.shape[1]-1))\n",
    "    return Z[:,order,:]\n",
    "\n",
    "# QMC+antithetic path generator\n",
    "\n",
    "def generate_qmc_paths(engine, m, n_steps, d, device):\n",
    "    u = engine.draw(m//2, dtype=torch.float32)\n",
    "    u = torch.cat([u, 1.0-u], dim=0).to(device)\n",
    "    u = u.clamp(min=1e-6, max=1-1e-6)\n",
    "    normals = Normal(0.,1.).icdf(u).view(m, n_steps, d)\n",
    "    return brownian_bridge(normals)\n",
    "\n",
    "# Chunk payoff generator (returns discounted worst-of & geo payoffs)\n",
    "@torch.no_grad()\n",
    "def chunk_payoffs(params, m, n_steps, engine, device):\n",
    "    Z     = generate_qmc_paths(engine, m, n_steps, N_ASSETS, device)\n",
    "    S0    = torch.tensor(params['S0'],   device=device)\n",
    "    sigma = torch.tensor(params['sigma'],device=device)\n",
    "    T     = torch.tensor(params['T'],    device=device)\n",
    "    rho   = torch.tensor(params['rho'],  device=device)\n",
    "    K,r   = params['K'], params['r']\n",
    "\n",
    "    dt    = T / n_steps\n",
    "    mu    = r - 0.5 * sigma**2\n",
    "    sig   = sigma\n",
    "    chol  = torch.linalg.cholesky(rho)\n",
    "\n",
    "    logS = torch.log(S0).expand(m, N_ASSETS).clone()\n",
    "    sqrt_dt = math.sqrt(dt.item())\n",
    "    for k in range(n_steps):\n",
    "        dW   = Z[:,k,:] @ chol.T\n",
    "        logS = logS + mu*dt + sig*sqrt_dt*dW\n",
    "    ST      = torch.exp(logS)\n",
    "    payoff  = torch.clamp(ST.min(dim=1).values - K, 0.)\n",
    "    geo_pay = torch.clamp(torch.exp(logS.mean(dim=1)) - K, 0.)\n",
    "\n",
    "    disc_f = math.exp(-r * T.item())\n",
    "    return disc_f * payoff.cpu(), disc_f * geo_pay.cpu()\n",
    "\n",
    "# Analytic geometric basket call price\n",
    "\n",
    "def geo_call_price(S0, K, r, T, sigma, rho):\n",
    "    # sigma_G^2 = (1/d^2) * sigma^T rho sigma\n",
    "    vec = torch.tensor(sigma, dtype=torch.float64)\n",
    "    R   = torch.tensor(rho,    dtype=torch.float64)\n",
    "    varG = (vec @ (R @ vec)) / (N_ASSETS**2)\n",
    "    sigmaG = math.sqrt(varG.item())\n",
    "    G0 = float(np.prod(S0)**(1/N_ASSETS))\n",
    "    d1 = (math.log(G0/K) + (r + 0.5*sigmaG**2)*T) / (sigmaG*math.sqrt(T))\n",
    "    d2 = d1 - sigmaG*math.sqrt(T)\n",
    "    N  = lambda x: 0.5*(1+math.erf(x/math.sqrt(2)))\n",
    "    return G0*N(d1) - K*math.exp(-r*T)*N(d2)\n",
    "\n",
    "# Streaming Monte Carlo with regression CV\n",
    "\n",
    "def price_mc_stream(params, n_paths, n_steps):\n",
    "    per_gpu = n_paths // NGPU\n",
    "    # running sums\n",
    "    cnt = 0\n",
    "    SP, SP2, SC, SC2, SPC = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "    for dev_idx, dev in enumerate(DEVICES):\n",
    "        engine = SobolEngine(N_ASSETS*n_steps, scramble=True, seed=SEED_BASE+dev_idx)\n",
    "        for offset in range(0, per_gpu, CHUNK_PATH):\n",
    "            m = min(CHUNK_PATH, per_gpu - offset)\n",
    "            pay, geo = chunk_payoffs(params, m, n_steps, engine, dev)\n",
    "            # update sums\n",
    "            SP  += pay.sum().item()\n",
    "            SP2 += (pay*pay).sum().item()\n",
    "            SC  += geo.sum().item()\n",
    "            SC2 += (geo*geo).sum().item()\n",
    "            SPC += (pay*geo).sum().item()\n",
    "            cnt += m\n",
    "\n",
    "    # moments\n",
    "    EP  = SP / cnt\n",
    "    EC  = SC / cnt\n",
    "    VarP = SP2/cnt - EP*EP\n",
    "    VarC = SC2/cnt - EC*EC\n",
    "    CovPC= SPC/cnt - EP*EC\n",
    "    beta = CovPC / (VarC + 1e-12)\n",
    "    # corrected price\n",
    "    E_geo = geo_call_price(params['S0'], params['K'], params['r'], params['T'], params['sigma'], params['rho'])\n",
    "    price_cv = EP + beta * (E_geo - EC)\n",
    "    # se\n",
    "    VarPCV = VarP + beta*beta*VarC - 2*beta*CovPC\n",
    "    se = math.sqrt(VarPCV / cnt)\n",
    "    return price_cv, se\n",
    "\n",
    "# Demo\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np, torch\n",
    "    np.random.seed(SEED_BASE)\n",
    "    torch.manual_seed(SEED_BASE)\n",
    "    params = fg_sample()\n",
    "    price, se = price_mc_stream(params, n_paths=100_000_000, n_steps=64)\n",
    "    print(f\"price = {price:.6f}, SE = {se:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a2d792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0_0</th>\n",
       "      <td>2.113525e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0_1</th>\n",
       "      <td>1.538592e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0_2</th>\n",
       "      <td>2.279245e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_0</th>\n",
       "      <td>1.560186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_1</th>\n",
       "      <td>1.559945e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_2</th>\n",
       "      <td>5.808361e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_0_1</th>\n",
       "      <td>5.957953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_0_2</th>\n",
       "      <td>2.674293e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_1_2</th>\n",
       "      <td>4.049550e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>3.000000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>2.285714e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_pw</th>\n",
       "      <td>5.911448e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>5.042010e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>8.749152e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>2.226335e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_0</th>\n",
       "      <td>9.155273e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_1</th>\n",
       "      <td>1.660156e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_2</th>\n",
       "      <td>-2.441406e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>-1.657573e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>-2.174000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>2.899824e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta</th>\n",
       "      <td>1.433021e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td>2.085259e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "S0_0      2.113525e+02\n",
       "S0_1      1.538592e+02\n",
       "S0_2      2.279245e+02\n",
       "sigma_0   1.560186e-01\n",
       "sigma_1   1.559945e-01\n",
       "sigma_2   5.808361e-02\n",
       "corr_0_1  5.957953e-01\n",
       "corr_0_2  2.674293e-01\n",
       "corr_1_2  4.049550e-01\n",
       "K         1.000000e+02\n",
       "r         3.000000e-02\n",
       "T         2.285714e+00\n",
       "price_pw  5.911448e+01\n",
       "delta_0   5.042010e-02\n",
       "delta_1   8.749152e-01\n",
       "delta_2   2.226335e-02\n",
       "gamma_0   9.155273e-13\n",
       "gamma_1   1.660156e-10\n",
       "gamma_2  -2.441406e-12\n",
       "vega_0   -1.657573e+01\n",
       "vega_1   -2.174000e+01\n",
       "vega_2    2.899824e-01\n",
       "theta     1.433021e+00\n",
       "rho       2.085259e+02"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_parquet(\"Train_FGAD.parquet\")\n",
    "\n",
    "x.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db393b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0_0</th>\n",
       "      <td>211.352480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0_1</th>\n",
       "      <td>153.859221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0_2</th>\n",
       "      <td>227.924505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_0</th>\n",
       "      <td>0.156019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_1</th>\n",
       "      <td>0.155995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma_2</th>\n",
       "      <td>0.058084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_0_1</th>\n",
       "      <td>0.595795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_0_2</th>\n",
       "      <td>0.267429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr_1_2</th>\n",
       "      <td>0.404955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>59.114473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>0.947599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>0.947599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>0.947599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_0</th>\n",
       "      <td>0.062639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_1</th>\n",
       "      <td>-1.032843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_2</th>\n",
       "      <td>-0.042773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>-16.575712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>-21.739972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>0.289992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta</th>\n",
       "      <td>1.433022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td>208.525882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "S0_0      211.352480\n",
       "S0_1      153.859221\n",
       "S0_2      227.924505\n",
       "sigma_0     0.156019\n",
       "sigma_1     0.155995\n",
       "sigma_2     0.058084\n",
       "corr_0_1    0.595795\n",
       "corr_0_2    0.267429\n",
       "corr_1_2    0.404955\n",
       "K         100.000000\n",
       "r           0.030000\n",
       "T           2.285714\n",
       "price      59.114473\n",
       "delta_0     0.947599\n",
       "delta_1     0.947599\n",
       "delta_2     0.947599\n",
       "gamma_0     0.062639\n",
       "gamma_1    -1.032843\n",
       "gamma_2    -0.042773\n",
       "vega_0    -16.575712\n",
       "vega_1    -21.739972\n",
       "vega_2      0.289992\n",
       "theta       1.433022\n",
       "rho       208.525882"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x = pd.read_parquet(\"Train_Fast2nd.parquet\")\n",
    "\n",
    "x.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
