{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7b6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_training.py  –– create & save the Rough-Heston surface-to-θ CNN\n",
    "# ================================================================\n",
    "import math, pathlib, time, warnings\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import torch, torch.nn.functional as F\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 0.  global knobs\n",
    "# ---------------------------------------------------------------\n",
    "OUT_DIR   = pathlib.Path.cwd().parent / \"SensitiveData\"\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "MODEL_OUT = OUT_DIR / \"rough_heston_cnn.h5\"\n",
    "\n",
    "# synthetic data set size\n",
    "N_TRAIN   = 60_000          # ~3 GB in RAM (reduce if needed)\n",
    "BATCH_MC  = 8_000           # MC paths per training surface\n",
    "\n",
    "# rough-Heston constants\n",
    "H, N_FAC, T_MAX = 0.1, 10, 1.0\n",
    "R_RATE, DT      = 0.05, 1/252\n",
    "MAT_GRID        = np.array([15,30,60,90,120,180,270,360])/365\n",
    "MNY_EDGES       = np.linspace(-0.25, 0.25, 31)        # 30 bins ⇒ 8×30 grid\n",
    "\n",
    "# seeds for reproducibility\n",
    "np.random.seed(21)\n",
    "torch.manual_seed(21)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1.  helper – rough-Heston MC price surface (torch, CPU/GPU)\n",
    "# ---------------------------------------------------------------\n",
    "lam = np.exp(np.linspace(math.log(1/T_MAX), math.log(1e4/T_MAX), N_FAC))\n",
    "wgt = np.array([math.gamma(H+0.5)/l**(H+0.5) for l in lam]); wgt /= wgt.sum()\n",
    "LAM = torch.tensor(lam);  WGT = torch.tensor(wgt)\n",
    "SQRT2PI = math.sqrt(2*math.pi)\n",
    "\n",
    "@torch.no_grad()\n",
    "def mc_surface(theta_raw, S0=1.0, n_paths=8_000, n_steps=60):\n",
    "    \"\"\"\n",
    "    Returns an 8×30 call-price surface (normalised by S0),\n",
    "    *plus* the option meta-info (K,T×8×30) so that\n",
    "    implied-vol calculation is easy later.\n",
    "    \"\"\"\n",
    "    # unpack raw → (ξ,rho,v0)\n",
    "    xi  = F.softplus(theta_raw[0])\n",
    "    rho = torch.tanh(theta_raw[1])\n",
    "    v0  = F.softplus(theta_raw[2])\n",
    "\n",
    "    # strike grid (8×30) in absolute prices\n",
    "    Krel = np.exp(np.linspace(MNY_EDGES[0], MNY_EDGES[-1], 30))\n",
    "    Kmat = np.repeat(Krel[None,:], MAT_GRID.size, axis=0)\n",
    "    K    = torch.tensor(Kmat * S0)\n",
    "\n",
    "    # pre-allocate tensors\n",
    "    disc = torch.exp(-R_RATE*torch.tensor(MAT_GRID))\n",
    "    S = torch.full((n_paths,), S0)\n",
    "    f = torch.zeros(n_paths, N_FAC)\n",
    "    f[:,0] = torch.sqrt(v0)/(xi*WGT[0])\n",
    "\n",
    "    # antithetic Brownian increments\n",
    "    zS  = torch.randn(n_paths//2, n_steps);  zS = torch.cat([zS,-zS])\n",
    "    zV0 = rho*zS + torch.sqrt(1-rho*rho)*torch.randn_like(zS)\n",
    "    zV  = torch.cat([zV0.unsqueeze(2),\n",
    "                     torch.randn(n_paths, n_steps, N_FAC-1)], 2)\n",
    "\n",
    "    sqrt_dt = math.sqrt(DT);  decay = torch.exp(-LAM*DT)\n",
    "    for t in range(n_steps):\n",
    "        f = f*decay + sqrt_dt*zV[:,t]\n",
    "        v = torch.clamp((xi*(f@WGT))**2, 1e-10)\n",
    "        S = S*torch.exp((-0.5*v)*DT + torch.sqrt(v)*sqrt_dt*zS[:,t])\n",
    "\n",
    "    # payoff (vectorised for all 8×30 strikes)\n",
    "    payoff = torch.relu(S[:,None] - K.flatten())\n",
    "    P_flat = disc.repeat_interleave(30)*payoff.mean(0)\n",
    "    P = P_flat.reshape(8,30) / S0           # scale by spot\n",
    "\n",
    "    return P.numpy().astype('float32')      # 8×30 surface\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2.  generate full training set (θ_raw ↔ surface)\n",
    "# ---------------------------------------------------------------\n",
    "def draw_theta_raw(n):\n",
    "    \"\"\"\n",
    "    Draw *raw* CNN targets θ_raw ~ Uniform(−2,2)^3\n",
    "    (covering a broad range of ξ,ρ,v0 after transforms).\n",
    "    \"\"\"\n",
    "    u = np.random.uniform(-2,2,size=(n,3)).astype('float32')\n",
    "    return u\n",
    "\n",
    "def build_dataset(n_samples, n_paths=BATCH_MC):\n",
    "    X = np.empty((n_samples,8,30,1),dtype='float32')\n",
    "    y = np.empty((n_samples,3),     dtype='float32')\n",
    "\n",
    "    for i in tqdm(range(n_samples),desc=\"synth surfaces\"):\n",
    "        θr = draw_theta_raw(1)[0]\n",
    "        surf = mc_surface(torch.tensor(θr), n_paths=n_paths)\n",
    "        X[i,...,0] = surf\n",
    "        y[i]       = θr\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3.  conv-net architecture\n",
    "# ---------------------------------------------------------------\n",
    "def build_cnn():\n",
    "    model = K.Sequential([\n",
    "        K.layers.Input((8,30,1)),\n",
    "        K.layers.Conv2D(32,(3,3),activation='relu',padding='same'),\n",
    "        K.layers.MaxPool2D((2,2)),\n",
    "        K.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n",
    "        K.layers.Flatten(),\n",
    "        K.layers.Dense(128,activation='relu'),\n",
    "        K.layers.Dense(3)                 # raw θ  (no activation)\n",
    "    ])\n",
    "    model.compile(optimizer=K.optimizers.Adam(1e-3), loss='mse')\n",
    "    return model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4.  train & save\n",
    "# ---------------------------------------------------------------\n",
    "def main():\n",
    "    print(f\"Device for MC (torch): {torch.get_default_dtype()}  |  CNN (TF): {tf.config.experimental.list_physical_devices('GPU')}\")\n",
    "    t0 = time.time()\n",
    "    X,y = build_dataset(N_TRAIN, n_paths=BATCH_MC)\n",
    "    print(f\"\\nSynthetic data built in {(time.time()-t0):.1f}s\\n\")\n",
    "\n",
    "    cnn = build_cnn()\n",
    "    cnn.fit(X, y, batch_size=256, epochs=20,\n",
    "            validation_split=0.05,\n",
    "            callbacks=[K.callbacks.EarlyStopping(patience=3, restore_best_weights=True)])\n",
    "    cnn.save(MODEL_OUT)\n",
    "    print(f\"\\n✓ model saved to {MODEL_OUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11ad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parquet already present – skipping WRDS pull\n",
      "\n",
      "Surface 2023-08-31  |  Spot 4516.08\n",
      "\n",
      "✓ CNN loaded\n",
      "CNN raw θ: [-7.0482683 -1.0284947 -3.0432596]\n",
      "\n",
      "◂ Adam phase (price+IV blend) ▸\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07eadfe7c4b43559913f2b50ef303e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adam:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  · early-stop at 142\n",
      "\n",
      "◂ IV-space LBFGS ▸\n"
     ]
    }
   ],
   "source": [
    "# calibration_and_diagnostics.py\n",
    "\n",
    "# =============================================================\n",
    "# 0.  imports & global knobs\n",
    "# =============================================================\n",
    "import os, math, warnings, pathlib, time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import pyarrow.parquet as pq, pyarrow as pa\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import wrds, torch, torch.nn.functional as F\n",
    "from tensorflow import keras as K\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "DEVICE  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "VERBOSE = True\n",
    "\n",
    "# ─── calibration knobs ────────────────────────────────────────\n",
    "MC_PATHS_FAST    = 25_000        # smoother Adam gradients\n",
    "MC_STEPS_FAST    =   60\n",
    "MC_PATHS_FINE    = 60_000        # hi-res for IV-LBFGS\n",
    "MC_STEPS_FINE    =  120\n",
    "CLAMP_RAW        = 10.0          # allow ξ, v0 up into double‐digits\n",
    "ADAM_LR          = 5e-2          # stronger initial Adam steps\n",
    "BLEND_IV_WEIGHT  = 0.50          # 50/50 blend of price‐ and IV‐loss in Adam\n",
    "EARLY_PATIENCE   = 12            # looser early‐stop\n",
    "MNY_LIMIT        = 0.10\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 1.  WRDS pull  (cached parquet)\n",
    "# =============================================================\n",
    "YEARS, SPX_SECID = range(2021,2024), 108105\n",
    "OUT   = pathlib.Path.cwd().parent / \"SensitiveData\"; OUT.mkdir(exist_ok=True)\n",
    "PARQ  = OUT / \"spx_option_data_2021-2023.parquet\"\n",
    "CNNF  = OUT / \"rough_heston_cnn.h5\"\n",
    "\n",
    "def fetch_spx():\n",
    "    if PARQ.exists():\n",
    "        if VERBOSE: print(\"✓ Parquet already present – skipping WRDS pull\")\n",
    "        return\n",
    "    db = wrds.Connection()\n",
    "    rf = (web.DataReader('DGS3MO','fred',\n",
    "                         datetime(min(YEARS),1,1),\n",
    "                         datetime(max(YEARS),12,31))\n",
    "          .rename(columns={'DGS3MO':'rf'}).reset_index())\n",
    "    rf['rf']  /= 100\n",
    "    rf['date'] = pd.to_datetime(rf['DATE'])\n",
    "    rf = rf[['date','rf']]\n",
    "\n",
    "    writer = None\n",
    "    for yr in YEARS:\n",
    "        print(f\"▸ pulling {yr}\")\n",
    "        opt = db.raw_sql(f\"\"\"\n",
    "          SELECT date,secid,strike_price,best_bid,best_offer,\n",
    "                 exdate,cp_flag\n",
    "          FROM optionm.opprcd{yr}\n",
    "          WHERE secid='{SPX_SECID}'\n",
    "        \"\"\")\n",
    "        if opt.empty: continue\n",
    "        opt['strike_price'] /= 1000\n",
    "        opt['date']   = pd.to_datetime(opt['date'])\n",
    "        opt['exdate'] = pd.to_datetime(opt['exdate'])\n",
    "        opt['mid_price'] = (opt.best_bid + opt.best_offer)/2\n",
    "        opt = opt.merge(rf, on='date', how='left').ffill()\n",
    "\n",
    "        und = db.raw_sql(f\"\"\"\n",
    "          SELECT secid,date,low,high,close,open\n",
    "          FROM optionm.secprd{yr}\n",
    "          WHERE secid='{SPX_SECID}'\n",
    "        \"\"\")\n",
    "        if und.empty: continue\n",
    "        und['date'] = pd.to_datetime(und['date'])\n",
    "        und['S']    = und[['low','high','close','open']].mean(axis=1)\n",
    "        und = und[['secid','date','S']]\n",
    "\n",
    "        df = opt.merge(und, on=['secid','date']).dropna(subset=['S'])\n",
    "        if df.empty: continue\n",
    "        tbl = pa.Table.from_pandas(df, preserve_index=False)\n",
    "        if writer is None:\n",
    "            writer = pa.ParquetWriter(PARQ, tbl.schema)\n",
    "        writer.write_table(tbl)\n",
    "\n",
    "    if writer: writer.close()\n",
    "    db.close()\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 2.  Build latest 8×30 surface\n",
    "# =============================================================\n",
    "MAT = np.array([15,30,60,90,120,180,270,360]) / 365\n",
    "MNY = np.linspace(-0.25, 0.25, 31)\n",
    "\n",
    "def latest_surface():\n",
    "    df = pq.read_table(PARQ).to_pandas()\n",
    "    if 'S' not in df.columns:\n",
    "        df = df.rename(columns={'underlying_price':'S'})\n",
    "\n",
    "    spx = df[(df.secid==SPX_SECID)&(df.cp_flag=='C')&(df.mid_price>0)]\n",
    "    ref = spx.date.max()\n",
    "    spx = spx[spx.date==ref]\n",
    "    S0  = float(spx.S.iloc[0])\n",
    "\n",
    "    spx['mny'] = np.log(spx.strike_price/S0)\n",
    "    spx['T']   = (spx.exdate-ref).dt.days/365\n",
    "    spx        = spx[spx['T'].between(0.04,1)]\n",
    "\n",
    "    grid = np.full((8,30), np.nan)\n",
    "    for i,T in enumerate(MAT):\n",
    "        blk  = spx[np.isclose(spx['T'],T,atol=1/365)]\n",
    "        bins = np.digitize(blk.mny, MNY) - 1\n",
    "        for p,b in zip(blk.mid_price, bins):\n",
    "            if 0<=b<30: grid[i,b] = p\n",
    "\n",
    "    grid = (pd.DataFrame(grid)\n",
    "              .ffill(axis=1).bfill(axis=1)\n",
    "              .ffill().bfill()\n",
    "              .fillna(grid.mean())\n",
    "              .values.astype('float32'))\n",
    "    return grid, S0, ref\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 3.  Load CNN\n",
    "# =============================================================\n",
    "def load_cnn():\n",
    "    if VERBOSE: print(\"✓ CNN loaded\")\n",
    "    return K.models.load_model(CNNF)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 4.  Rough‐Heston MC + BS‐IV helpers\n",
    "# =============================================================\n",
    "H,N_FAC,T_MAX = 0.1,10,1.0\n",
    "R_RATE,DT     = 0.05,1/252\n",
    "lam = np.exp(np.linspace(math.log(1/T_MAX),\n",
    "                         math.log(1e4/T_MAX), N_FAC))\n",
    "wgt = np.array([math.gamma(H+0.5)/l**(H+0.5) for l in lam])\n",
    "wgt /= wgt.sum()\n",
    "LAM, WGT = (torch.tensor(lam,device=DEVICE),\n",
    "            torch.tensor(wgt,device=DEVICE))\n",
    "\n",
    "def mc_price(raw, K, T, S0, n_paths, n_steps):\n",
    "    raw = raw.to(DEVICE)\n",
    "    xi, rho, v0 = (F.softplus(raw[0]),\n",
    "                   torch.tanh(raw[1]),\n",
    "                   F.softplus(raw[2]))\n",
    "    Kt, Tt = map(lambda x: torch.as_tensor(x,device=DEVICE),(K,T))\n",
    "    disc   = torch.exp(-R_RATE*Tt)\n",
    "\n",
    "    half = n_paths//2\n",
    "    zS   = torch.randn(half,n_steps,device=DEVICE)\n",
    "    zS   = torch.cat([zS,-zS],0)  # antithetic\n",
    "    zV0  = rho*zS + torch.sqrt(1-rho*rho)*torch.randn_like(zS)\n",
    "    zV   = torch.cat([zV0.unsqueeze(2),\n",
    "                      torch.randn(n_paths,n_steps,N_FAC-1,\n",
    "                                   device=DEVICE)],2)\n",
    "\n",
    "    S = torch.full((n_paths,),S0,device=DEVICE)\n",
    "    f = torch.zeros(n_paths,N_FAC,device=DEVICE)\n",
    "    f[:,0] = torch.sqrt(v0)/(xi*WGT[0])\n",
    "\n",
    "    sqrt_dt, decay = math.sqrt(DT), torch.exp(-LAM*DT)\n",
    "    for t in range(n_steps):\n",
    "        f = f*decay + sqrt_dt*zV[:,t]\n",
    "        v = torch.clamp((xi*(f@WGT))**2,1e-10)\n",
    "        S = S*torch.exp((-0.5*v)*DT + torch.sqrt(v)*sqrt_dt*zS[:,t])\n",
    "\n",
    "    payoff    = torch.relu(S.unsqueeze(1)-Kt)\n",
    "    P         = disc*payoff.mean(0)\n",
    "    intrinsic = torch.clamp(S0-Kt,min=0.0)\n",
    "    maxv      = intrinsic.new_full(intrinsic.shape,0.999*S0)\n",
    "    return torch.clamp(P,intrinsic+1e-6,maxv)\n",
    "\n",
    "\n",
    "SQRT2PI = math.sqrt(2*math.pi)\n",
    "def iv_from_price(price, S, K, T, guess=0.2):\n",
    "    price,S,K,T = [x.to(DEVICE) for x in (price,S,K,T)]\n",
    "    σ = torch.full_like(price, guess, device=DEVICE)\n",
    "    for _ in range(10):\n",
    "        d1    = (torch.log(S/K)+0.5*σ**2*T)/(σ*torch.sqrt(T)+1e-12)\n",
    "        d2    = d1 - σ*torch.sqrt(T)\n",
    "        c     = (S*0.5*(1+torch.erf(d1/math.sqrt(2)))\n",
    "                 -K*torch.exp(-R_RATE*T)*0.5*(1+torch.erf(d2/math.sqrt(2))))\n",
    "        vega  = S*torch.exp(-0.5*d1**2)/SQRT2PI * torch.sqrt(T)\n",
    "        σ     = torch.clamp(σ-(c-price)/vega.clamp_min(1e-8),\n",
    "                             1e-4,5.0)\n",
    "    return torch.nan_to_num(σ,nan=5.0)\n",
    "\n",
    "bs_iv    = iv_from_price\n",
    "bs_vega  = lambda S,K,T,σ: (\n",
    "    S*torch.exp(-0.5*((torch.log(S/K)+0.5*σ**2*T)/(σ*torch.sqrt(T)+1e-12))**2)\n",
    "    / SQRT2PI * torch.sqrt(T)\n",
    ")\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 5.  Two‐stage calibration\n",
    "# =============================================================\n",
    "def huber(res, δ=0.05):\n",
    "    return torch.where(res.abs()<δ, 0.5*res**2/δ, res.abs()-0.5*δ)\n",
    "\n",
    "def calibrate(theta0, K, T, mid, S0):\n",
    "    K,T,mid = map(lambda x: np.asarray(x,dtype=np.float64),(K,T,mid))\n",
    "    θ = torch.tensor(np.clip(theta0,-CLAMP_RAW,CLAMP_RAW),\n",
    "                     dtype=torch.double,requires_grad=True,device=DEVICE)\n",
    "\n",
    "    Kt, Tt, mid_t = [torch.tensor(x,dtype=torch.double,device=DEVICE)\n",
    "                     for x in (K,T,mid)]\n",
    "\n",
    "    # precompute market IV + vega\n",
    "    iv_t   = bs_iv(mid_t, torch.tensor(S0,device=DEVICE), Kt, Tt)\n",
    "    vega_t = bs_vega(torch.tensor(S0,device=DEVICE), Kt, Tt, iv_t).clamp_min(1e-3)\n",
    "    W_price = 1/vega_t\n",
    "    W_iv    = 1/vega_t\n",
    "\n",
    "    # --- Adam (blended price+IV) ---\n",
    "    optA  = torch.optim.Adam([θ], lr=ADAM_LR)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optA, T_max=150)\n",
    "    best, bad = 1e9, 0\n",
    "\n",
    "    if VERBOSE: print(\"\\n◂ Adam phase (price+IV blend) ▸\")\n",
    "    for it in tqdm(range(200), disable=not VERBOSE, desc=\"Adam\"):\n",
    "        optA.zero_grad()\n",
    "        P     = mc_price(θ,K,T,S0,MC_PATHS_FAST,MC_STEPS_FAST)\n",
    "        σ     = bs_iv(P, torch.tensor(S0,device=DEVICE), Kt, Tt)\n",
    "        lp    = torch.mean(W_price * huber(P-mid_t))\n",
    "        li    = torch.mean(W_iv    * (σ-iv_t)**2)\n",
    "        loss  = (1-BLEND_IV_WEIGHT)*lp + BLEND_IV_WEIGHT*li\n",
    "        loss.backward(); optA.step(); sched.step()\n",
    "        θ.data.clamp_(-CLAMP_RAW, CLAMP_RAW)\n",
    "\n",
    "        l = loss.item()\n",
    "        if l < best-1e-4:\n",
    "            best, bad = l, 0\n",
    "        else:\n",
    "            bad += 1\n",
    "        if bad >= EARLY_PATIENCE:\n",
    "            if VERBOSE: print(f\"  · early-stop at {it}\")\n",
    "            break\n",
    "\n",
    "    # --- IV-space LBFGS fine-tune ---\n",
    "    optB = torch.optim.LBFGS([θ], lr=0.1, max_iter=20,\n",
    "                             line_search_fn='strong_wolfe')\n",
    "    def closure():\n",
    "        optB.zero_grad()\n",
    "        P  = mc_price(θ,K,T,S0,MC_PATHS_FINE,MC_STEPS_FINE)\n",
    "        σ  = bs_iv(P, torch.tensor(S0,device=DEVICE), Kt, Tt)\n",
    "        l  = torch.mean(W_iv * (σ-iv_t)**2)\n",
    "        l.backward()\n",
    "        return l\n",
    "\n",
    "    if VERBOSE: print(\"\\n◂ IV-space LBFGS ▸\")\n",
    "    optB.step(closure)\n",
    "    θ.data.clamp_(-CLAMP_RAW, CLAMP_RAW)\n",
    "\n",
    "    return θ.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 6.  main: calibrate & diagnostics (with vega‐weighted RMSE)\n",
    "# =============================================================\n",
    "if __name__==\"__main__\":\n",
    "    fetch_spx()\n",
    "\n",
    "    surf, S0, ref = latest_surface()\n",
    "    print(f\"\\nSurface {ref.date()}  |  Spot {S0:.2f}\\n\")\n",
    "\n",
    "    θ0 = load_cnn().predict(surf[None,...],verbose=0)[0]\n",
    "    print(\"CNN raw θ:\", θ0)\n",
    "\n",
    "    df = pq.read_table(PARQ).to_pandas()\n",
    "    df = df[(df.date==ref)&(df.cp_flag=='C')]\n",
    "    df['T'] = (df.exdate-ref).dt.days/365\n",
    "    df = df[np.abs(np.log(df.strike_price/S0)) < MNY_LIMIT]\n",
    "\n",
    "    K_vec, T_vec, mid_vec = (\n",
    "        df.strike_price.values,\n",
    "        df['T'].values,\n",
    "        df.mid_price.values\n",
    "    )\n",
    "\n",
    "    θ_ref = calibrate(θ0, K_vec, T_vec, mid_vec, S0)\n",
    "    print(\"\\nRefined θ:\", θ_ref)\n",
    "\n",
    "    # diagnostics\n",
    "    with torch.no_grad():\n",
    "        P_mod = mc_price(torch.tensor(θ_ref,device=DEVICE),\n",
    "                         K_vec, T_vec, S0,\n",
    "                         MC_PATHS_FINE, MC_STEPS_FINE).cpu().numpy()\n",
    "        iv_mkt = bs_iv(torch.tensor(mid_vec,device=DEVICE),\n",
    "                       torch.tensor(S0,device=DEVICE),\n",
    "                       torch.tensor(K_vec,device=DEVICE),\n",
    "                       torch.tensor(T_vec,device=DEVICE)).cpu().numpy()\n",
    "        σ_mod  = bs_iv(torch.tensor(P_mod,device=DEVICE),\n",
    "                       torch.tensor(S0,device=DEVICE),\n",
    "                       torch.tensor(K_vec,device=DEVICE),\n",
    "                       torch.tensor(T_vec,device=DEVICE)).cpu().numpy()\n",
    "\n",
    "    # Price-space scatter\n",
    "    plt.figure(figsize=(5,5))\n",
    "    m = max(mid_vec.max(), P_mod.max())\n",
    "    plt.scatter(mid_vec, P_mod, alpha=0.4)\n",
    "    plt.plot([0,m],[0,m],'k--')\n",
    "    plt.title(\"Price-space fit\")\n",
    "    plt.xlabel(\"Market Price\"); plt.ylabel(\"Model Price\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # IV-space scatter\n",
    "    plt.figure(figsize=(5,5))\n",
    "    miv = max(iv_mkt.max(), σ_mod.max())\n",
    "    plt.scatter(iv_mkt, σ_mod, alpha=0.4)\n",
    "    plt.plot([0,miv],[0,miv],'k--')\n",
    "    plt.title(\"IV-space fit\")\n",
    "    plt.xlabel(\"Market IV\"); plt.ylabel(\"Model IV\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # Vega‐weighted RMSE in price‐space\n",
    "    vega_np = bs_vega(torch.tensor(S0),\n",
    "                      torch.tensor(K_vec),\n",
    "                      torch.tensor(T_vec),\n",
    "                      torch.tensor(iv_mkt)\n",
    "                     ).cpu().numpy()\n",
    "    # clamp to avoid division by zero\n",
    "    vega_np = np.clip(vega_np, 1e-3, None)\n",
    "    rmse_vw = np.sqrt(np.mean(((P_mod-mid_vec)/vega_np)**2))\n",
    "    print(f\"Vega-weighted RMSE (price): {rmse_vw:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1b320",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_mkt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# P_mkt and P_fit should already be in your namespace\u001b[39;00m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(\u001b[43mP_mkt\u001b[49m, P_fit, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[0;32m      8\u001b[0m m \u001b[38;5;241m=\u001b[39m P_mkt\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m0\u001b[39m,m],[\u001b[38;5;241m0\u001b[39m,m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk--\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P_mkt' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simulate_synthetic.py\n",
    "\n",
    "import pandas as pd\n",
    "import torch, math\n",
    "from calibration_and_diagnostics import simulate_synthetic_paths\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    # load your calibrated θ_ref from disk or re-run Part A to get θ_ref\n",
    "    θ_ref = ...  # e.g. np.load(\"theta_ref.npy\")\n",
    "\n",
    "    print(\"Generating synthetic scenarios...\")\n",
    "    synth_df = simulate_synthetic_paths(\n",
    "        θ_ref,\n",
    "        n_scenarios=1000,\n",
    "        days=252\n",
    "    )\n",
    "    out = pathlib.Path.cwd().parent / \"SensitiveData\" / \"synthetic_dataset.parquet\"\n",
    "    synth_df.to_parquet(out, index=False)\n",
    "    print(f\"Saved synthetic dataset at {out}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
