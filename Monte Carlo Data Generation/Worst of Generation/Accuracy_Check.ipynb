{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e44ec06",
   "metadata": {},
   "source": [
    "# Accuracy across 20 rows at 10M and 100M paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b59c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRICE diagnostics:\n",
      "\n",
      "mean_10M           20.575977\n",
      "se_mean_10M         0.003528\n",
      "mean_100M          23.098340\n",
      "se_mean_100M        0.001233\n",
      "diff               -2.522363\n",
      "pooled_se           0.003737\n",
      "z                -674.890099\n",
      "significant?            True\n",
      "same_3dp?              False\n",
      "accurate_10M?          False\n",
      "accurate_100M?         False\n",
      "Name: price, dtype: object\n",
      "\n",
      "Full comparison table:\n",
      "\n",
      "         mean_10M  se_mean_10M  mean_100M  se_mean_100M      diff  pooled_se  \\\n",
      "metric                                                                         \n",
      "delta_0  0.219971     0.000170   0.310645      0.000071 -0.090674   0.000184   \n",
      "delta_1  0.149243     0.000325   0.108130      0.000067  0.041113   0.000332   \n",
      "delta_2  0.107227     0.000104   0.096484      0.000034  0.010742   0.000109   \n",
      "gamma_0 -4.162500     0.016171   4.431250      0.006797 -8.593750   0.017541   \n",
      "gamma_2 -6.606250     0.006380  -5.940625      0.002079 -0.665625   0.006710   \n",
      "price   20.575977     0.003528  23.098340      0.001233 -2.522363   0.003737   \n",
      "theta   -0.298389     0.007527  -0.537662      0.002432  0.239273   0.007911   \n",
      "\n",
      "                  z  significant?  same_3dp?  accurate_10M?  accurate_100M?  \n",
      "metric                                                                       \n",
      "delta_0 -492.866736          True      False           True            True  \n",
      "delta_1  123.704875          True      False           True            True  \n",
      "delta_2   98.609272          True      False           True            True  \n",
      "gamma_0 -489.916273          True      False          False           False  \n",
      "gamma_2  -99.198776          True      False          False           False  \n",
      "price   -674.890099          True      False          False           False  \n",
      "theta     30.247100          True      False          False           False  \n",
      "\n",
      "ACCURACY SUMMARY:\n",
      "\n",
      "Metrics matching 3dp       : None\n",
      "Metrics failing  3dp       : delta_0, delta_1, delta_2, gamma_0, gamma_2, price, theta\n",
      "Significantly different    : delta_0, delta_1, delta_2, gamma_0, gamma_2, price, theta\n",
      "Accurate at 3dp (10M run)  : delta_0, delta_1, delta_2\n",
      "Accurate at 3dp (100M run) : delta_0, delta_1, delta_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacks\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\numpy\\core\\_methods.py:49: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    "Checks:\n",
    "1. Statistical significance between 10M and 100M runs using MC-SE of the *mean*.\n",
    "2. Whether the two runs match to 3 dp (|Δmean| < tol).\n",
    "3. Whether each run’s own SE is small enough (SE_of_mean < tol).\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "# ── edit these paths if needed ──────────────────────────────────\n",
    "FILE_10M  = \"results_10M.parquet\"\n",
    "FILE_100M = \"results_100M.parquet\"\n",
    "\n",
    "# ── knobs ───────────────────────────────────────────────────────\n",
    "ABS_TOL = 5e-4       # tolerance on mean difference for 3dp\n",
    "Z_CRIT  = 1.96       # two-tailed z-critical for α = 0.05\n",
    "\n",
    "\n",
    "def load_dfs():\n",
    "    df10 = pd.read_parquet(FILE_10M)\n",
    "    df100 = pd.read_parquet(FILE_100M)\n",
    "    return df10, df100\n",
    "\n",
    "\n",
    "def metrics_from_df(df):\n",
    "    \"\"\"\n",
    "    Identify all metrics that have a matching SE column in the dataframe.\n",
    "    \"\"\"\n",
    "    metrics = set()\n",
    "    for col in df.columns:\n",
    "        m = re.match(r\"(.+)_se(?:_(\\d+))?\", col)\n",
    "        if m:\n",
    "            prefix, idx = m.group(1), m.group(2)\n",
    "            metric = f\"{prefix}_{idx}\" if idx else prefix\n",
    "            metrics.add(metric)\n",
    "    return sorted(metrics)\n",
    "\n",
    "\n",
    "def compute_run_se_of_mean(se_series):\n",
    "    \"\"\"\n",
    "    Compute SE of the mean across rows:\n",
    "      SE_mean = sqrt(sum(se_i**2)) / N_rows\n",
    "    \"\"\"\n",
    "    return np.sqrt((se_series.values**2).sum()) / len(se_series)\n",
    "\n",
    "\n",
    "def compare(df_a, df_b, tol=ABS_TOL, zcrit=Z_CRIT):\n",
    "    mets = metrics_from_df(df_a)\n",
    "    rows = []\n",
    "    for m in mets:\n",
    "        # determine se column name\n",
    "        if '_' in m:\n",
    "            base, idx = m.rsplit('_',1)\n",
    "            se_col = f\"{base}_se_{idx}\"\n",
    "        else:\n",
    "            se_col = f\"{m}_se\"\n",
    "\n",
    "        try:\n",
    "            # compute means\n",
    "            ma = df_a[m].mean()\n",
    "            mb = df_b[m].mean()\n",
    "            # compute SE of mean\n",
    "            sea = compute_run_se_of_mean(df_a[se_col])\n",
    "            seb = compute_run_se_of_mean(df_b[se_col])\n",
    "        except Exception:\n",
    "            # missing columns or other error: skip\n",
    "            continue\n",
    "\n",
    "        # skip if any is not finite\n",
    "        if not all(np.isfinite([ma, mb, sea, seb])):\n",
    "            continue\n",
    "\n",
    "        # z-test for mean difference\n",
    "        diff       = ma - mb\n",
    "        pooled_se  = sqrt(sea**2 + seb**2)\n",
    "        zscore     = diff / pooled_se\n",
    "        significant= abs(zscore) > zcrit\n",
    "\n",
    "        # 3dp agreement\n",
    "        same_3dp   = abs(diff) < tol\n",
    "        # intrinsic accuracy\n",
    "        acc_a      = sea < tol\n",
    "        acc_b      = seb < tol\n",
    "\n",
    "        rows.append({\n",
    "            \"metric\":         m,\n",
    "            \"mean_10M\":       ma,\n",
    "            \"se_mean_10M\":    sea,\n",
    "            \"mean_100M\":      mb,\n",
    "            \"se_mean_100M\":   seb,\n",
    "            \"diff\":           diff,\n",
    "            \"pooled_se\":      pooled_se,\n",
    "            \"z\":              zscore,\n",
    "            \"significant?\":   significant,\n",
    "            \"same_3dp?\":      same_3dp,\n",
    "            \"accurate_10M?\":  acc_a,\n",
    "            \"accurate_100M?\": acc_b,\n",
    "        })\n",
    "    return pd.DataFrame(rows).set_index(\"metric\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    df10, df100 = load_dfs()\n",
    "    cmp = compare(df10, df100)\n",
    "\n",
    "    # PRICE diagnostics\n",
    "    print(\"\\nPRICE diagnostics:\\n\")\n",
    "    print(cmp.loc[\"price\", [\n",
    "        \"mean_10M\",\"se_mean_10M\",\n",
    "        \"mean_100M\",\"se_mean_100M\",\n",
    "        \"diff\",\"pooled_se\",\"z\",\n",
    "        \"significant?\",\"same_3dp?\",\n",
    "        \"accurate_10M?\",\"accurate_100M?\"\n",
    "    ]])\n",
    "\n",
    "    # Full comparison table\n",
    "    pd.set_option(\"display.float_format\", \"{:0.6f}\".format)\n",
    "    print(\"\\nFull comparison table:\\n\")\n",
    "    print(cmp)\n",
    "\n",
    "    # Accuracy summary\n",
    "    print(\"\\nACCURACY SUMMARY:\\n\")\n",
    "    match3 = cmp.index[cmp[\"same_3dp?\"]].tolist()\n",
    "    fail3  = cmp.index[~cmp[\"same_3dp?\"]].tolist()\n",
    "    sig    = cmp.index[cmp[\"significant?\"]].tolist()\n",
    "    acc10  = cmp.index[cmp[\"accurate_10M?\"]].tolist()\n",
    "    acc100 = cmp.index[cmp[\"accurate_100M?\"]].tolist()\n",
    "\n",
    "    print(f\"Metrics matching 3dp       : {', '.join(match3) or 'None'}\")\n",
    "    print(f\"Metrics failing  3dp       : {', '.join(fail3) or 'None'}\")\n",
    "    print(f\"Significantly different    : {', '.join(sig) or 'None'}\")\n",
    "    print(f\"Accurate at 3dp (10M run)  : {', '.join(acc10) or 'None'}\")\n",
    "    print(f\"Accurate at 3dp (100M run) : {', '.join(acc100) or 'None'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2518ea",
   "metadata": {},
   "source": [
    "# Ferguson and Green Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae59449",
   "metadata": {},
   "source": [
    "## Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886117c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 54.250000,  SE = 0.002989\n",
      "\n",
      "1 cent (0.01)  : PASS  (SE = 0.002989 < 0.010000)\n",
      "0.1 cent (0.001): FAIL  (SE = 0.002989 > 0.001000)\n",
      "0.01 cent (0.0001): FAIL  (SE = 0.002989 > 0.000100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, torch\n",
    "from make_worst_of import fg_sample, price_mc, SEED_BASE\n",
    "\n",
    "# 1) Fix your seeds for full reproducibility\n",
    "np.random.seed(SEED_BASE)\n",
    "torch.manual_seed(SEED_BASE)\n",
    "\n",
    "# 2) Draw one scenario and compute price + SE\n",
    "params = fg_sample()\n",
    "price, se = price_mc(\n",
    "    params,\n",
    "    n_paths= 100_000_000,\n",
    "    n_steps=64,\n",
    "    return_se=True\n",
    ")\n",
    "\n",
    "# 3) Define your accuracy thresholds (in absolute price‐error units)\n",
    "thresholds = {\n",
    "    \"1 cent (0.01)\":    0.01,\n",
    "    \"0.1 cent (0.001)\": 0.001,\n",
    "    \"0.01 cent (0.0001)\": 0.0001,\n",
    "}\n",
    "\n",
    "# 4) Print results\n",
    "print(f\"price = {price:.6f},  SE = {se:.6f}\\n\")\n",
    "for label, tol in thresholds.items():\n",
    "    status = \"PASS\" if se < tol else \"FAIL\"\n",
    "    print(f\"{label:15}: {status}  (SE = {se:.6f} {'<' if status=='PASS' else '>'} {tol:.6f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb756232",
   "metadata": {},
   "source": [
    "Able to replicate the Ferguson and Green of 1 cent accuracy with both 10 Mil and 100 Mil paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c64ff",
   "metadata": {},
   "source": [
    "## Variance Reduction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e6efcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 32.144659, SE = 0.002985\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "make_worst_of_dataset_fast.py\n",
    "  • multi-GPU, single-process Monte-Carlo in FP32 for stability\n",
    "  • Owen-scrambled Sobol, antithetic, Brownian bridge\n",
    "  • Control variate: sum of single-asset Black-Scholes calls\n",
    "  • Chunk-safe up to 100 M paths on 4×12 GiB GPUs\n",
    "  • Exports price & Greeks with sampling-error columns\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "import pathlib\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from torch.distributions import Beta, Normal\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "# ─────────────────────────── knobs ────────────────────────────\n",
    "# Use FP32 to avoid NaNs\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark       = True\n",
    "\n",
    "# Problem constants\n",
    "N_ASSETS   = 3\n",
    "R_RATE     = 0.03\n",
    "EPS_REL    = 1e-4\n",
    "SEED_BASE  = 42\n",
    "CHUNK_MAX  = 1_000_000   # flush Parquet every X rows\n",
    "CHUNK_PATH = 1_000_000   # inner GPU chunk size for MC\n",
    "\n",
    "# CUDA devices\n",
    "NGPU    = torch.cuda.device_count()\n",
    "DEVICES = [torch.device(f\"cuda:{i}\") for i in range(NGPU)]\n",
    "if NGPU == 0:\n",
    "    sys.exit(\"No CUDA GPU visible – aborting.\")\n",
    "\n",
    "# ───────────────── Sampler helpers ──────────────────────────\n",
    "\n",
    "def cvine_corr(d, a=5.0, b=2.0):\n",
    "    \"\"\"C-vine correlation sampler in FP32\"\"\"\n",
    "    beta = Beta(torch.tensor([a], device=\"cuda\"), torch.tensor([b], device=\"cuda\"))\n",
    "    P = torch.eye(d, device=\"cuda\")\n",
    "    for k in range(d - 1):\n",
    "        for i in range(k + 1, d):\n",
    "            rho = 2 * beta.sample().item() - 1.0\n",
    "            for m in range(k - 1, -1, -1):\n",
    "                rho = rho * math.sqrt((1 - P[m,i]**2)*(1 - P[m,k]**2)) + P[m,i]*P[m,k]\n",
    "            P[k,i] = P[i,k] = rho\n",
    "    ev, evec = torch.linalg.eigh(P)\n",
    "    P_corr = evec @ torch.diag(torch.clamp(ev, min=1e-6)) @ evec.T\n",
    "    return P_corr\n",
    "\n",
    "\n",
    "def fg_sample():\n",
    "    z = np.random.normal(0.5, 0.5, N_ASSETS)\n",
    "    return dict(\n",
    "        S0=100 * np.exp(z),\n",
    "        sigma=np.random.uniform(0.0, 1.0, N_ASSETS),\n",
    "        T=(np.random.randint(1, 44)**2) / 252.0,\n",
    "        rho=cvine_corr(N_ASSETS).cpu().numpy(),\n",
    "        K=100.0,\n",
    "        r=R_RATE\n",
    "    )\n",
    "\n",
    "# ──────────── Brownian bridge transformer ───────────────────\n",
    "\n",
    "def brownian_bridge(increments):\n",
    "    \"\"\"Simple Brownian-bridge reordering\"\"\"\n",
    "    order = [increments.shape[1] - 1] + list(range(increments.shape[1] - 1))\n",
    "    return increments[:, order, :]\n",
    "\n",
    "# ──────────── QMC + Antithetic path generator ────────────────\n",
    "\n",
    "def generate_qmc_paths(m, n_steps, d, device):\n",
    "    \"\"\"Generate Sobol + antithetic normal increments with Brownian bridge.\"\"\"\n",
    "    engine = SobolEngine(d * n_steps, scramble=True)\n",
    "    # draw half the uniforms, append antithetic, move to GPU\n",
    "    u = engine.draw(m // 2, dtype=torch.float32)\n",
    "    u = torch.cat([u, 1.0 - u], dim=0).to(device)\n",
    "    # clamp to avoid exact 0/1 -> inf in icdf\n",
    "    u = u.clamp(min=1e-6, max=1.0 - 1e-6)\n",
    "    normals = Normal(0.,1.).icdf(u).view(m, n_steps, d)\n",
    "    return brownian_bridge(normals)\n",
    "\n",
    "# ──────────── Raw MC price (no CV), chunked ──────────────────\n",
    "\n",
    "@torch.no_grad()\n",
    "def price_mc(params, n_paths, n_steps, *, return_se=False):\n",
    "    \"\"\" MC with control variate: raw price + CV correction \"\"\"\n",
    "    # 1) Raw MC payoff and SE\n",
    "    disc, se = price_mc_raw(params, n_paths, n_steps)\n",
    "    raw_price = torch.mean(disc).item()\n",
    "\n",
    "    # 2) Monte Carlo estimate of control variate: sum of individual call payoffs\n",
    "    per_gpu = n_paths // NGPU\n",
    "    ctrl_vals = []\n",
    "    for dev in DEVICES:\n",
    "        for offset in range(0, per_gpu, CHUNK_PATH):\n",
    "            chunk = min(CHUNK_PATH, per_gpu - offset)\n",
    "            Z = generate_qmc_paths(chunk, n_steps, N_ASSETS, dev)\n",
    "            # simulate terminal asset prices\n",
    "            S0    = torch.tensor(params['S0'],    device=dev)\n",
    "            sigma = torch.tensor(params['sigma'], device=dev)\n",
    "            T     = torch.tensor(params['T'],     device=dev)\n",
    "            rho   = torch.tensor(params['rho'],   device=dev)\n",
    "            K = params['K']; r = params['r']\n",
    "            dt    = T / n_steps\n",
    "            mu    = (r - 0.5 * sigma**2)\n",
    "            sig   = sigma\n",
    "            chol  = torch.linalg.cholesky(rho)\n",
    "\n",
    "            logS = torch.log(S0).expand(chunk, N_ASSETS).clone()\n",
    "            sqrt_dt = math.sqrt(dt.item())\n",
    "            for k in range(n_steps):\n",
    "                dW = Z[:,k,:] @ chol.T\n",
    "                logS = logS + mu * dt + sig * sqrt_dt * dW\n",
    "            ST    = torch.exp(logS)  # [chunk, assets]\n",
    "            calls = torch.clamp(ST - K, 0.).sum(dim=1)  # [chunk]\n",
    "            ctrl_vals.append(calls.cpu())\n",
    "    ctrl_all = torch.cat(ctrl_vals)  # length n_paths\n",
    "    mc_ctrl   = ctrl_all.mean().item()\n",
    "\n",
    "    # 3) Analytical expectation of sum-of-calls\n",
    "    E_ctrl = sum(\n",
    "        bs_call_price(params['S0'][j], params['K'], params['r'],\n",
    "                      params['T'], params['sigma'][j])\n",
    "        for j in range(N_ASSETS)\n",
    "    )\n",
    "\n",
    "    # 4) Control variate correction\n",
    "    price_cv = raw_price + (E_ctrl - mc_ctrl)\n",
    "    if return_se:\n",
    "        return price_cv, se\n",
    "    return price_cv\n",
    "\n",
    "# ────────── main + quick test ──────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(SEED_BASE)\n",
    "    torch.manual_seed(SEED_BASE)\n",
    "    params = fg_sample()\n",
    "    price, se = price_mc(params, n_paths=100_000_000, n_steps=64, return_se=True)\n",
    "    print(f\"price = {price:.6f}, SE = {se:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
