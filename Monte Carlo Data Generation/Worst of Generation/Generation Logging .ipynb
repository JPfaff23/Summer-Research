{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebd52829",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418c38b2",
   "metadata": {},
   "source": [
    "## Py File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "make_worst_of.py\n",
    "  • multi‑GPU, single‑process, FP16+TF32 Monte‑Carlo\n",
    "  • Chunk‑safe up to 100 M paths on 4×12 GiB GPUs\n",
    "  • Exports price & Greeks with sampling‑error columns\n",
    "\"\"\"\n",
    "\n",
    "import os, math, time, argparse, pathlib, sys\n",
    "import numpy as np, pandas as pd, torch, pyarrow as pa, pyarrow.parquet as pq\n",
    "from torch.distributions import Beta\n",
    "\n",
    "# ──────────────────────────── knobs ────────────────────────────\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark       = True\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "N_ASSETS   = 3\n",
    "R_RATE     = 0.03\n",
    "EPS_REL    = 1e-4\n",
    "SEED_BASE  = 42\n",
    "CHUNK_MAX  = 1_000_000   # flush Parquet every X rows\n",
    "CHUNK_PATH = 5_000_000   # inner GPU chunk size\n",
    "NGPU       = torch.cuda.device_count()\n",
    "DEVICES    = [torch.device(f\"cuda:{i}\") for i in range(NGPU)]\n",
    "\n",
    "if not NGPU:\n",
    "    sys.exit(\"No CUDA GPU visible – aborting.\")\n",
    "\n",
    "# ───────────────────── correlation sampler ─────────────────────\n",
    "\n",
    "def cvine_corr(d, a=5.0, b=2.0):\n",
    "    beta = Beta(torch.tensor([a], device=\"cuda\"), torch.tensor([b], device=\"cuda\"))\n",
    "    P = torch.eye(d, device=\"cuda\")\n",
    "    for k in range(d - 1):\n",
    "        for i in range(k + 1, d):\n",
    "            rho = 2 * beta.sample().item() - 1.0\n",
    "            for m in range(k - 1, -1, -1):\n",
    "                rho = rho * math.sqrt((1 - P[m, i]**2) * (1 - P[m, k]**2)) + P[m, i]*P[m, k]\n",
    "            P[k, i] = P[i, k] = rho\n",
    "    ev, evec = torch.linalg.eigh(P)\n",
    "    return evec @ torch.diag(torch.clamp(ev, min=1e-6)) @ evec.T\n",
    "\n",
    "\n",
    "def fg_sample():\n",
    "    z = np.random.normal(0.5, math.sqrt(0.25), N_ASSETS)\n",
    "    return dict(\n",
    "        S0=100 * np.exp(z),\n",
    "        sigma=np.random.uniform(0.0, 1.0, N_ASSETS),\n",
    "        T=(np.random.randint(1, 44)**2)/252.0,\n",
    "        rho=cvine_corr(N_ASSETS).cpu().numpy(),\n",
    "        K=100.0,\n",
    "        r=R_RATE\n",
    "    )\n",
    "\n",
    "# ────────────────── Monte‑Carlo building blocks ─────────────────\n",
    "\n",
    "@torch.no_grad()\n",
    "def terminal_prices(S0, sigma, T, rho, *, n_paths, n_steps, r, Z=None):\n",
    "    device = S0.device\n",
    "    dt = torch.full((), T / n_steps, dtype=torch.float16, device=device)\n",
    "    mu     = (r - 0.5 * sigma**2).to(torch.float16)\n",
    "    sig    = sigma.to(torch.float16)\n",
    "    sqrt_dt= torch.sqrt(dt)\n",
    "    chol   = torch.linalg.cholesky(rho).to(torch.float16)\n",
    "\n",
    "    out = torch.empty(n_paths, N_ASSETS, dtype=torch.float16, device=device)\n",
    "    for start in range(0, n_paths, CHUNK_PATH):\n",
    "        end = min(start + CHUNK_PATH, n_paths)\n",
    "        m   = end - start\n",
    "        Zi  = Z[start:end] if Z is not None else torch.randn(\n",
    "              m, n_steps, N_ASSETS, device=device, dtype=torch.float16)\n",
    "        logS = torch.log(S0).expand(m, N_ASSETS).clone().to(torch.float16)\n",
    "        for k in range(n_steps):\n",
    "            dW    = Zi[:, k] @ chol.T\n",
    "            logS += mu * dt + sig * sqrt_dt * dW\n",
    "        out[start:end] = torch.exp(logS)\n",
    "    return out\n",
    "\n",
    "\n",
    "def price_mc(params, n_paths, n_steps, Z=None, *, return_payoff=False, return_se=False):\n",
    "    \"\"\"Monte-Carlo worst-of price with optional payoff / SE outputs.\"\"\"\n",
    "    per_gpu = n_paths // NGPU\n",
    "    payoffs = []\n",
    "    for g, dev in enumerate(DEVICES):\n",
    "        S0    = torch.tensor(params['S0'],    device=dev)\n",
    "        sigma = torch.tensor(params['sigma'], device=dev)\n",
    "        T     = torch.tensor(params['T'],     device=dev)\n",
    "        rho   = torch.tensor(params['rho'],   device=dev)\n",
    "        K, r  = params['K'], params['r']\n",
    "        Zi    = Z[g] if Z is not None else None\n",
    "        n_gpu = Zi.shape[0] if Zi is not None else per_gpu\n",
    "\n",
    "        ST = terminal_prices(S0, sigma, T, rho,\n",
    "                             n_paths=n_gpu, n_steps=n_steps, r=r, Z=Zi)\n",
    "        payoffs.append(torch.clamp(ST.min(dim=1).values - K, 0.).cpu())\n",
    "\n",
    "    pay = torch.cat(payoffs)\n",
    "    disc_pay = math.exp(-params['r'] * params['T']) * pay\n",
    "\n",
    "    # both payoff and SE requested\n",
    "    if return_payoff and return_se:\n",
    "        se = disc_pay.std(unbiased=True).item() / math.sqrt(n_paths)\n",
    "        return disc_pay, se\n",
    "\n",
    "    if return_payoff:\n",
    "        return disc_pay\n",
    "\n",
    "    price = disc_pay.mean().item()\n",
    "    if return_se:\n",
    "        se = disc_pay.std(unbiased=True).item() / math.sqrt(n_paths)\n",
    "        return price, se\n",
    "    return price\n",
    "\n",
    "def greeks_fd(params, n_paths, n_steps):\n",
    "    half = (n_paths // NGPU) // 2\n",
    "    Zpairs = [torch.randn(half, n_steps, N_ASSETS, device=d, dtype=torch.float16)\n",
    "              for d in DEVICES]\n",
    "\n",
    "    pay, base_se = price_mc(params, n_paths, n_steps, Zpairs,\n",
    "                            return_payoff=True, return_se=True)\n",
    "    base = pay.mean().item()\n",
    "\n",
    "    delta, delta_se = np.empty(N_ASSETS), np.empty(N_ASSETS)\n",
    "    vega,  vega_se  = np.empty(N_ASSETS), np.empty(N_ASSETS)\n",
    "    gamma, gamma_se = np.empty(N_ASSETS), np.empty(N_ASSETS)\n",
    "\n",
    "    for i in range(N_ASSETS):\n",
    "        hS = max(EPS_REL * params['S0'][i],    1e-6)\n",
    "        hV = max(EPS_REL * params['sigma'][i], 1e-6)\n",
    "\n",
    "        # Δ & Γ\n",
    "        p_up = {**params, 'S0': params['S0'].copy()}; p_up['S0'][i] += hS\n",
    "        p_dn = {**params, 'S0': params['S0'].copy()}; p_dn['S0'][i] -= hS\n",
    "        pu = price_mc(p_up, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "        pd = price_mc(p_dn, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "\n",
    "        paths_d = (pu - pd)/(2*hS)\n",
    "        delta[i]    = paths_d.mean().item()\n",
    "        delta_se[i] = paths_d.std(unbiased=True).item()/math.sqrt(n_paths)\n",
    "\n",
    "        paths_g = (pu - 2*pay + pd)/(hS*hS)\n",
    "        gamma[i]    = paths_g.mean().item()\n",
    "        gamma_se[i] = paths_g.std(unbiased=True).item()/math.sqrt(n_paths)\n",
    "\n",
    "        # ν bump\n",
    "        p_up = {**params, 'sigma': params['sigma'].copy()}; p_up['sigma'][i] += hV\n",
    "        p_dn = {**params, 'sigma': params['sigma'].copy()}; p_dn['sigma'][i] -= hV\n",
    "        pu = price_mc(p_up, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "        pd = price_mc(p_dn, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "\n",
    "        paths_v = (pu - pd)/(2*hV)\n",
    "        vega[i]    = paths_v.mean().item()\n",
    "        vega_se[i] = paths_v.std(unbiased=True).item()/math.sqrt(n_paths)\n",
    "\n",
    "    # ρ\n",
    "    hR = max(EPS_REL * abs(params['r']), 1e-6)\n",
    "    pu = price_mc({**params, 'r': params['r']+hR}, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "    pd = price_mc({**params, 'r': params['r']-hR}, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "    paths_r = (pu-pd)/(2*hR)\n",
    "    rho_v   = paths_r.mean().item()\n",
    "    rho_se  = paths_r.std(unbiased=True).item()/math.sqrt(n_paths)\n",
    "\n",
    "    # θ\n",
    "    hT = max(EPS_REL*params['T'],1e-6)\n",
    "    pu = price_mc({**params,'T':params['T']+hT}, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "    pd = price_mc({**params,'T':max(1e-6,params['T']-hT)}, n_paths, n_steps, Zpairs, return_payoff=True)\n",
    "    paths_t = (pu-pd)/(2*hT)\n",
    "    theta   = paths_t.mean().item()\n",
    "    theta_se= paths_t.std(unbiased=True).item()/math.sqrt(n_paths)\n",
    "\n",
    "    return (base, base_se,\n",
    "            delta, delta_se,\n",
    "            vega,  vega_se,\n",
    "            gamma, gamma_se,\n",
    "            rho_v, rho_se,\n",
    "            theta, theta_se)\n",
    "\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--rows',        type=int, default=100000)\n",
    "    ap.add_argument('--paths',       type=int, default=10000)\n",
    "    ap.add_argument('--steps',       type=int, default=64)\n",
    "    ap.add_argument('--seed_offset', type=int, default=0)\n",
    "    ap.add_argument('--out',         type=str, default='data.parquet')\n",
    "    ap.add_argument('--no_chunking', action='store_true',\n",
    "                    help=\"run all rows in one chunk for timing\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    np.random.seed(SEED_BASE + args.seed_offset)\n",
    "    torch.manual_seed(SEED_BASE + args.seed_offset)\n",
    "\n",
    "    out_path   = pathlib.Path(args.out)\n",
    "    pa_writer, first = None, True\n",
    "    chunk_size = args.rows if args.no_chunking else CHUNK_MAX\n",
    "\n",
    "    total_start = time.time()\n",
    "    sample_time = mc_time = 0.0\n",
    "    rows_left   = args.rows\n",
    "\n",
    "    print(f\"⏱️  Starting Monte-Carlo for {args.rows:,} rows (chunk_size={chunk_size})…\", flush=True)\n",
    "\n",
    "    while rows_left:\n",
    "        batch = min(rows_left, chunk_size)\n",
    "        recs  = []\n",
    "        for _ in range(batch):\n",
    "            ts = time.perf_counter(); p = fg_sample(); sample_time += time.perf_counter()-ts\n",
    "            tm = time.perf_counter()\n",
    "            (pr,pr_se, d,d_se,v,v_se,g,g_se, rv,rv_se, th,th_se) = \\\n",
    "                greeks_fd(p, args.paths, args.steps)\n",
    "            mc_time += time.perf_counter()-tm\n",
    "            rec = {\n",
    "                **{f\"S0_{i}\": p[\"S0\"][i]   for i in range(N_ASSETS)},\n",
    "                **{f\"sigma_{i}\": p[\"sigma\"][i] for i in range(N_ASSETS)},\n",
    "                \"price\":pr, \"price_se\":pr_se,\n",
    "                **{f\"delta_{i}\":d[i]       for i in range(N_ASSETS)},\n",
    "                **{f\"delta_se_{i}\":d_se[i] for i in range(N_ASSETS)},\n",
    "                **{f\"vega_{i}\":v[i]        for i in range(N_ASSETS)},\n",
    "                **{f\"vega_se_{i}\":v_se[i]  for i in range(N_ASSETS)},\n",
    "                **{f\"gamma_{i}\":g[i]       for i in range(N_ASSETS)},\n",
    "                **{f\"gamma_se_{i}\":g_se[i] for i in range(N_ASSETS)},\n",
    "                \"rho\":rv, \"rho_se\":rv_se,\n",
    "                \"theta\":th, \"theta_se\":th_se,\n",
    "                \"T\":p[\"T\"], \"r\":p[\"r\"]\n",
    "            }\n",
    "            recs.append(rec)\n",
    "        tbl = pa.Table.from_pylist(recs)\n",
    "        if first:\n",
    "            pa_writer=pq.ParquetWriter(str(out_path),tbl.schema,compression='zstd')\n",
    "            first=False\n",
    "        pa_writer.write_table(tbl)\n",
    "        rows_left -= batch\n",
    "\n",
    "    pa_writer.close()\n",
    "    total_time = time.time() - total_start\n",
    "    print(f\"Total sampler time: {sample_time:.1f}s, MC+Greeks time: {mc_time:.1f}s\",flush=True)\n",
    "    print(f\"Wrote {args.rows:,} rows → {out_path} in {total_time:.1f}s on {NGPU} GPU(s)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29571458",
   "metadata": {},
   "source": [
    "## Base SH file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e7e62f",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_timing\n",
    "#SBATCH --output=WOF_%j.out\n",
    "#SBATCH --time=1:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         10000 \\\n",
    "       --paths        10000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          test.parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16891717",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c2bba",
   "metadata": {},
   "source": [
    "5 million rows by 10,000 paths  -- 61192765\n",
    "\n",
    "Way to much noise in Greeks - Using finite differencing for greeks is basically unusable \n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Train_timing\n",
    "#SBATCH --output=WOF_Train_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         5000000 \\\n",
    "       --paths        10000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Train.parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f143c7b",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08486ec",
   "metadata": {},
   "source": [
    "500,000 rows by 10,000 paths - 61192186\n",
    "\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Validation10k_timing\n",
    "#SBATCH --output=WOF_Validation10k_%j.out\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         500000 \\\n",
    "       --paths        10000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Validtion10k.parquet\n",
    "\n",
    "500,000 rows by 50,000 paths - 61192297\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Validation50k_timing\n",
    "#SBATCH --output=WOF_Validation50k_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         500000 \\\n",
    "       --paths        50000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Validtion50k.parquet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a538f29",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783b802",
   "metadata": {},
   "source": [
    "500 rows by 10 mil paths - 61192451\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Test_10M_timing\n",
    "#SBATCH --output=WOF_Test_10M_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         500 \\\n",
    "       --paths        10000000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Test10M.parquet\n",
    "\n",
    "\n",
    "\n",
    "500 rows by 100 mil paths - 61192471\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Test_100M_timing\n",
    "#SBATCH --output=WOF_Test_100M_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF.py \\\n",
    "       --rows         500 \\\n",
    "       --paths        100000000 \\\n",
    "       --steps        64 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Test100M.parquet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e91c8",
   "metadata": {},
   "source": [
    "# New Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fd134",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Train_timing\n",
    "#SBATCH --output=WOF_Train_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF_No_Step.py \\\n",
    "       --rows         5000000 \\\n",
    "       --paths        10000 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Train.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a78030",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Validation10k_timing\n",
    "#SBATCH --output=WOF_Validation10k_%j.out\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF_No_Step.py \\\n",
    "       --rows         500000 \\\n",
    "       --paths        10000 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Validtion10k.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf96e59",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --job-name=WOF_Test_100M_timing\n",
    "#SBATCH --output=WOF_Test_100M_%j.out\n",
    "#SBATCH --time=168:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --cpus-per-task=16\n",
    "#SBATCH --mem=64G\n",
    "#SBATCH --gres=gpu:4\n",
    "#SBATCH --account=def-lstentof\n",
    "#SBATCH --mail-user=jpfaff23@uwo.ca\n",
    "#SBATCH --mail-type=END,FAIL\n",
    "\n",
    "set -euo pipefail\n",
    "module --force purge\n",
    "module load StdEnv/2023 python/3.10 cuda/12.2 arrow/14.0.1\n",
    "export PYTHONPATH=$SCRATCH/.local/lib/python3.10/site-packages:$PYTHONPATH\n",
    "export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export OPENBLAS_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "export TORCH_NUM_THREADS=$SLURM_CPUS_PER_TASK\n",
    "\n",
    "cd $SCRATCH\n",
    "python -u ~/WOF_No_Step.py \\\n",
    "       --rows         500 \\\n",
    "       --paths        100000000 \\\n",
    "       --seed_offset  0 \\\n",
    "       --out          Test100M.parquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
