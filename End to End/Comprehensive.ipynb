{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e35a6d",
   "metadata": {},
   "source": [
    "# Overview of Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860a209",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b048c3",
   "metadata": {},
   "source": [
    "# Data Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a34af",
   "metadata": {},
   "source": [
    "# Explanation/ Reasoning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266ed6d",
   "metadata": {},
   "source": [
    "## Data Generation for Worst-of Basket Options (Train & Test)\n",
    "\n",
    "## 1) Product & Pricing Model\n",
    "\n",
    "We generate labels for a **European call on the worst-of an equity basket** with strike $K$:\n",
    "\n",
    "$$\n",
    "\\text{payoff} \\;=\\; \\max\\!\\big(0,\\, \\min_i S_i(T) - K\\big).\n",
    "$$\n",
    "\n",
    "Under the risk-neutral measure, each asset $S_i$ follows geometric Brownian motion with **flat** vol and **constant** short rate $r$:\n",
    "\n",
    "$$\n",
    "\\frac{dS_i(t)}{S_i(t)} \\;=\\; r\\,dt \\;+\\; \\sigma_i\\,dW_i(t), \n",
    "\\qquad \\mathbb{E}[dW_i\\,dW_j]=\\rho_{ij}\\,dt .\n",
    "$$\n",
    "\n",
    "For a maturity $T$, terminal prices along a Monte-Carlo path are simulated in log-space:\n",
    "\n",
    "$$\n",
    "S_i(T) \\;=\\; \\exp\\!\\Big(\\log S_i(0) + (r-\\tfrac12\\sigma_i^2)T + \\sigma_i\\sqrt{T}\\,Y_i\\Big),\n",
    "$$\n",
    "\n",
    "where $Y \\sim \\mathcal{N}(0,\\Sigma)$ with $\\Sigma$ built from a sampled correlation matrix $\\rho$, and the discounted payoff is $e^{-rT}$ times the expression above.\n",
    "\n",
    "**Why worst-of?** It yields a moderately high-dimensional but still tractable example; its valuation is typically **Monte-Carlo-only**, and it exhibits strong curvature for **short-dated, near-ATM** scenarios—exactly the kind of landscape that exposes strengths/weaknesses in data sampling. This mirrors the canonical setup in Ferguson & Green (2018).&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Scenario Sampling Strategy (Inputs → Features)\n",
    "\n",
    "We follow the *“random scenarios, broad but purposeful coverage”* philosophy from Ferguson & Green, adapted to your implementation:\n",
    "\n",
    "* **Spots $S_{0,i}$:**\n",
    "  Sampled as $100\\cdot e^Z$ with $Z\\sim \\mathcal{N}(\\mu=0.5,\\sigma^2=0.25)$.\n",
    "  *Rationale:* lognormal draws keep prices positive and concentrate mass near realistic levels while exploring a wide range. (Same spirit as the paper.)&#x20;\n",
    "\n",
    "* **Volatilities $\\sigma_i$:**\n",
    "  Uniform on $[0.05, 0.8]$ (paper used $[0,1]$).\n",
    "  *Rationale:* trim extremely low vols (numerical fragility for Greeks) and extremely high vols (rare in practice) while still covering a broad regime.&#x20;\n",
    "\n",
    "* **Maturity $T$:**\n",
    "  $T = U^2/252$ with $U\\sim\\text{Uniform}\\{1,\\dots,43\\}$.\n",
    "  *Rationale:* **Quadratic** mapping biases samples to **shorter maturities**—where convexity is highest and worst-of options change rapidly—matching the paper’s emphasis on short-dated richness.&#x20;\n",
    "\n",
    "* **Correlations $\\rho$:**\n",
    "  Drawn via a **C-vine** scheme with $\\tilde{\\rho}=2\\cdot \\text{Beta}(5,2)-1$ (elementwise), then projected to the nearest PSD matrix (eigenvalue clip) before Cholesky.\n",
    "  *Rationale:* produces realistic, varied correlation structures over $[-1,1]$ while ensuring positive-definiteness for multivariate normals; this mirrors the paper’s C-vine approach.&#x20;\n",
    "\n",
    "* **Strike & rate:**\n",
    "  $K=100$ fixed; $r=0.03$ (paper used $r\\approx 0$ for simplicity; using $3\\%$ is a benign generalization).\n",
    "\n",
    "> **Independence assumption.** Inputs are sampled independently (except correlations), as in the paper’s base setup; this is fast and broad-coverage. In production, one could add stratification/importance sampling to emphasize boundary/sensitive regions.&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Monte-Carlo Engine (Paths → Labels)\n",
    "\n",
    "* **Multi-GPU + chunking.**\n",
    "  A total of `n_paths` is split across visible GPUs; each device processes chunks of size `SIM_CHUNK` to control memory.\n",
    "\n",
    "* **Terminal draw:**\n",
    "  For each chunk, draw $Z\\sim\\mathcal{N}(0,I)$, map to correlated $Y=ZL^\\top$ using **Cholesky** $L=\\text{chol}(\\rho)$, then form $S(T)$ with the closed-form GBM formula above.\n",
    "\n",
    "* **Estimator:**\n",
    "  $\\widehat{V}=\\exp(-rT)\\cdot \\frac1{N}\\sum_{k=1}^N \\max(0,\\min_i S^{(k)}_i(T)-K)$.\n",
    "  The code also tracks the **standard error** from the sample variance to quantify MC noise per scenario.\n",
    "\n",
    "* **Precision:**\n",
    "  Pricing uses CUDA autocast to `float16` for speed (inside the path loop) but returns single-precision CPU scalars; Greeks routines run in **float64** for stability.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Determinism & Seeding (CRNs)\n",
    "\n",
    "To make finite-difference (FD) Greeks **variance-reduced and reproducible**, we use **Common Random Numbers (CRN)**: the *same* Gaussian draws drive up/down bumps.\n",
    "\n",
    "* **Seed formula:**\n",
    "  `manual_seed = base_seed + 1_000_003*dev_idx + chunk_idx`.\n",
    "  *Rationale:* the large prime `1,000,003` guarantees different, non-overlapping subsequences per **device** and **chunk**, while the per-scenario `base_seed` enforces run-to-run reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Greeks in the Dataset (Why we store both)\n",
    "\n",
    "Although this section focuses on generation rather than learning, it’s useful context:\n",
    "\n",
    "* **FD Δ/ν with CRN (`delta_vega_fd_crn`)**\n",
    "  Central bumps with **relative step** $h=\\max(\\text{rel}\\cdot x, 10^{-6})$. Reuse the same $Y$ for up/down to slash variance.\n",
    "\n",
    "* **AAD Δ/ν (`delta_vega_aad`)**\n",
    "  Build a scalar price and call `torch.autograd.grad(price, (S0, σ))` to get per-scenario **sensitivities** in one reverse pass. Accumulate chunk-wise to form averages.\n",
    "\n",
    "These labels support your later comparisons (FD vs AAD speed/accuracy; model-based gradients vs MC).\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Train vs Test Configurations\n",
    "\n",
    "### 6.1 Train (large rows, moderate paths)\n",
    "\n",
    "* **Defaults:** `rows=5,000,000`, `paths=1,000,000`.\n",
    "* **Purpose:** generate a **broad** training corpus where each row’s price/Greeks carry modest MC noise, but the sheer *volume* of scenarios covers the state space.\n",
    "* **Outputs per row:**\n",
    "\n",
    "  * Inputs: $\\{S0_i\\}$, $\\{\\sigma_i\\}$, pairwise $\\rho_{ij}$, $K, r, T$.\n",
    "  * Labels: price, price standard error, **FD** $\\Delta_i$, $\\nu_i$, and (optionally) **AAD** $\\Delta_i$, $\\nu_i$.\n",
    "* **I/O:** Streamed appends to a single Parquet via `pyarrow` with compression; periodic **timing checkpoints** to CSV + cumulative runtime plot.\n",
    "\n",
    "### 6.2 Test (small rows, ultra-high paths)\n",
    "\n",
    "* **Defaults:** `rows=50,000`, `paths=100,000,000`.\n",
    "* **Purpose:** produce a **“gold”** test set with *negligible MC noise*—a faithful ground truth for out-of-sample evaluation and for quantifying how well learned models beat MC noise.\n",
    "* **Provenance:** This mirrors the paper’s design: tiny test set, **huge** per-row path count (e.g., 100M paths → $\\sim$ 1-cent accuracy) to decouple test error from MC randomness.&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Why These Distributions? (Design Rationale)\n",
    "\n",
    "* **Short maturities emphasized.** Worst-of payoffs are most nonlinear near expiry; a quadratic map from integers ($U^2/252$) oversamples that region to give the learner rich curvature.&#x20;\n",
    "* **Wide spans for $S_0$, $\\sigma$, $\\rho$.** Keeps the network honest: it must interpolate across realistic but varied regimes (low/high vols, negative/positive correlations).&#x20;\n",
    "* **Independence (first pass).** Simple, fast, and surprisingly effective; the paper shows that **more, noisier** training examples can outperform **fewer, cleaner** ones—the NN learns to average away MC noise. Your **Train**/**Test** split reflects this insight.&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Implementation Notes & Safeguards\n",
    "\n",
    "* **Correlation PSD fix:** After C-vine sampling, eigenvalues are clipped to ensure a valid covariance (required for Cholesky).\n",
    "* **Bump floors:** FD bumps use $\\max(\\text{rel}\\cdot x,10^{-6})$ to avoid tiny denominators and catastrophic cancellation.\n",
    "* **Mixed precision where safe:** MC price loops run under autocast; all Greeks are float64.\n",
    "* **Streaming Parquet:** `CHUNK_MAX` rows per table to bound memory; one **schema** across batches for a single file.\n",
    "\n",
    "---\n",
    "\n",
    "## 9) Differences vs. Ferguson & Green (and why they’re okay)\n",
    "\n",
    "| Aspect      | Paper                | This code             | Comment                                                       |\n",
    "| ----------- | -------------------- | --------------------- | ------------------------------------------------------------- |\n",
    "| Basket size | 6 names              | 3 names               | Dimensionality reduced for dev speed; methodology identical.  |\n",
    "| Vol range   | $[0,1]$              | $[0.05,0.8]$          | Slight trimming for numerical stability; still broad.         |\n",
    "| Rate $r$    | \\~0%                 | 3%                    | Adds realism; GBM formula unchanged.                          |\n",
    "| Test design | 5k rows @ 100M paths | 50k rows @ 100M paths | Same principle: tiny noise, high-fidelity labels.             |\n",
    "\n",
    "---\n",
    "\n",
    "## 10) Column Schema (what lands in Parquet)\n",
    "\n",
    "* **Features:**\n",
    "  `S0_0..S0_{N-1}`, `sigma_0..sigma_{N-1}`, `corr_i_j` (upper triangle), `K`, `r`, `T`\n",
    "* **Labels & diagnostics:**\n",
    "  `price`, `price_se`, `delta_0..delta_{N-1}`, `vega_0..vega_{N-1}`, and (if enabled) `delta_aad_*`, `vega_aad_*`\n",
    "* **Instrumentation (separate files):**\n",
    "  `timelog.csv` (cumulative times), and PNG plot comparing **FD vs AAD** runtime scaling.\n",
    "\n",
    "---\n",
    "\n",
    "## 11) Summary\n",
    "\n",
    "* The **Train** program creates **millions** of broadly sampled scenarios with **moderate** path counts per row—cheap, dense coverage whose MC noise a neural net can learn to smooth.\n",
    "* The **Test** program creates a **small** but **ultra-accurate** set (100M paths/row) that isolates *true* generalization error from MC randomness.\n",
    "* The sampling distributions (lognormal spots, uniform vols, short-biased maturities, C-vine correlations) and the **CRN + AAD/FD** labeling directly follow the successful recipe documented by Ferguson & Green, adapted to your hardware and dimensionality.&#x20;\n",
    "\n",
    "---\n",
    "\n",
    "*Primary reference for methodology and sampling choices: Ferguson & Green (2018), “Deeply Learning Derivatives.”*&#x20;\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec1f5",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb60bf",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a72529a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Monte-Carlo for 5,000,000 rows …\n",
      "Sampling: 1200.47s | Pricing: 22507.23s | FD: 54858.84s | AAD: 18505.20s\n",
      "TOTAL (wall): 97596.84s for 5,000,000 rows @ 1,000,000 paths\n",
      "Wrote timing checkpoints → timelog.csv\n",
      "Wrote runtime plot → fd_vs_aad_runtime.png\n",
      "AAD becomes faster than FD (cumulative) at ~10,000 rows (FD=112.40s, AAD=38.14s).\n"
     ]
    }
   ],
   "source": [
    "import os, math, time, argparse, pathlib, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyarrow as pa, pyarrow.parquet as pq\n",
    "\n",
    "# Optional plotting/logging deps\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe for headless / servers\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# --------- global knobs ---------\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark       = True\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "N_ASSETS   = 3\n",
    "R_RATE     = 0.03\n",
    "SEED_BASE  = 42\n",
    "CHUNK_MAX  = 100_000                 # rows before flushing Parquet\n",
    "NGPU       = torch.cuda.device_count()\n",
    "DEVICES    = [torch.device(f\"cuda:{i}\") for i in range(NGPU)]\n",
    "SIM_CHUNK  = 1_000_000               # per-GPU sub-batch size (paths)\n",
    "\n",
    "if not NGPU:\n",
    "    sys.exit(\"No CUDA GPU visible – aborting.\")\n",
    "\n",
    "# --------- correlation sampler ---------\n",
    "def cvine_corr_np(d, a: float = 5.0, b: float = 2.0) -> torch.Tensor:\n",
    "    P = np.eye(d)\n",
    "    for k in range(d - 1):\n",
    "        for i in range(k + 1, d):\n",
    "            rho = 2.0 * np.random.beta(a, b) - 1.0\n",
    "            for m in range(k - 1, -1, -1):\n",
    "                rho = rho * np.sqrt((1 - P[m, i] ** 2) * (1 - P[m, k] ** 2)) + P[m, i] * P[m, k]\n",
    "            P[k, i] = P[i, k] = rho\n",
    "    ev, evec = np.linalg.eigh(P)\n",
    "    P = evec @ np.diag(np.clip(ev, 1e-6, None)) @ evec.T\n",
    "    return torch.as_tensor(P, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "# --------- random scenario generator ---------\n",
    "def fg_sample():\n",
    "    z     = np.random.normal(0.5, math.sqrt(0.25), N_ASSETS)\n",
    "    S0    = 100 * np.exp(z)\n",
    "    sigma = np.random.uniform(0.05, 0.8, N_ASSETS)\n",
    "    T     = (np.random.randint(1, 44) ** 2) / 252.0\n",
    "    return dict(S0=S0.astype(np.float32), sigma=sigma.astype(np.float32),\n",
    "                T=float(T), rho=cvine_corr_np(N_ASSETS), K=100.0, r=R_RATE)\n",
    "\n",
    "# --------- helpers ---------\n",
    "def _split_across_devices(total: int, ndev: int):\n",
    "    base = total // ndev\n",
    "    rem  = total % ndev\n",
    "    return [base + (1 if i < rem else 0) for i in range(ndev)]\n",
    "\n",
    "@torch.no_grad()\n",
    "def terminal_prices(S0, sigma, T, rho, *, n_paths, r, device, gen=None):\n",
    "    L = torch.linalg.cholesky(rho.to(device))\n",
    "    Z = torch.randn(n_paths, N_ASSETS, device=device, generator=gen)\n",
    "    with torch.autocast('cuda', dtype=torch.float16):\n",
    "        drift     = (r - 0.5 * sigma**2) * T\n",
    "        diffusion = sigma * math.sqrt(T) * (Z @ L.T)\n",
    "        return torch.exp(torch.log(S0) + drift + diffusion)\n",
    "\n",
    "# --------- streaming MC price (fast path) ---------\n",
    "def price_mc(params, n_paths, return_se=False):\n",
    "    counts      = _split_across_devices(n_paths, NGPU)\n",
    "    total_sum   = 0.0\n",
    "    total_sumsq = 0.0\n",
    "    disc        = math.exp(-float(params['r']) * float(params['T']))\n",
    "\n",
    "    for dev, count in zip(DEVICES, counts):\n",
    "        if count == 0: continue\n",
    "        S0    = torch.tensor(params['S0'],    device=dev)\n",
    "        sigma = torch.tensor(params['sigma'], device=dev)\n",
    "        T     = torch.tensor(params['T'],     device=dev)\n",
    "        r     = torch.tensor(params['r'],     device=dev)\n",
    "        K     = torch.tensor(params['K'],     device=dev)\n",
    "\n",
    "        for offset in range(0, count, SIM_CHUNK):\n",
    "            sz  = min(SIM_CHUNK, count - offset)\n",
    "            ST  = terminal_prices(S0, sigma, T, params['rho'], n_paths=sz, r=r, device=dev)\n",
    "            pay = torch.clamp(ST.min(dim=1).values - K, 0.0)\n",
    "            arr = (disc * pay).float().cpu().numpy()\n",
    "            total_sum   += arr.sum()\n",
    "            total_sumsq += (arr * arr).sum()\n",
    "\n",
    "    mean = total_sum / n_paths\n",
    "    if not return_se:\n",
    "        return mean\n",
    "    var  = (total_sumsq / n_paths) - mean * mean\n",
    "    se   = math.sqrt(max(var, 0.0) / n_paths)\n",
    "    return mean, se\n",
    "\n",
    "# ===================== FD Δ & ν WITH CRN =====================\n",
    "def delta_vega_fd_crn(params, n_paths, rel=1e-4, base_seed=None):\n",
    "    \"\"\"\n",
    "    FD Δ/ν using common random numbers (same Z/Y reused for up/down).\n",
    "    float64 throughout; chunked + multi-GPU; deterministic with base_seed.\n",
    "    Returns (delta[N_ASSETS], vega[N_ASSETS]) as numpy float64 arrays.\n",
    "    \"\"\"\n",
    "    disc = math.exp(-float(params['r']) * float(params['T']))\n",
    "    delta_num = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "    vega_num  = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "\n",
    "    counts = _split_across_devices(n_paths, NGPU)\n",
    "    for dev_idx, (dev, count) in enumerate(zip(DEVICES, counts)):\n",
    "        if count == 0: continue\n",
    "\n",
    "        S0f  = torch.tensor(params['S0'],    dtype=torch.float64, device=dev)\n",
    "        sigf = torch.tensor(params['sigma'], dtype=torch.float64, device=dev)\n",
    "        Tf   = torch.tensor(float(params['T']), dtype=torch.float64, device=dev)\n",
    "        rf   = torch.tensor(float(params['r']), dtype=torch.float64, device=dev)\n",
    "        Kf   = torch.tensor(float(params['K']), dtype=torch.float64, device=dev)\n",
    "        L    = torch.linalg.cholesky(params['rho'].to(dev).to(torch.float64))\n",
    "\n",
    "        for chunk_idx, offset in enumerate(range(0, count, SIM_CHUNK)):\n",
    "            sz   = min(SIM_CHUNK, count - offset)\n",
    "\n",
    "            gen = None\n",
    "            if base_seed is not None:\n",
    "                gen = torch.Generator(device=dev)\n",
    "                gen.manual_seed(int(base_seed) + 1_000_003*dev_idx + chunk_idx)\n",
    "\n",
    "            Z = torch.randn(sz, N_ASSETS, dtype=torch.float64, device=dev, generator=gen)\n",
    "            Y = Z @ L.T\n",
    "\n",
    "            drift_b = (rf - 0.5 * sigf**2) * Tf\n",
    "            diff_b  = sigf * torch.sqrt(Tf) * Y\n",
    "\n",
    "            for i in range(N_ASSETS):\n",
    "                # Δ bump\n",
    "                hS   = float(max(rel * float(S0f[i].item()), 1e-6))\n",
    "                S_up = S0f.clone(); S_up[i] += hS\n",
    "                S_dn = S0f.clone(); S_dn[i] -= hS\n",
    "\n",
    "                ST_up = torch.exp(torch.log(S_up) + drift_b + diff_b)\n",
    "                ST_dn = torch.exp(torch.log(S_dn) + drift_b + diff_b)\n",
    "                pay_up = torch.clamp(ST_up.min(dim=1).values - Kf, 0.0)\n",
    "                pay_dn = torch.clamp(ST_dn.min(dim=1).values - Kf, 0.0)\n",
    "\n",
    "                delta_num[i] += (disc * (pay_up.sum().double() - pay_dn.sum().double()) / (2.0 * hS)).cpu().item()\n",
    "\n",
    "                # ν bump (reuse Y)\n",
    "                hV     = float(max(rel * float(sigf[i].item()), 1e-6))\n",
    "                sig_up = sigf.clone(); sig_up[i] += hV\n",
    "                sig_dn = sigf.clone(); sig_dn[i] -= hV\n",
    "\n",
    "                drift_up = (rf - 0.5 * sig_up**2) * Tf\n",
    "                diff_up  = sig_up * torch.sqrt(Tf) * Y\n",
    "                drift_dn = (rf - 0.5 * sig_dn**2) * Tf\n",
    "                diff_dn  = sig_dn * torch.sqrt(Tf) * Y\n",
    "\n",
    "                ST_vup  = torch.exp(torch.log(S0f) + drift_up + diff_up)\n",
    "                ST_vdn  = torch.exp(torch.log(S0f) + drift_dn + diff_dn)\n",
    "                pay_vup = torch.clamp(ST_vup.min(dim=1).values - Kf, 0.0)\n",
    "                pay_vdn = torch.clamp(ST_vdn.min(dim=1).values - Kf, 0.0)\n",
    "\n",
    "                vega_num[i]  += (disc * (pay_vup.sum().double() - pay_vdn.sum().double()) / (2.0 * hV)).cpu().item()\n",
    "\n",
    "    delta = delta_num / n_paths\n",
    "    vega  = vega_num  / n_paths\n",
    "    return delta, vega\n",
    "\n",
    "# ===================== AAD Δ & ν (float64, chunked) =====================\n",
    "def delta_vega_aad(params, n_paths, base_seed=None):\n",
    "    counts = _split_across_devices(n_paths, NGPU)\n",
    "    sum_dS = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "    sum_dV = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "\n",
    "    for dev_idx, (dev, count) in enumerate(zip(DEVICES, counts)):\n",
    "        if count == 0: continue\n",
    "        L  = torch.linalg.cholesky(params['rho'].to(dev).to(torch.float64))\n",
    "        Tf = torch.tensor(float(params['T']), dtype=torch.float64, device=dev)\n",
    "        rf = torch.tensor(float(params['r']), dtype=torch.float64, device=dev)\n",
    "        Kf = torch.tensor(float(params['K']), dtype=torch.float64, device=dev)\n",
    "\n",
    "        for chunk_idx, offset in enumerate(range(0, count, SIM_CHUNK)):\n",
    "            sz  = min(SIM_CHUNK, count - offset)\n",
    "\n",
    "            gen = None\n",
    "            if base_seed is not None:\n",
    "                gen = torch.Generator(device=dev)\n",
    "                gen.manual_seed(int(base_seed) + 1_000_003*dev_idx + chunk_idx)\n",
    "\n",
    "            # Leaf vars with grads\n",
    "            S0  = torch.tensor(params['S0'],    dtype=torch.float64, device=dev, requires_grad=True)\n",
    "            sig = torch.tensor(params['sigma'], dtype=torch.float64, device=dev, requires_grad=True)\n",
    "\n",
    "            Z = torch.randn(sz, N_ASSETS, dtype=torch.float64, device=dev, generator=gen)\n",
    "            Y = Z @ L.T\n",
    "\n",
    "            drift = (rf - 0.5 * sig**2) * Tf\n",
    "            diff  = sig * torch.sqrt(Tf) * Y\n",
    "            ST    = torch.exp(torch.log(S0) + drift + diff)\n",
    "            payoff = torch.clamp(ST.min(dim=1).values - Kf, 0.0)\n",
    "            price  = torch.exp(-rf * Tf) * payoff.mean()\n",
    "\n",
    "            dS, dV = torch.autograd.grad(price, (S0, sig), retain_graph=False, create_graph=False)\n",
    "            # accumulate sums (note: host transfer happens here)\n",
    "            sum_dS += dS.detach().double().cpu().numpy() * sz\n",
    "            sum_dV += dV.detach().double().cpu().numpy() * sz\n",
    "\n",
    "    return sum_dS / n_paths, sum_dV / n_paths\n",
    "\n",
    "# ----------------- main driver -----------------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--rows',        type=int, default=5_000_000)\n",
    "    ap.add_argument('--paths',       type=int, default=1_000_000)\n",
    "    ap.add_argument('--seed_offset', type=int, default=0)\n",
    "    ap.add_argument('--out',         type=str, default='Train.parquet')\n",
    "    ap.add_argument('--no-aad',      dest='do_aad', action='store_false', default=True, help='disable AAD Δ/ν')\n",
    "\n",
    "    # Instrumentation & outputs\n",
    "    ap.add_argument('--checkpoint',  type=int, default=10_000, help='rows between timing checkpoints')\n",
    "    ap.add_argument('--timelog',     type=str, default='timelog.csv', help='CSV to write timing checkpoints')\n",
    "    ap.add_argument('--plot',        type=str, default='fd_vs_aad_runtime.png', help='PNG plot output')\n",
    "\n",
    "    # (Jupyter sometimes injects -f/--f; we’ll ignore unknowns in notebooks)\n",
    "    ap.add_argument('-f', '--f', default=None, help=argparse.SUPPRESS)\n",
    "\n",
    "    # Robust parsing across CLI & notebooks\n",
    "    in_notebook = False\n",
    "    try:\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "        in_notebook = get_ipython() is not None\n",
    "    except Exception:\n",
    "        in_notebook = False\n",
    "\n",
    "    if in_notebook:\n",
    "        args, _ = ap.parse_known_args([])   # ignore Jupyter's flags, use defaults\n",
    "    else:\n",
    "        args, _ = ap.parse_known_args()\n",
    "\n",
    "    np.random.seed(SEED_BASE + args.seed_offset)\n",
    "    torch.manual_seed(SEED_BASE + args.seed_offset)\n",
    "\n",
    "    out_path  = pathlib.Path(args.out)\n",
    "    writer    = None\n",
    "    first     = True\n",
    "\n",
    "    # cumulative timers\n",
    "    total_t0  = time.time()\n",
    "    sample_t = price_t = fd_t = aad_t = 0.0\n",
    "\n",
    "    # checkpoint series (cumulative)\n",
    "    ck_rows, ck_fd, ck_aad, ck_wall = [], [], [], []\n",
    "\n",
    "    print(f\"Launching Monte-Carlo for {args.rows:,} rows …\", flush=True)\n",
    "    global_row_idx = 0\n",
    "\n",
    "    rows_left = args.rows\n",
    "    try:\n",
    "        while rows_left:\n",
    "            batch = min(rows_left, CHUNK_MAX)\n",
    "            records = []\n",
    "\n",
    "            for _ in range(batch):\n",
    "                # ---- sample scenario\n",
    "                t0 = time.perf_counter()\n",
    "                p  = fg_sample()\n",
    "                sample_t += time.perf_counter() - t0\n",
    "\n",
    "                # ---- price & SE\n",
    "                t1 = time.perf_counter()\n",
    "                price, price_se = price_mc(p, args.paths, return_se=True)\n",
    "                price_t += time.perf_counter() - t1\n",
    "\n",
    "                # ---- FD Δ/ν\n",
    "                scen_seed = SEED_BASE + args.seed_offset + global_row_idx\n",
    "                t2 = time.perf_counter()\n",
    "                delta, vega = delta_vega_fd_crn(p, args.paths, rel=1e-4, base_seed=scen_seed)\n",
    "                fd_t += time.perf_counter() - t2\n",
    "\n",
    "                # ---- AAD Δ/ν (optional)\n",
    "                if args.do_aad:\n",
    "                    t3 = time.perf_counter()\n",
    "                    delta_aad, vega_aad = delta_vega_aad(p, args.paths, base_seed=scen_seed)\n",
    "                    aad_t += time.perf_counter() - t3\n",
    "                else:\n",
    "                    delta_aad = vega_aad = None\n",
    "\n",
    "                # ---- flatten correlation matrix\n",
    "                corr_mat = p['rho'].detach().cpu().numpy()\n",
    "                corr_fields = {\n",
    "                    f\"corr_{i}_{j}\": float(corr_mat[i, j])\n",
    "                    for i in range(N_ASSETS) for j in range(i + 1, N_ASSETS)\n",
    "                }\n",
    "\n",
    "                # ---- assemble record\n",
    "                rec = {\n",
    "                    **{f\"S0_{i}\":     float(p['S0'][i])     for i in range(N_ASSETS)},\n",
    "                    **{f\"sigma_{i}\":  float(p['sigma'][i])  for i in range(N_ASSETS)},\n",
    "                    **corr_fields,\n",
    "                    \"K\": float(p['K']),\n",
    "                    \"r\": float(p['r']),\n",
    "                    \"T\": float(p['T']),\n",
    "                    \"price\":    float(price),\n",
    "                    \"price_se\": float(price_se),\n",
    "                    **{f\"delta_{i}\": float(delta[i]) for i in range(N_ASSETS)},\n",
    "                    **{f\"vega_{i}\":  float(vega[i])  for i in range(N_ASSETS)},\n",
    "                }\n",
    "                if delta_aad is not None:\n",
    "                    rec.update({f\"delta_aad_{i}\": float(delta_aad[i]) for i in range(N_ASSETS)})\n",
    "                    rec.update({f\"vega_aad_{i}\":  float(vega_aad[i])  for i in range(N_ASSETS)})\n",
    "\n",
    "                records.append(rec)\n",
    "                global_row_idx += 1\n",
    "\n",
    "                # ---- checkpoint logging\n",
    "                if (global_row_idx % args.checkpoint) == 0:\n",
    "                    ck_rows.append(global_row_idx)\n",
    "                    ck_fd.append(fd_t)\n",
    "                    ck_aad.append(aad_t if args.do_aad else 0.0)\n",
    "                    ck_wall.append(time.time() - total_t0)\n",
    "\n",
    "            # ---- write Parquet (single file)\n",
    "            table = pa.Table.from_pylist(records)\n",
    "            if first:\n",
    "                writer = pq.ParquetWriter(str(out_path), table.schema, compression='zstd')\n",
    "                first = False\n",
    "            writer.write_table(table)\n",
    "            rows_left -= batch\n",
    "\n",
    "    finally:\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "\n",
    "    total_elapsed = time.time() - total_t0\n",
    "\n",
    "    # ---- console summary (paper-ready numbers)\n",
    "    print(f\"Sampling: {sample_t:.2f}s | Pricing: {price_t:.2f}s | FD: {fd_t:.2f}s | AAD: {aad_t:.2f}s\")\n",
    "    print(f\"TOTAL (wall): {total_elapsed:.2f}s for {args.rows:,} rows @ {args.paths:,} paths\")\n",
    "\n",
    "    # ---- write timing CSV\n",
    "    if len(ck_rows) > 0:\n",
    "        with open(args.timelog, \"w\", newline=\"\") as f:\n",
    "            wr = csv.writer(f)\n",
    "            wr.writerow([\"rows\", \"fd_time_sec_cum\", \"aad_time_sec_cum\", \"wall_time_sec_cum\"])\n",
    "            for r, fdv, aadv, w in zip(ck_rows, ck_fd, ck_aad, ck_wall):\n",
    "                wr.writerow([r, f\"{fdv:.6f}\", f\"{aadv:.6f}\", f\"{w:.6f}\"])\n",
    "        print(f\"Wrote timing checkpoints → {args.timelog}\")\n",
    "\n",
    "    # ---- make plot (cumulative runtime vs rows)\n",
    "    if len(ck_rows) > 0:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.plot(ck_rows, ck_fd,  label=\"FD cumulative runtime (s)\")\n",
    "        if args.do_aad:\n",
    "            plt.plot(ck_rows, ck_aad, label=\"AAD cumulative runtime (s)\")\n",
    "        plt.xlabel(\"Rows (scenarios)\")\n",
    "        plt.ylabel(\"Cumulative runtime (seconds)\")\n",
    "        plt.title(\"FD vs AAD runtime scaling\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(args.plot, dpi=150)\n",
    "        print(f\"Wrote runtime plot → {args.plot}\")\n",
    "\n",
    "        # ---- find crossover (first rows where AAD faster than FD cumulatively)\n",
    "        if args.do_aad:\n",
    "            crossover_idx = None\n",
    "            for i in range(len(ck_rows)):\n",
    "                if ck_aad[i] < ck_fd[i]:\n",
    "                    crossover_idx = i\n",
    "                    break\n",
    "            if crossover_idx is not None:\n",
    "                print(f\"AAD becomes faster than FD (cumulative) at ~{ck_rows[crossover_idx]:,} rows \"\n",
    "                      f\"(FD={ck_fd[crossover_idx]:.2f}s, AAD={ck_aad[crossover_idx]:.2f}s).\")\n",
    "            else:\n",
    "                print(\"No cumulative AAD<FD crossover within sampled rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37ae99",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd49947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Monte-Carlo for 50,000 rows …\n",
      "Sampling: 12.02s | Pricing: 22267.82s | FD: 50801.53s | AAD: 16086.47s\n",
      "TOTAL (wall): 89169.91s for 50,000 rows @ 100,000,000 paths\n",
      "Wrote timing checkpoints → timelog_test.csv\n",
      "Wrote runtime plot → fd_vs_aad_runtime_test.png\n",
      "AAD becomes faster than FD (cumulative) at ~500 rows (FD=512.34s, AAD=162.18s).\n"
     ]
    }
   ],
   "source": [
    "import os, math, time, argparse, pathlib, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyarrow as pa, pyarrow.parquet as pq\n",
    "\n",
    "# Optional plotting/logging deps\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # safe for headless / servers\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# --------- global knobs ---------\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark       = True\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "N_ASSETS   = 3\n",
    "R_RATE     = 0.03\n",
    "SEED_BASE  = 42\n",
    "CHUNK_MAX  = 100_000                 # rows before flushing Parquet\n",
    "NGPU       = torch.cuda.device_count()\n",
    "DEVICES    = [torch.device(f\"cuda:{i}\") for i in range(NGPU)]\n",
    "SIM_CHUNK  = 1_000_000               # per-GPU sub-batch size (paths)\n",
    "\n",
    "if not NGPU:\n",
    "    sys.exit(\"No CUDA GPU visible – aborting.\")\n",
    "\n",
    "# --------- correlation sampler ---------\n",
    "def cvine_corr_np(d, a: float = 5.0, b: float = 2.0) -> torch.Tensor:\n",
    "    P = np.eye(d)\n",
    "    for k in range(d - 1):\n",
    "        for i in range(k + 1, d):\n",
    "            rho = 2.0 * np.random.beta(a, b) - 1.0\n",
    "            for m in range(k - 1, -1, -1):\n",
    "                rho = rho * np.sqrt((1 - P[m, i] ** 2) * (1 - P[m, k] ** 2)) + P[m, i] * P[m, k]\n",
    "            P[k, i] = P[i, k] = rho\n",
    "    ev, evec = np.linalg.eigh(P)\n",
    "    P = evec @ np.diag(np.clip(ev, 1e-6, None)) @ evec.T\n",
    "    return torch.as_tensor(P, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "# --------- random scenario generator ---------\n",
    "def fg_sample():\n",
    "    z     = np.random.normal(0.5, math.sqrt(0.25), N_ASSETS)\n",
    "    S0    = 100 * np.exp(z)\n",
    "    sigma = np.random.uniform(0.05, 0.8, N_ASSETS)\n",
    "    T     = (np.random.randint(1, 44) ** 2) / 252.0\n",
    "    return dict(S0=S0.astype(np.float32), sigma=sigma.astype(np.float32),\n",
    "                T=float(T), rho=cvine_corr_np(N_ASSETS), K=100.0, r=R_RATE)\n",
    "\n",
    "# --------- helpers ---------\n",
    "def _split_across_devices(total: int, ndev: int):\n",
    "    base = total // ndev\n",
    "    rem  = total % ndev\n",
    "    return [base + (1 if i < rem else 0) for i in range(ndev)]\n",
    "\n",
    "@torch.no_grad()\n",
    "def terminal_prices(S0, sigma, T, rho, *, n_paths, r, device, gen=None):\n",
    "    L = torch.linalg.cholesky(rho.to(device))\n",
    "    Z = torch.randn(n_paths, N_ASSETS, device=device, generator=gen)\n",
    "    with torch.autocast('cuda', dtype=torch.float16):\n",
    "        drift     = (r - 0.5 * sigma**2) * T\n",
    "        diffusion = sigma * math.sqrt(T) * (Z @ L.T)\n",
    "        return torch.exp(torch.log(S0) + drift + diffusion)\n",
    "\n",
    "# --------- streaming MC price (fast path) ---------\n",
    "def price_mc(params, n_paths, return_se=False):\n",
    "    counts      = _split_across_devices(n_paths, NGPU)\n",
    "    total_sum   = 0.0\n",
    "    total_sumsq = 0.0\n",
    "    disc        = math.exp(-float(params['r']) * float(params['T']))\n",
    "\n",
    "    for dev, count in zip(DEVICES, counts):\n",
    "        if count == 0: continue\n",
    "        S0    = torch.tensor(params['S0'],    device=dev)\n",
    "        sigma = torch.tensor(params['sigma'], device=dev)\n",
    "        T     = torch.tensor(params['T'],     device=dev)\n",
    "        r     = torch.tensor(params['r'],     device=dev)\n",
    "        K     = torch.tensor(params['K'],     device=dev)\n",
    "\n",
    "        for offset in range(0, count, SIM_CHUNK):\n",
    "            sz  = min(SIM_CHUNK, count - offset)\n",
    "            ST  = terminal_prices(S0, sigma, T, params['rho'], n_paths=sz, r=r, device=dev)\n",
    "            pay = torch.clamp(ST.min(dim=1).values - K, 0.0)\n",
    "            arr = (disc * pay).float().cpu().numpy()\n",
    "            total_sum   += arr.sum()\n",
    "            total_sumsq += (arr * arr).sum()\n",
    "\n",
    "    mean = total_sum / n_paths\n",
    "    if not return_se:\n",
    "        return mean\n",
    "    var  = (total_sumsq / n_paths) - mean * mean\n",
    "    se   = math.sqrt(max(var, 0.0) / n_paths)\n",
    "    return mean, se\n",
    "\n",
    "# ===================== FD Δ & ν WITH CRN =====================\n",
    "def delta_vega_fd_crn(params, n_paths, rel=1e-4, base_seed=None):\n",
    "    \"\"\"\n",
    "    FD Δ/ν using common random numbers (same Z/Y reused for up/down).\n",
    "    float64 throughout; chunked + multi-GPU; deterministic with base_seed.\n",
    "    Returns (delta[N_ASSETS], vega[N_ASSETS]) as numpy float64 arrays.\n",
    "    \"\"\"\n",
    "    disc = math.exp(-float(params['r']) * float(params['T']))\n",
    "    delta_num = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "    vega_num  = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "\n",
    "    counts = _split_across_devices(n_paths, NGPU)\n",
    "    for dev_idx, (dev, count) in enumerate(zip(DEVICES, counts)):\n",
    "        if count == 0: continue\n",
    "\n",
    "        S0f  = torch.tensor(params['S0'],    dtype=torch.float64, device=dev)\n",
    "        sigf = torch.tensor(params['sigma'], dtype=torch.float64, device=dev)\n",
    "        Tf   = torch.tensor(float(params['T']), dtype=torch.float64, device=dev)\n",
    "        rf   = torch.tensor(float(params['r']), dtype=torch.float64, device=dev)\n",
    "        Kf   = torch.tensor(float(params['K']), dtype=torch.float64, device=dev)\n",
    "        L    = torch.linalg.cholesky(params['rho'].to(dev).to(torch.float64))\n",
    "\n",
    "        for chunk_idx, offset in enumerate(range(0, count, SIM_CHUNK)):\n",
    "            sz   = min(SIM_CHUNK, count - offset)\n",
    "\n",
    "            gen = None\n",
    "            if base_seed is not None:\n",
    "                gen = torch.Generator(device=dev)\n",
    "                gen.manual_seed(int(base_seed) + 1_000_003*dev_idx + chunk_idx)\n",
    "\n",
    "            Z = torch.randn(sz, N_ASSETS, dtype=torch.float64, device=dev, generator=gen)\n",
    "            Y = Z @ L.T\n",
    "\n",
    "            drift_b = (rf - 0.5 * sigf**2) * Tf\n",
    "            diff_b  = sigf * torch.sqrt(Tf) * Y\n",
    "\n",
    "            for i in range(N_ASSETS):\n",
    "                # Δ bump\n",
    "                hS   = float(max(rel * float(S0f[i].item()), 1e-6))\n",
    "                S_up = S0f.clone(); S_up[i] += hS\n",
    "                S_dn = S0f.clone(); S_dn[i] -= hS\n",
    "\n",
    "                ST_up = torch.exp(torch.log(S_up) + drift_b + diff_b)\n",
    "                ST_dn = torch.exp(torch.log(S_dn) + drift_b + diff_b)\n",
    "                pay_up = torch.clamp(ST_up.min(dim=1).values - Kf, 0.0)\n",
    "                pay_dn = torch.clamp(ST_dn.min(dim=1).values - Kf, 0.0)\n",
    "\n",
    "                delta_num[i] += (disc * (pay_up.sum().double() - pay_dn.sum().double()) / (2.0 * hS)).cpu().item()\n",
    "\n",
    "                # ν bump (reuse Y)\n",
    "                hV     = float(max(rel * float(sigf[i].item()), 1e-6))\n",
    "                sig_up = sigf.clone(); sig_up[i] += hV\n",
    "                sig_dn = sigf.clone(); sig_dn[i] -= hV\n",
    "\n",
    "                drift_up = (rf - 0.5 * sig_up**2) * Tf\n",
    "                diff_up  = sig_up * torch.sqrt(Tf) * Y\n",
    "                drift_dn = (rf - 0.5 * sig_dn**2) * Tf\n",
    "                diff_dn  = sig_dn * torch.sqrt(Tf) * Y\n",
    "\n",
    "                ST_vup  = torch.exp(torch.log(S0f) + drift_up + diff_up)\n",
    "                ST_vdn  = torch.exp(torch.log(S0f) + drift_dn + diff_dn)\n",
    "                pay_vup = torch.clamp(ST_vup.min(dim=1).values - Kf, 0.0)\n",
    "                pay_vdn = torch.clamp(ST_vdn.min(dim=1).values - Kf, 0.0)\n",
    "\n",
    "                vega_num[i]  += (disc * (pay_vup.sum().double() - pay_vdn.sum().double()) / (2.0 * hV)).cpu().item()\n",
    "\n",
    "    delta = delta_num / n_paths\n",
    "    vega  = vega_num  / n_paths\n",
    "    return delta, vega\n",
    "\n",
    "# ===================== AAD Δ & ν (float64, chunked) =====================\n",
    "def delta_vega_aad(params, n_paths, base_seed=None):\n",
    "    counts = _split_across_devices(n_paths, NGPU)\n",
    "    sum_dS = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "    sum_dV = np.zeros(N_ASSETS, dtype=np.float64)\n",
    "\n",
    "    for dev_idx, (dev, count) in enumerate(zip(DEVICES, counts)):\n",
    "        if count == 0: continue\n",
    "        L  = torch.linalg.cholesky(params['rho'].to(dev).to(torch.float64))\n",
    "        Tf = torch.tensor(float(params['T']), dtype=torch.float64, device=dev)\n",
    "        rf = torch.tensor(float(params['r']), dtype=torch.float64, device=dev)\n",
    "        Kf = torch.tensor(float(params['K']), dtype=torch.float64, device=dev)\n",
    "\n",
    "        for chunk_idx, offset in enumerate(range(0, count, SIM_CHUNK)):\n",
    "            sz  = min(SIM_CHUNK, count - offset)\n",
    "\n",
    "            gen = None\n",
    "            if base_seed is not None:\n",
    "                gen = torch.Generator(device=dev)\n",
    "                gen.manual_seed(int(base_seed) + 1_000_003*dev_idx + chunk_idx)\n",
    "\n",
    "            # Leaf vars with grads\n",
    "            S0  = torch.tensor(params['S0'],    dtype=torch.float64, device=dev, requires_grad=True)\n",
    "            sig = torch.tensor(params['sigma'], dtype=torch.float64, device=dev, requires_grad=True)\n",
    "\n",
    "            Z = torch.randn(sz, N_ASSETS, dtype=torch.float64, device=dev, generator=gen)\n",
    "            Y = Z @ L.T\n",
    "\n",
    "            drift = (rf - 0.5 * sig**2) * Tf\n",
    "            diff  = sig * torch.sqrt(Tf) * Y\n",
    "            ST    = torch.exp(torch.log(S0) + drift + diff)\n",
    "            payoff = torch.clamp(ST.min(dim=1).values - Kf, 0.0)\n",
    "            price  = torch.exp(-rf * Tf) * payoff.mean()\n",
    "\n",
    "            dS, dV = torch.autograd.grad(price, (S0, sig), retain_graph=False, create_graph=False)\n",
    "            # accumulate sums (note: host transfer happens here)\n",
    "            sum_dS += dS.detach().double().cpu().numpy() * sz\n",
    "            sum_dV += dV.detach().double().cpu().numpy() * sz\n",
    "\n",
    "    return sum_dS / n_paths, sum_dV / n_paths\n",
    "\n",
    "# ----------------- main driver -----------------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('--rows',        type=int, default=50_000)\n",
    "    ap.add_argument('--paths',       type=int, default=100_000_000)\n",
    "    ap.add_argument('--seed_offset', type=int, default=0)\n",
    "    ap.add_argument('--out',         type=str, default='Test.parquet')\n",
    "    ap.add_argument('--no-aad',      dest='do_aad', action='store_false', default=True, help='disable AAD Δ/ν')\n",
    "\n",
    "    # Instrumentation & outputs\n",
    "    ap.add_argument('--checkpoint',  type=int, default=500, help='rows between timing checkpoints')\n",
    "    ap.add_argument('--timelog',     type=str, default='timelog_test.csv', help='CSV to write timing checkpoints')\n",
    "    ap.add_argument('--plot',        type=str, default='fd_vs_aad_runtime_test.png', help='PNG plot output')\n",
    "\n",
    "    # (Jupyter sometimes injects -f/--f; we’ll ignore unknowns in notebooks)\n",
    "    ap.add_argument('-f', '--f', default=None, help=argparse.SUPPRESS)\n",
    "\n",
    "    # Robust parsing across CLI & notebooks\n",
    "    in_notebook = False\n",
    "    try:\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "        in_notebook = get_ipython() is not None\n",
    "    except Exception:\n",
    "        in_notebook = False\n",
    "\n",
    "    if in_notebook:\n",
    "        args, _ = ap.parse_known_args([])   # ignore Jupyter's flags, use defaults\n",
    "    else:\n",
    "        args, _ = ap.parse_known_args()\n",
    "\n",
    "    np.random.seed(SEED_BASE + args.seed_offset)\n",
    "    torch.manual_seed(SEED_BASE + args.seed_offset)\n",
    "\n",
    "    out_path  = pathlib.Path(args.out)\n",
    "    writer    = None\n",
    "    first     = True\n",
    "\n",
    "    # cumulative timers\n",
    "    total_t0  = time.time()\n",
    "    sample_t = price_t = fd_t = aad_t = 0.0\n",
    "\n",
    "    # checkpoint series (cumulative)\n",
    "    ck_rows, ck_fd, ck_aad, ck_wall = [], [], [], []\n",
    "\n",
    "    print(f\"Launching Monte-Carlo for {args.rows:,} rows …\", flush=True)\n",
    "    global_row_idx = 0\n",
    "\n",
    "    rows_left = args.rows\n",
    "    try:\n",
    "        while rows_left:\n",
    "            batch = min(rows_left, CHUNK_MAX)\n",
    "            records = []\n",
    "\n",
    "            for _ in range(batch):\n",
    "                # ---- sample scenario\n",
    "                t0 = time.perf_counter()\n",
    "                p  = fg_sample()\n",
    "                sample_t += time.perf_counter() - t0\n",
    "\n",
    "                # ---- price & SE\n",
    "                t1 = time.perf_counter()\n",
    "                price, price_se = price_mc(p, args.paths, return_se=True)\n",
    "                price_t += time.perf_counter() - t1\n",
    "\n",
    "                # ---- FD Δ/ν\n",
    "                scen_seed = SEED_BASE + args.seed_offset + global_row_idx\n",
    "                t2 = time.perf_counter()\n",
    "                delta, vega = delta_vega_fd_crn(p, args.paths, rel=1e-4, base_seed=scen_seed)\n",
    "                fd_t += time.perf_counter() - t2\n",
    "\n",
    "                # ---- AAD Δ/ν (optional)\n",
    "                if args.do_aad:\n",
    "                    t3 = time.perf_counter()\n",
    "                    delta_aad, vega_aad = delta_vega_aad(p, args.paths, base_seed=scen_seed)\n",
    "                    aad_t += time.perf_counter() - t3\n",
    "                else:\n",
    "                    delta_aad = vega_aad = None\n",
    "\n",
    "                # ---- flatten correlation matrix\n",
    "                corr_mat = p['rho'].detach().cpu().numpy()\n",
    "                corr_fields = {\n",
    "                    f\"corr_{i}_{j}\": float(corr_mat[i, j])\n",
    "                    for i in range(N_ASSETS) for j in range(i + 1, N_ASSETS)\n",
    "                }\n",
    "\n",
    "                # ---- assemble record\n",
    "                rec = {\n",
    "                    **{f\"S0_{i}\":     float(p['S0'][i])     for i in range(N_ASSETS)},\n",
    "                    **{f\"sigma_{i}\":  float(p['sigma'][i])  for i in range(N_ASSETS)},\n",
    "                    **corr_fields,\n",
    "                    \"K\": float(p['K']),\n",
    "                    \"r\": float(p['r']),\n",
    "                    \"T\": float(p['T']),\n",
    "                    \"price\":    float(price),\n",
    "                    \"price_se\": float(price_se),\n",
    "                    **{f\"delta_{i}\": float(delta[i]) for i in range(N_ASSETS)},\n",
    "                    **{f\"vega_{i}\":  float(vega[i])  for i in range(N_ASSETS)},\n",
    "                }\n",
    "                if delta_aad is not None:\n",
    "                    rec.update({f\"delta_aad_{i}\": float(delta_aad[i]) for i in range(N_ASSETS)})\n",
    "                    rec.update({f\"vega_aad_{i}\":  float(vega_aad[i])  for i in range(N_ASSETS)})\n",
    "\n",
    "                records.append(rec)\n",
    "                global_row_idx += 1\n",
    "\n",
    "                # ---- checkpoint logging\n",
    "                if (global_row_idx % args.checkpoint) == 0:\n",
    "                    ck_rows.append(global_row_idx)\n",
    "                    ck_fd.append(fd_t)\n",
    "                    ck_aad.append(aad_t if args.do_aad else 0.0)\n",
    "                    ck_wall.append(time.time() - total_t0)\n",
    "\n",
    "            # ---- write Parquet (single file)\n",
    "            table = pa.Table.from_pylist(records)\n",
    "            if first:\n",
    "                writer = pq.ParquetWriter(str(out_path), table.schema, compression='zstd')\n",
    "                first = False\n",
    "            writer.write_table(table)\n",
    "            rows_left -= batch\n",
    "\n",
    "    finally:\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "\n",
    "    total_elapsed = time.time() - total_t0\n",
    "\n",
    "    # ---- console summary (paper-ready numbers)\n",
    "    print(f\"Sampling: {sample_t:.2f}s | Pricing: {price_t:.2f}s | FD: {fd_t:.2f}s | AAD: {aad_t:.2f}s\")\n",
    "    print(f\"TOTAL (wall): {total_elapsed:.2f}s for {args.rows:,} rows @ {args.paths:,} paths\")\n",
    "\n",
    "    # ---- write timing CSV\n",
    "    if len(ck_rows) > 0:\n",
    "        with open(args.timelog, \"w\", newline=\"\") as f:\n",
    "            wr = csv.writer(f)\n",
    "            wr.writerow([\"rows\", \"fd_time_sec_cum\", \"aad_time_sec_cum\", \"wall_time_sec_cum\"])\n",
    "            for r, fdv, aadv, w in zip(ck_rows, ck_fd, ck_aad, ck_wall):\n",
    "                wr.writerow([r, f\"{fdv:.6f}\", f\"{aadv:.6f}\", f\"{w:.6f}\"])\n",
    "        print(f\"Wrote timing checkpoints → {args.timelog}\")\n",
    "\n",
    "    # ---- make plot (cumulative runtime vs rows)\n",
    "    if len(ck_rows) > 0:\n",
    "        plt.figure(figsize=(7,5))\n",
    "        plt.plot(ck_rows, ck_fd,  label=\"FD cumulative runtime (s)\")\n",
    "        if args.do_aad:\n",
    "            plt.plot(ck_rows, ck_aad, label=\"AAD cumulative runtime (s)\")\n",
    "        plt.xlabel(\"Rows (scenarios)\")\n",
    "        plt.ylabel(\"Cumulative runtime (seconds)\")\n",
    "        plt.title(\"FD vs AAD runtime scaling\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(args.plot, dpi=150)\n",
    "        print(f\"Wrote runtime plot → {args.plot}\")\n",
    "\n",
    "        # ---- find crossover (first rows where AAD faster than FD cumulatively)\n",
    "        if args.do_aad:\n",
    "            crossover_idx = None\n",
    "            for i in range(len(ck_rows)):\n",
    "                if ck_aad[i] < ck_fd[i]:\n",
    "                    crossover_idx = i\n",
    "                    break\n",
    "            if crossover_idx is not None:\n",
    "                print(f\"AAD becomes faster than FD (cumulative) at ~{ck_rows[crossover_idx]:,} rows \"\n",
    "                      f\"(FD={ck_fd[crossover_idx]:.2f}s, AAD={ck_aad[crossover_idx]:.2f}s).\")\n",
    "            else:\n",
    "                print(\"No cumulative AAD<FD crossover within sampled rows.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbac403",
   "metadata": {},
   "source": [
    "## Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0286e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved cleaned file → Train_Clean.parquet\n",
      "✔ Saved cleaned file → Test_Clean.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_parquet(src_path, dst_path):\n",
    "    \"\"\"\n",
    "    • Divides every S0_* and price by the row’s K\n",
    "    • Renames the results to `S0_i/K` and `price/k`\n",
    "    • Removes *_se, the raw S0_*, price, and K columns\n",
    "    • Drops rows where price/k < 1e-6\n",
    "    \"\"\"\n",
    "    df = pd.read_parquet(src_path)\n",
    "\n",
    "    # 1) locate relevant columns\n",
    "    s0_cols = [c for c in df.columns if c.lower().startswith(\"s0_\")]\n",
    "    se_cols = [c for c in df.columns if c.endswith(\"_se\")]\n",
    "\n",
    "    # 2) create scaled columns with the requested names\n",
    "    for col in s0_cols:\n",
    "        df[f\"{col}/K\"] = df[col] / df[\"K\"]\n",
    "    df[\"price/k\"] = df[\"price\"] / df[\"K\"]\n",
    "\n",
    "    # 3) filter out extremely small payoffs\n",
    "    df = df[df[\"price/k\"] >= 1e-6]\n",
    "\n",
    "    # 4) drop the original, now-redundant columns\n",
    "    df = df.drop(columns=s0_cols + [\"price\", \"K\"] + se_cols)\n",
    "\n",
    "    # 5) save the cleaned file\n",
    "    df.to_parquet(dst_path, index=False)\n",
    "    print(f\"✔ Saved cleaned file → {dst_path!s}\")\n",
    "\n",
    "# Apply to both datasets\n",
    "clean_parquet(\"Train.parquet\", \"Train_Clean.parquet\")\n",
    "clean_parquet(\"Test.parquet\",  \"Test_Clean.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22932002",
   "metadata": {},
   "source": [
    "# Adjoint Neural Pricer (ANP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34274d6",
   "metadata": {},
   "source": [
    "## Explanantion/ Reasoning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52d988",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda\n",
      "Removing 12 Greek columns: ['delta_0', 'delta_1', 'delta_2', 'delta_aad_0', 'delta_aad_1', 'delta_aad_2', 'vega_0', 'vega_1', 'vega_2', 'vega_aad_0', 'vega_aad_1', 'vega_aad_2']\n",
      "\n",
      "Included feature columns (11):\n",
      "  • sigma_0\n",
      "  • sigma_1\n",
      "  • sigma_2\n",
      "  • corr_0_1\n",
      "  • corr_0_2\n",
      "  • corr_1_2\n",
      "  • r\n",
      "  • T\n",
      "  • S0_0/K\n",
      "  • S0_1/K\n",
      "  • S0_2/K\n",
      "\n",
      "train 4,773,294 rows\n",
      "valid 48,216 rows\n",
      " test 48,224 rows\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — imports & device setup\n",
    "import os, math, random, time, pathlib, re\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import re\n",
    "\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "# Use inline plots\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ.setdefault(\"NCCL_P2P_LEVEL\", \"0\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", DEVICE)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 1) Read cleaned Parquet files\n",
    "train_df = pd.read_parquet(\"Train_Clean.parquet\", engine=\"pyarrow\")\n",
    "test_df  = pd.read_parquet(\"Test_Clean.parquet\",  engine=\"pyarrow\")\n",
    "\n",
    "# 2) Identify and remove any Greek columns (delta*, vega*, incl. *_aad variants)\n",
    "def find_greek_cols(df: pd.DataFrame):\n",
    "    return [c for c in df.columns if (\"delta\" in c.lower()) or (\"vega\" in c.lower())]\n",
    "\n",
    "greeks_to_drop = sorted(set(find_greek_cols(train_df)) | set(find_greek_cols(test_df)))\n",
    "if greeks_to_drop:\n",
    "    print(f\"Removing {len(greeks_to_drop)} Greek columns: {greeks_to_drop}\")\n",
    "\n",
    "# 3) Define feature columns = all non-target, non-Greeks\n",
    "TARGET_COL = \"price/k\"\n",
    "feature_cols = [c for c in train_df.columns if c not in greeks_to_drop and c != TARGET_COL]\n",
    "\n",
    "# Sanity: ensure test has the same feature columns\n",
    "missing_in_test = [c for c in feature_cols if c not in test_df.columns]\n",
    "if missing_in_test:\n",
    "    raise KeyError(f\"Test set is missing expected feature columns: {missing_in_test}\")\n",
    "\n",
    "# >>> Print which columns ARE included\n",
    "print(f\"\\nIncluded feature columns ({len(feature_cols)}):\")\n",
    "for col in feature_cols:\n",
    "    print(\"  •\", col)\n",
    "\n",
    "\n",
    "# 4) Build X/y with the agreed feature set\n",
    "X_full = train_df[feature_cols].values.astype(np.float32)\n",
    "y_full = train_df[TARGET_COL].values.astype(np.float32)\n",
    "\n",
    "X_test = test_df[feature_cols].values.astype(np.float32)\n",
    "y_test = test_df[TARGET_COL].values.astype(np.float32)\n",
    "\n",
    "# 5) Split → train/val\n",
    "X_tr_np, X_val_np, y_tr_np, y_val_np = train_test_split(\n",
    "    X_full, y_full, test_size=0.01, random_state=42\n",
    ")\n",
    "\n",
    "# 6) TensorDatasets\n",
    "train_ds = TensorDataset(torch.from_numpy(X_tr_np),  torch.from_numpy(y_tr_np))\n",
    "val_ds   = TensorDataset(torch.from_numpy(X_val_np), torch.from_numpy(y_val_np))\n",
    "test_ds  = TensorDataset(torch.from_numpy(X_test),   torch.from_numpy(y_test))\n",
    "\n",
    "print(f\"\\ntrain {len(train_ds):,} rows\")\n",
    "print(f\"valid {len(val_ds):,} rows\")\n",
    "print(f\" test {len(test_ds):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc2f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[upd 1/100000] train MSE=7.066e-02  val MSE=1.460e-01\n"
     ]
    }
   ],
   "source": [
    "# ---- imports (safe even if already imported in earlier cells) ----\n",
    "import os, time, random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import R2Score\n",
    "\n",
    "# ---- helper for accurate timing on GPU ----\n",
    "def _now_sync():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    return time.perf_counter()\n",
    "\n",
    "# ---- model ----\n",
    "class BasketNet(nn.Module):\n",
    "    def __init__(self, in_dim: int, width: int, layers: int):\n",
    "        super().__init__()\n",
    "        blocks = [nn.Linear(in_dim, width), nn.ReLU()]\n",
    "        for _ in range(layers - 1):\n",
    "            blocks += [nn.Linear(width, width), nn.ReLU()]\n",
    "        blocks.append(nn.Linear(width, 1))\n",
    "        self.net = nn.Sequential(*blocks)\n",
    "        # Xavier init\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ---- training run (save FINAL only) ----\n",
    "def run_experiment_updates_per_update(\n",
    "    width: int = 300,\n",
    "    layers: int = 4,\n",
    "    batch_size: int = 50_000,\n",
    "    n_updates: int = 100_000,\n",
    "    lr: float = 1e-3,\n",
    "    optimizer_name: str = \"Adam\",   # \"Adam\" | \"SGD\" | \"LBFGS\"\n",
    "    seed: int = 42,\n",
    "    save_model: bool = True,        # save final only\n",
    "    save_dir: str = \"checkpoints\",\n",
    "    log_every: int = 1\n",
    "):\n",
    "    \"\"\"\n",
    "    Train for exactly n_updates minibatches, time the run, and save ONLY the FINAL checkpoint.\n",
    "    Returns a dict with timing and final metrics.\n",
    "    \"\"\"\n",
    "    # 1) Seed + loaders\n",
    "    torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    # 2) Model\n",
    "    in_dim = train_ds[0][0].shape[0]\n",
    "    model = BasketNet(in_dim, width, layers).to(DEVICE)\n",
    "    if DEVICE.type == \"cuda\" and torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    # 3) Loss & optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"LBFGS\":\n",
    "        optimizer = optim.LBFGS(model.parameters(), lr=lr, max_iter=20)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "\n",
    "    # 4) Infinite train iterator\n",
    "    def infinite_train_iter(loader):\n",
    "        while True:\n",
    "            for batch in loader:\n",
    "                yield batch\n",
    "    inf_train = infinite_train_iter(train_loader)\n",
    "\n",
    "    # 5) Logging\n",
    "    train_losses, valid_losses, steps_recorded = [], [], []\n",
    "    print_every = max(1, n_updates // 10)\n",
    "\n",
    "    # 6) Saving prep (FINAL only)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tag = f\"w{width}_L{layers}_bs{batch_size}_upd{n_updates}_{optimizer_name}_lr{lr:g}_{timestamp}\"\n",
    "    final_path = os.path.join(save_dir, f\"model_{tag}_final.pt\")\n",
    "\n",
    "    def _model_to_save(m):\n",
    "        return m.module if isinstance(m, nn.DataParallel) else m\n",
    "\n",
    "    def _save_final(val_mse_last):\n",
    "        chk = {\n",
    "            \"model_state\": _model_to_save(model).state_dict(),\n",
    "            \"optimizer_state\": optimizer.state_dict(),\n",
    "            \"config\": {\n",
    "                \"in_dim\": in_dim, \"width\": width, \"layers\": layers,\n",
    "                \"batch_size\": batch_size, \"n_updates\": n_updates,\n",
    "                \"lr\": lr, \"optimizer_name\": optimizer_name, \"seed\": seed\n",
    "            },\n",
    "            \"val_mse\": float(val_mse_last)\n",
    "        }\n",
    "        torch.save(chk, final_path)\n",
    "        print(f\"[SAVE:final] -> {final_path}  (val MSE={val_mse_last:.3e})\")\n",
    "\n",
    "    # 7) Train (timed, GPU-synced)\n",
    "    t0 = _now_sync()\n",
    "    model.train()\n",
    "    for step in range(1, n_updates + 1):\n",
    "        Xb, yb = next(inf_train)\n",
    "        Xb, yb = Xb.to(DEVICE), yb.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "        if optimizer_name == \"LBFGS\":\n",
    "            def closure():\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                out = model(Xb)\n",
    "                loss = criterion(out, yb)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "            loss = optimizer.step(closure)\n",
    "            loss_val = float(loss.item())\n",
    "        else:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            out = model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_val = float(loss.item())\n",
    "\n",
    "        # periodic validation\n",
    "        if step == 1 or step == n_updates or (step % log_every == 0):\n",
    "            model.eval()\n",
    "            tot_val, cnt_val = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for Xv, yv in val_loader:\n",
    "                    Xv, yv = Xv.to(DEVICE), yv.to(DEVICE).unsqueeze(1)\n",
    "                    ov = model(Xv)\n",
    "                    tot_val += criterion(ov, yv).item() * Xv.size(0)\n",
    "                    cnt_val += Xv.size(0)\n",
    "            val_mse = tot_val / cnt_val\n",
    "\n",
    "            steps_recorded.append(step)\n",
    "            train_losses.append(loss_val)\n",
    "            valid_losses.append(val_mse)\n",
    "\n",
    "            if step == 1 or step == n_updates or (step % print_every == 0):\n",
    "                print(f\"[upd {step}/{n_updates}] train MSE={loss_val:.3e}  val MSE={val_mse:.3e}\")\n",
    "\n",
    "            model.train()\n",
    "\n",
    "    train_time_sec = _now_sync() - t0\n",
    "    updates_per_sec = n_updates / train_time_sec if train_time_sec > 0 else float(\"inf\")\n",
    "    samples_per_sec = (n_updates * batch_size) / train_time_sec if train_time_sec > 0 else float(\"inf\")\n",
    "\n",
    "    # 8) Plot curves (cum-min, same style as before)\n",
    "    train_min = np.minimum.accumulate(train_losses)\n",
    "    valid_min = np.minimum.accumulate(valid_losses)\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(steps_recorded, np.log10(train_min), label=\"train (cum-min)\")\n",
    "    plt.plot(steps_recorded, np.log10(valid_min), label=\"valid (cum-min)\")\n",
    "    plt.xlabel(\"update step\"); plt.ylabel(\"log10 MSE\")\n",
    "    plt.title(f\"{layers}×{width} • bs={batch_size} • {optimizer_name}\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # 9) Test (evaluates the last trained weights)\n",
    "    model.eval()\n",
    "    all_preds, all_truths = [], []\n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in test_loader:\n",
    "            pr = model(Xb.to(DEVICE)).cpu().squeeze()\n",
    "            all_preds.append(pr); all_truths.append(yb)\n",
    "    preds, truths = torch.cat(all_preds), torch.cat(all_truths)\n",
    "    test_mse = criterion(preds.unsqueeze(1), truths.unsqueeze(1)).item()\n",
    "    test_r2  = R2Score()(preds, truths).cpu().item()\n",
    "\n",
    "    print(f\"\\nTrain wall time: {train_time_sec:.2f}s | {updates_per_sec:.2f} upd/s | {samples_per_sec:.0f} samples/s\")\n",
    "    print(f\"Test results (final weights) → MSE = {test_mse:.3e}   R² = {test_r2:.4f}\")\n",
    "\n",
    "    # 10) Save FINAL (only)\n",
    "    if save_model:\n",
    "        _save_final(valid_losses[-1])\n",
    "\n",
    "    return {\n",
    "        \"train_time_sec\": train_time_sec,\n",
    "        \"updates_per_sec\": updates_per_sec,\n",
    "        \"samples_per_sec\": samples_per_sec,\n",
    "        \"final_val_mse\": valid_losses[-1],\n",
    "        \"test_mse\": test_mse,\n",
    "        \"test_r2\": test_r2,\n",
    "        \"final_path\": final_path if save_model else None\n",
    "    }\n",
    "\n",
    "# ---- example call ----\n",
    "res = run_experiment_updates_per_update(\n",
    "    width=250,\n",
    "    layers=5,\n",
    "    batch_size=5_000,\n",
    "    n_updates=100_000,\n",
    "    lr=1e-3,\n",
    "    optimizer_name=\"Adam\",\n",
    "    seed=42,\n",
    "    save_model=True,        # FINAL only\n",
    "    save_dir=\"checkpoints\",\n",
    "    log_every=100\n",
    ")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff356b6",
   "metadata": {},
   "source": [
    "### Out of Sample Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef4af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell — Predict price + AAD Greeks from the model and save\n",
    "\n",
    "import torch, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ---------------- config ----------------\n",
    "TEST_PARQUET   = \"Test_Clean.parquet\"      # or \"Test_clean_5k.parquet\"\n",
    "MODEL_CKPT     = \"model_w250_L5_bs5000_upd100000_Adam_lr0.001.pt\"\n",
    "OUT_PARQUET    = \"Test_ModelAAD_price+greeks.parquet\"\n",
    "TARGET_COL     = \"price/k\"\n",
    "N_ASSETS       = 3\n",
    "DEVICE         = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# ------------ helpers ------------\n",
    "def drop_greek_cols(df: pd.DataFrame):\n",
    "    \"\"\"Remove any columns containing 'delta' or 'vega' (case-insensitive).\"\"\"\n",
    "    bad = [c for c in df.columns if (\"delta\" in c.lower()) or (\"vega\" in c.lower())]\n",
    "    return df.drop(columns=bad), bad\n",
    "\n",
    "def load_features(df: pd.DataFrame):\n",
    "    \"\"\"Derive feature columns by removing Greeks + target.\"\"\"\n",
    "    df_no_greeks, dropped = drop_greek_cols(df)\n",
    "    if dropped:\n",
    "        print(f\"Removed {len(dropped)} Greek columns: {sorted(dropped)}\")\n",
    "    feature_cols = [c for c in df_no_greeks.columns if c != TARGET_COL]\n",
    "    print(f\"Using {len(feature_cols)} feature columns:\")\n",
    "    for c in feature_cols: print(\"  •\", c)\n",
    "    return feature_cols\n",
    "\n",
    "def ensure_spot_vol_indices(feature_cols):\n",
    "    name_to_idx = {c: i for i, c in enumerate(feature_cols)}\n",
    "    spot_names  = [f\"S0_{i}/K\" for i in range(N_ASSETS)]\n",
    "    vol_names   = [f\"sigma_{i}\" for i in range(N_ASSETS)]\n",
    "    missing = [n for n in (spot_names + vol_names) if n not in name_to_idx]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Required columns not found in features: {missing}\")\n",
    "    spot_idx = [name_to_idx[n] for n in spot_names]\n",
    "    vol_idx  = [name_to_idx[n] for n in vol_names]\n",
    "    return spot_idx, vol_idx\n",
    "\n",
    "def flexible_load_state_dict(model: nn.Module, ckpt_path: str):\n",
    "    \"\"\"Load either a raw state_dict or a checkpoint dict with 'model_state'. Handles module. prefixes.\"\"\"\n",
    "    obj = torch.load(ckpt_path, map_location=DEVICE)\n",
    "    state = obj.get(\"model_state\", obj) if isinstance(obj, dict) else obj\n",
    "    try:\n",
    "        model.load_state_dict(state, strict=True)\n",
    "        return\n",
    "    except RuntimeError:\n",
    "        # strip potential 'module.' prefixes (from DataParallel)\n",
    "        fixed = OrderedDict((k.replace(\"module.\", \"\"), v) for k, v in state.items())\n",
    "        model.load_state_dict(fixed, strict=True)\n",
    "\n",
    "# ------------ model ------------\n",
    "class BasketNet(nn.Module):\n",
    "    def __init__(self, d, w=250, L=5):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(d,w), nn.ReLU()]\n",
    "        for _ in range(L-1):\n",
    "            layers += [nn.Linear(w,w), nn.ReLU()]\n",
    "        layers.append(nn.Linear(w,1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "# ------------ load data & features ------------\n",
    "df = pd.read_parquet(TEST_PARQUET, engine=\"pyarrow\")\n",
    "feature_cols = load_features(df)\n",
    "spot_idx, vol_idx = ensure_spot_vol_indices(feature_cols)\n",
    "\n",
    "# ------------ build model & load weights ------------\n",
    "model = BasketNet(d=len(feature_cols), w=250, L=5).to(DEVICE)\n",
    "flexible_load_state_dict(model, MODEL_CKPT)\n",
    "model.eval()\n",
    "\n",
    "# ------------ predict in batches (price + AAD Greeks) ------------\n",
    "BATCH = 100_000  # safe and fast; adjust if needed\n",
    "n = len(df)\n",
    "prices, deltas, vegas = [], [], []\n",
    "\n",
    "for i in range(0, n, BATCH):\n",
    "    block = df.iloc[i:i+BATCH][feature_cols].values.astype(np.float32)\n",
    "    X = torch.from_numpy(block).to(DEVICE).requires_grad_(True)\n",
    "\n",
    "    # forward price\n",
    "    p = model(X)  # (B,)\n",
    "\n",
    "    # AAD gradients wrt inputs\n",
    "    g = torch.autograd.grad(outputs=p, inputs=X, grad_outputs=torch.ones_like(p))[0]  # (B, F)\n",
    "\n",
    "    # slice Greeks\n",
    "    d_blk = g[:, spot_idx].detach().cpu().numpy()\n",
    "    v_blk = g[:, vol_idx].detach().cpu().numpy()\n",
    "    prices.append(p.detach().cpu().numpy())\n",
    "    deltas.append(d_blk)\n",
    "    vegas.append(v_blk)\n",
    "\n",
    "# stack outputs\n",
    "price_pred = np.concatenate(prices, axis=0)\n",
    "delta_pred = np.vstack(deltas)\n",
    "vega_pred  = np.vstack(vegas)\n",
    "\n",
    "# ------------ assemble & save ------------\n",
    "delta_cols = [f\"delta_{i}\" for i in range(N_ASSETS)]\n",
    "vega_cols  = [f\"vega_{i}\"  for i in range(N_ASSETS)]\n",
    "out = pd.DataFrame(\n",
    "    np.column_stack([price_pred, delta_pred, vega_pred]),\n",
    "    columns=[TARGET_COL] + delta_cols + vega_cols,\n",
    "    index=df.index\n",
    ")\n",
    "out.to_parquet(OUT_PARQUET, engine=\"pyarrow\", compression=\"zstd\", index=True)\n",
    "print(f\"Wrote {OUT_PARQUET} with columns: {[TARGET_COL] + delta_cols + vega_cols}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ac708",
   "metadata": {},
   "source": [
    "# Dual Headed Neural Net "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585ffa8",
   "metadata": {},
   "source": [
    "## Explananation/ Reasoning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97594d82",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 1) Device & seeds\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", DEVICE)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# 2) Load dataset with price and FD Greeks\n",
    "df = pd.read_parquet(\"Train_clean_5m_aad_greeks.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "# 3) Define target and feature columns\n",
    "target_cols = [\"price/k\"] + [f\"delta_{i}\" for i in range(3)] + [f\"vega_{i}\" for i in range(3)]\n",
    "feature_cols = [c for c in df.columns if c not in target_cols]\n",
    "\n",
    "# 4) Extract NumPy arrays\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df[target_cols].values.astype(np.float32)\n",
    "\n",
    "# 5) Train/val split (99/1)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.01, random_state=42)\n",
    "\n",
    "# 6) Separate price, delta, vega targets\n",
    "price_tr, delta_tr, vega_tr = y_tr[:,0], y_tr[:,1:4], y_tr[:,4:7]\n",
    "price_val, delta_val, vega_val = y_val[:,0], y_val[:,1:4], y_val[:,4:7]\n",
    "\n",
    "# 7) Build PyTorch datasets\n",
    "train_ds = TensorDataset(\n",
    "    torch.from_numpy(X_tr),\n",
    "    torch.from_numpy(price_tr),\n",
    "    torch.from_numpy(delta_tr),\n",
    "    torch.from_numpy(vega_tr)\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.from_numpy(X_val),\n",
    "    torch.from_numpy(price_val),\n",
    "    torch.from_numpy(delta_val),\n",
    "    torch.from_numpy(vega_val)\n",
    ")\n",
    "print(f\"train {len(train_ds):,} rows\")\n",
    "print(f\"valid {len(val_ds):,} rows\")\n",
    "\n",
    "# 8) Define single-output BasketNet model with Softplus activations\n",
    "class BasketNet(nn.Module):\n",
    "    def __init__(self, in_dim, width=300, layers=4):\n",
    "        super().__init__()\n",
    "        blocks = [nn.Linear(in_dim, width), nn.Softplus()]\n",
    "        for _ in range(layers - 1):\n",
    "            blocks += [nn.Linear(width, width), nn.Softplus()]\n",
    "        blocks.append(nn.Linear(width, 1))\n",
    "        self.net = nn.Sequential(*blocks)\n",
    "        # Xavier init for all Linear layers\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # returns shape (batch,)\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "# 9) Feature indices for Greeks\n",
    "delta_idx = [feature_cols.index(f\"S0_{i}/K\") for i in range(3)]\n",
    "vega_idx  = [feature_cols.index(f\"sigma_{i}\") for i in range(3)]\n",
    "\n",
    "# 10) Training loop with Sobolev (differential) loss\n",
    "def run_differential(\n",
    "    width=300,\n",
    "    layers=4,\n",
    "    batch_size=50_000,\n",
    "    n_updates=100_000,\n",
    "    lr=1e-3,\n",
    "    λ=1.0,\n",
    "    log_every=5_000\n",
    "):\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    model     = BasketNet(len(feature_cols), width, layers).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    train_losses, valid_losses, steps = [], [], []\n",
    "\n",
    "    # infinite iterator for training\n",
    "    def inf_iter(loader):\n",
    "        while True:\n",
    "            for batch in loader:\n",
    "                yield batch\n",
    "    train_iter = inf_iter(train_loader)\n",
    "\n",
    "    model.train()\n",
    "    for step in range(1, n_updates + 1):\n",
    "        Xb, p_true, d_true, v_true = next(train_iter)\n",
    "        Xb = Xb.to(DEVICE).requires_grad_(True)\n",
    "        p_true, d_true, v_true = [t.to(DEVICE) for t in (p_true, d_true, v_true)]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward price\n",
    "        p_pred = model(Xb)\n",
    "        loss_p = criterion(p_pred, p_true)\n",
    "\n",
    "        # compute autograd Greeks (retain graph for Sobolev loss)\n",
    "        grad = torch.autograd.grad(\n",
    "            outputs=p_pred,\n",
    "            inputs=Xb,\n",
    "            grad_outputs=torch.ones_like(p_pred),\n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        # extract predictions\n",
    "        d_pred = grad[:, delta_idx]\n",
    "        v_pred = grad[:, vega_idx]\n",
    "        loss_g = criterion(d_pred, d_true) + criterion(v_pred, v_true)\n",
    "\n",
    "        # total loss\n",
    "        loss = loss_p + λ * loss_g\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # validation & logging\n",
    "        if step == 1 or step % log_every == 0 or step == n_updates:\n",
    "            model.eval()\n",
    "            tot_val, cnt = 0.0, 0\n",
    "            for Xv, pv, dv, vv in val_loader:\n",
    "                Xv = Xv.to(DEVICE).requires_grad_(True)\n",
    "                pv, dv, vv = [t.to(DEVICE) for t in (pv, dv, vv)]\n",
    "\n",
    "                pp = model(Xv)\n",
    "                lp = criterion(pp, pv)\n",
    "\n",
    "                g = torch.autograd.grad(\n",
    "                    outputs=pp,\n",
    "                    inputs=Xv,\n",
    "                    grad_outputs=torch.ones_like(pp),\n",
    "                    create_graph=False\n",
    "                )[0]\n",
    "                lg = criterion(g[:, delta_idx], dv) + criterion(g[:, vega_idx], vv)\n",
    "\n",
    "                tot_val += (lp + λ * lg).item() * Xv.size(0)\n",
    "                cnt     += Xv.size(0)\n",
    "\n",
    "            val_loss = tot_val / cnt\n",
    "            train_losses.append(loss.item())\n",
    "            valid_losses.append(val_loss)\n",
    "            steps.append(step)\n",
    "            print(f\"[upd {step}/{n_updates}] train loss={loss.item():.3e}  val loss={val_loss:.3e}\")\n",
    "            model.train()\n",
    "\n",
    "    # plot training curves\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(steps, np.log10(train_losses), label=\"train\")\n",
    "    plt.plot(steps, np.log10(valid_losses), label=\"valid\")\n",
    "    plt.xlabel(\"update step\")\n",
    "    plt.ylabel(\"log10 loss\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "\n",
    "# 11) Run training\n",
    "model = run_differential(\n",
    "    width=250,\n",
    "    layers=5,\n",
    "    batch_size=5_000,\n",
    "    n_updates=100_000,\n",
    "    lr=1e-3,\n",
    "    λ=1.0,\n",
    "    log_every=5_000\n",
    ")\n",
    "\n",
    "# 12) Test evaluation\n",
    "test_df = pd.read_parquet(\"Test_clean_5k_aad_greeks.parquet\", engine=\"pyarrow\")\n",
    "X_test = torch.from_numpy(test_df[feature_cols].values.astype(np.float32)).to(DEVICE).requires_grad_(True)\n",
    "y_test = test_df[target_cols].values.astype(np.float32)\n",
    "\n",
    "model.eval()\n",
    "# forward pass\n",
    "p_pred_tensor = model(X_test)\n",
    "# compute AAD Greeks\n",
    "grad_test = torch.autograd.grad(\n",
    "    outputs=p_pred_tensor,\n",
    "    inputs=X_test,\n",
    "    grad_outputs=torch.ones_like(p_pred_tensor)\n",
    ")[0]\n",
    "\n",
    "# convert to numpy\n",
    "price_pred = p_pred_tensor.detach().cpu().numpy()\n",
    "delta_pred = grad_test[:, delta_idx].detach().cpu().numpy()\n",
    "vega_pred  = grad_test[:, vega_idx].detach().cpu().numpy()\n",
    "\n",
    "# true targets\n",
    "p_true = y_test[:, 0]\n",
    "d_true = y_test[:, 1:4]\n",
    "v_true = y_test[:, 4:7]\n",
    "\n",
    "# 13) Metrics & plots\n",
    "def report_and_plot(name, pred, true):\n",
    "    mae  = np.mean(np.abs(pred - true))\n",
    "    rmse = np.sqrt(np.mean((pred - true)**2))\n",
    "    r2   = np.corrcoef(pred, true)[0,1]**2\n",
    "    print(f\"{name:>8s}: MAE={mae:.3e}, RMSE={rmse:.3e}, R²={r2:.4f}\")\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(true, pred, s=3, alpha=0.3)\n",
    "    lo, hi = min(true.min(), pred.min()), max(true.max(), pred.max())\n",
    "    plt.plot([lo,hi],[lo,hi],'k--')\n",
    "    plt.title(f\"{name}: MAE={mae:.3e}, RMSE={rmse:.3e}, R²={r2:.4f}\")\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.grid(ls=\":\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nTest set performance:\")\n",
    "report_and_plot(\"Price\", price_pred, p_true)\n",
    "for i in range(3):\n",
    "    report_and_plot(f\"Delta_{i}\", delta_pred[:, i], d_true[:, i])\n",
    "for i in range(3):\n",
    "    report_and_plot(f\"Vega_{i}\", vega_pred[:, i], v_true[:, i])\n",
    "\n",
    "# 14) Save NN predictions for Test and Train (5k) in comparison-ready format\n",
    "pred_cols = [\"price/k\"] + [f\"delta_{i}\" for i in range(3)] + [f\"vega_{i}\" for i in range(3)]\n",
    "\n",
    "def predict_df(df_like: pd.DataFrame, batch_size: int = 100_000) -> pd.DataFrame:\n",
    "    \"\"\"Return a DataFrame with columns ['price/k','delta_0..2','vega_0..2'] for rows in df_like.\"\"\"\n",
    "    model.eval()\n",
    "    outs = []\n",
    "    idxs = []\n",
    "    n = len(df_like)\n",
    "    for i in range(0, n, batch_size):\n",
    "        Xb_np = df_like.iloc[i:i+batch_size][feature_cols].values.astype(np.float32)\n",
    "        Xb = torch.from_numpy(Xb_np).to(DEVICE)\n",
    "        Xb.requires_grad_(True)\n",
    "\n",
    "        pb = model(Xb)  # (B,)\n",
    "        gb = torch.autograd.grad(outputs=pb, inputs=Xb, grad_outputs=torch.ones_like(pb))[0]  # (B, F)\n",
    "\n",
    "        block = np.column_stack([\n",
    "            pb.detach().cpu().numpy(),\n",
    "            gb[:, delta_idx].detach().cpu().numpy(),\n",
    "            gb[:, vega_idx].detach().cpu().numpy()\n",
    "        ])\n",
    "        outs.append(block)\n",
    "        idxs.append(df_like.index[i:i+batch_size])\n",
    "\n",
    "    out = np.vstack(outs) if len(outs) > 1 else outs[0]\n",
    "    pred = pd.DataFrame(out, columns=pred_cols, index=pd.Index(np.concatenate([np.array(ix) for ix in idxs])))\n",
    "    pred = pred.loc[df_like.index]  # preserve original order\n",
    "    return pred\n",
    "\n",
    "# Test predictions saved as Test_clean_5k_NN.parquet\n",
    "test_pred_df = predict_df(test_df)\n",
    "test_pred_df.to_parquet(\"Test_clean_5k_NN.parquet\", engine=\"pyarrow\", index=True)\n",
    "\n",
    "# Train 5k sample predictions saved as Train_clean_5k_NN.parquet\n",
    "train_5k = df.sample(n=5000, random_state=42)\n",
    "train_pred_df = predict_df(train_5k)\n",
    "train_pred_df.to_parquet(\"Train_clean_5k_NN.parquet\", engine=\"pyarrow\", index=True)\n",
    "\n",
    "print(\"Saved: Test_clean_5k_NN.parquet  and  Train_clean_5k_NN.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f769a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74609089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Delta: Model AAD vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.157290</td>\n",
       "      <td>-0.005265</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.110328</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.993985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>-0.152547</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.160013</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.993185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.124199</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.183293</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.993885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806  -0.000707  0.014806 -0.157290 -0.005265 -0.000404  0.004152   \n",
       "delta_1   4806   0.000362  0.016276 -0.152547 -0.004731  0.000044  0.004693   \n",
       "delta_2   4806  -0.000707  0.014941 -0.124199 -0.005217 -0.000312  0.003866   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.110328  0.008789  0.000220  0.014821  0.993985  \n",
       "delta_1  0.160013  0.009169  0.000265  0.016278  0.993185  \n",
       "delta_2  0.183293  0.008755  0.000224  0.014956  0.993885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model AAD vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>-0.157290</td>\n",
       "      <td>-0.005265</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.110327</td>\n",
       "      <td>0.008789</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.993985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.016276</td>\n",
       "      <td>-0.152546</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.160010</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.993185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>-0.124199</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>0.183294</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.993885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806  -0.000707  0.014806 -0.157290 -0.005265 -0.000404  0.004151   \n",
       "delta_1   4806   0.000362  0.016276 -0.152546 -0.004731  0.000044  0.004693   \n",
       "delta_2   4806  -0.000707  0.014941 -0.124199 -0.005217 -0.000312  0.003866   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.110327  0.008789  0.000220  0.014821  0.993985  \n",
       "delta_1  0.160010  0.009169  0.000265  0.016278  0.993185  \n",
       "delta_2  0.183294  0.008755  0.000224  0.014956  0.993885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model AAD vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.009497</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.197933</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.985453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>-0.311557</td>\n",
       "      <td>-0.008432</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.248155</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.982299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>0.024758</td>\n",
       "      <td>-0.297383</td>\n",
       "      <td>-0.009155</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.199936</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.982617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.000123  0.023004 -0.176788 -0.009497  0.000137  0.008973   \n",
       "vega_1   4806   0.000515  0.024158 -0.311557 -0.008432  0.000171  0.009013   \n",
       "vega_2   4806  -0.000697  0.024758 -0.297383 -0.009155 -0.000226  0.008687   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.197933  0.014824  0.000529  0.023002  0.985453  \n",
       "vega_1  0.248155  0.014766  0.000584  0.024161  0.982299  \n",
       "vega_2  0.199936  0.014985  0.000613  0.024765  0.982617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model AAD vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>-0.176788</td>\n",
       "      <td>-0.009497</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.008973</td>\n",
       "      <td>0.197929</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.985453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>-0.311557</td>\n",
       "      <td>-0.008432</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.248155</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.024161</td>\n",
       "      <td>0.982299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>0.024758</td>\n",
       "      <td>-0.297384</td>\n",
       "      <td>-0.009155</td>\n",
       "      <td>-0.000226</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.199935</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.982617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.000123  0.023004 -0.176788 -0.009497  0.000138  0.008973   \n",
       "vega_1   4806   0.000515  0.024158 -0.311557 -0.008432  0.000171  0.009013   \n",
       "vega_2   4806  -0.000697  0.024758 -0.297384 -0.009155 -0.000226  0.008687   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.197929  0.014824  0.000529  0.023002  0.985453  \n",
       "vega_1  0.248155  0.014766  0.000584  0.024161  0.982299  \n",
       "vega_2  0.199935  0.014985  0.000613  0.024765  0.982617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model NN vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.108188</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.999558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>-0.113954</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.109329</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.999140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806   0.000782  0.004059 -0.058500 -0.000192  0.000480  0.001433   \n",
       "delta_1   4806  -0.000553  0.005777 -0.113954 -0.001832 -0.000571  0.000260   \n",
       "delta_2   4806   0.000767  0.003752 -0.045523 -0.000206  0.000585  0.001585   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.108188  0.001932  0.000017  0.004133  0.999558  \n",
       "delta_1  0.109329  0.002547  0.000034  0.005803  0.999140  \n",
       "delta_2  0.061217  0.001995  0.000015  0.003829  0.999615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model NN vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.108188</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.999558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>-0.113954</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.109329</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.999140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-0.045524</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806   0.000782  0.004059 -0.058500 -0.000192  0.000480  0.001433   \n",
       "delta_1   4806  -0.000553  0.005777 -0.113954 -0.001832 -0.000571  0.000260   \n",
       "delta_2   4806   0.000767  0.003752 -0.045524 -0.000205  0.000584  0.001585   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.108188  0.001932  0.000017  0.004133  0.999558  \n",
       "delta_1  0.109329  0.002547  0.000034  0.005803  0.999140  \n",
       "delta_2  0.061217  0.001995  0.000015  0.003829  0.999615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model NN vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.999210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>-0.209940</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.998535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.143590</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.998876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.001093  0.005360 -0.079406 -0.000852  0.000774  0.002787   \n",
       "vega_1   4806   0.000312  0.006909 -0.209940 -0.001675 -0.000168  0.001805   \n",
       "vega_2   4806  -0.000766  0.006298 -0.143590 -0.002406 -0.000534  0.001242   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.115532  0.003029  0.000030  0.005470  0.999210  \n",
       "vega_1  0.162330  0.003273  0.000048  0.006915  0.998535  \n",
       "vega_2  0.071150  0.003396  0.000040  0.006344  0.998876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model NN vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.999210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>-0.209942</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.998535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.143589</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.998876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.001093  0.005360 -0.079406 -0.000852  0.000773  0.002787   \n",
       "vega_1   4806   0.000312  0.006909 -0.209942 -0.001675 -0.000168  0.001805   \n",
       "vega_2   4806  -0.000766  0.006298 -0.143589 -0.002406 -0.000534  0.001242   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.115532  0.003029  0.000030  0.005470  0.999210  \n",
       "vega_1  0.162330  0.003273  0.000048  0.006915  0.998535  \n",
       "vega_2  0.071150  0.003396  0.000040  0.006344  0.998876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ——— load as before ———\n",
    "aad_mc     = pd.read_parquet(\"Test_clean_5k_aad_greeks.parquet\")\n",
    "fd_mc      = pd.read_parquet(\"Test_clean_5k_fd_greeks.parquet\")\n",
    "model_aad  = pd.read_parquet(\"Test_clean_5k_Model+AAD_greeks.parquet\")\n",
    "model_nn   = pd.read_parquet(\"Test_clean_5k_NN.parquet\")   # <-- added NN predictions\n",
    "\n",
    "delta_cols = [f\"delta_{i}\" for i in range(3)]\n",
    "vega_cols  = [f\"vega_{i}\"  for i in range(3)]\n",
    "\n",
    "def enhanced_stats(stored: pd.DataFrame, model: pd.DataFrame, cols):\n",
    "    diffs     = model[cols] - stored[cols]\n",
    "    abs_diffs = diffs.abs()\n",
    "    sq_diffs  = diffs ** 2\n",
    "\n",
    "    stats = pd.DataFrame(index=cols)\n",
    "    stats['count']     = diffs.count().values\n",
    "    stats['mean_diff'] = diffs.mean().values\n",
    "    stats['std_diff']  = diffs.std().values\n",
    "    stats['min_diff']  = diffs.min().values\n",
    "    stats['25%']       = diffs.quantile(0.25).values\n",
    "    stats['50%']       = diffs.median().values\n",
    "    stats['75%']       = diffs.quantile(0.75).values\n",
    "    stats['max_diff']  = diffs.max().values\n",
    "\n",
    "    # additional error metrics\n",
    "    stats['MAE']  = abs_diffs.mean().values\n",
    "    stats['MSE']  = sq_diffs.mean().values\n",
    "    stats['RMSE'] = np.sqrt(stats['MSE'])\n",
    "\n",
    "    # R^2 = (Pearson r)^2\n",
    "    r2_list = []\n",
    "    for col in cols:\n",
    "        r = stored[col].corr(model[col])\n",
    "        r2_list.append(r**2)\n",
    "    stats['R2'] = r2_list\n",
    "\n",
    "    return stats\n",
    "\n",
    "# ——— compute vs Model+AAD (existing) ———\n",
    "delta_aad_vs_mc_aad = enhanced_stats(aad_mc,    model_aad, delta_cols)\n",
    "delta_aad_vs_mc_fd  = enhanced_stats(fd_mc,     model_aad, delta_cols)\n",
    "vega_aad_vs_mc_aad  = enhanced_stats(aad_mc,    model_aad, vega_cols)\n",
    "vega_aad_vs_mc_fd   = enhanced_stats(fd_mc,     model_aad, vega_cols)\n",
    "\n",
    "# ——— compute vs Model NN (added) ———\n",
    "delta_nn_vs_mc_aad = enhanced_stats(aad_mc,    model_nn, delta_cols)\n",
    "delta_nn_vs_mc_fd  = enhanced_stats(fd_mc,     model_nn, delta_cols)\n",
    "vega_nn_vs_mc_aad  = enhanced_stats(aad_mc,    model_nn, vega_cols)\n",
    "vega_nn_vs_mc_fd   = enhanced_stats(fd_mc,     model_nn, vega_cols)\n",
    "\n",
    "# ——— display ———\n",
    "print(\"=== Delta: Model AAD vs MC AAD ===\")\n",
    "display(delta_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model AAD vs MC FD ===\")\n",
    "display(delta_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC AAD ===\")\n",
    "display(vega_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC FD ===\")\n",
    "display(vega_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC AAD ===\")\n",
    "display(delta_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC FD ===\")\n",
    "display(delta_nn_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC AAD ===\")\n",
    "display(vega_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC FD ===\")\n",
    "display(vega_nn_vs_mc_fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e35b98e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No price column found. Tried: price/k, price_norm, price, option_price, y_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m PRICE_COL_AAD  \u001b[38;5;241m=\u001b[39m find_price_col(aad_mc)\n\u001b[0;32m     22\u001b[0m PRICE_COL_FD   \u001b[38;5;241m=\u001b[39m find_price_col(fd_mc)\n\u001b[1;32m---> 23\u001b[0m PRICE_COL_MAAD \u001b[38;5;241m=\u001b[39m \u001b[43mfind_price_col\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_aad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m PRICE_COL_MNN  \u001b[38;5;241m=\u001b[39m find_price_col(model_nn)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menhanced_stats\u001b[39m(stored: pd\u001b[38;5;241m.\u001b[39mDataFrame, model: pd\u001b[38;5;241m.\u001b[39mDataFrame, cols):\n",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m, in \u001b[0;36mfind_price_col\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m c\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo price column found. Tried: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(candidates))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'No price column found. Tried: price/k, price_norm, price, option_price, y_price'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ——— load as before ———\n",
    "aad_mc     = pd.read_parquet(\"Test_clean_5k_aad_greeks.parquet\")\n",
    "fd_mc      = pd.read_parquet(\"Test_clean_5k_fd_greeks.parquet\")\n",
    "model_aad  = pd.read_parquet(\"Test_clean_5k_Model+AAD_greeks.parquet\")\n",
    "model_nn   = pd.read_parquet(\"Test_clean_5k_NN.parquet\")   # <-- added NN predictions\n",
    "\n",
    "delta_cols = [f\"delta_{i}\" for i in range(3)]\n",
    "vega_cols  = [f\"vega_{i}\"  for i in range(3)]\n",
    "\n",
    "# --- helpers ---\n",
    "def find_price_col(df: pd.DataFrame) -> str:\n",
    "    candidates = [\"price/k\", \"price_norm\", \"price\", \"option_price\", \"y_price\"]\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(\"No price column found. Tried: \" + \", \".join(candidates))\n",
    "\n",
    "PRICE_COL_AAD  = find_price_col(aad_mc)\n",
    "PRICE_COL_FD   = find_price_col(fd_mc)\n",
    "PRICE_COL_MAAD = find_price_col(model_aad)\n",
    "PRICE_COL_MNN  = find_price_col(model_nn)\n",
    "\n",
    "def enhanced_stats(stored: pd.DataFrame, model: pd.DataFrame, cols):\n",
    "    \"\"\"General stats for vectors (Greeks or price).\"\"\"\n",
    "    diffs     = model[cols] - stored[cols]\n",
    "    abs_diffs = diffs.abs()\n",
    "    sq_diffs  = diffs ** 2\n",
    "\n",
    "    stats = pd.DataFrame(index=cols)\n",
    "    stats['count']     = diffs.count().values\n",
    "    stats['mean_diff'] = diffs.mean().values\n",
    "    stats['std_diff']  = diffs.std().values\n",
    "    stats['min_diff']  = diffs.min().values\n",
    "    stats['25%']       = diffs.quantile(0.25).values\n",
    "    stats['50%']       = diffs.median().values\n",
    "    stats['75%']       = diffs.quantile(0.75).values\n",
    "    stats['max_diff']  = diffs.max().values\n",
    "\n",
    "    # additional error metrics\n",
    "    stats['MAE']  = abs_diffs.mean().values\n",
    "    stats['MSE']  = sq_diffs.mean().values\n",
    "    stats['RMSE'] = np.sqrt(stats['MSE'])\n",
    "\n",
    "    # R^2 = (Pearson r)^2\n",
    "    r2_list = []\n",
    "    for col in cols:\n",
    "        r = stored[col].corr(model[col])\n",
    "        r2_list.append((0.0 if pd.isna(r) else r**2))\n",
    "    stats['R2'] = r2_list\n",
    "\n",
    "    return stats\n",
    "\n",
    "def price_stats(stored: pd.Series, model: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Price-focused stats including MAPE/sMAPE and bias.\"\"\"\n",
    "    diffs = model - stored\n",
    "    abs_diffs = diffs.abs()\n",
    "    sq_diffs = diffs**2\n",
    "\n",
    "    # Avoid divide-by-zero in MAPE: exclude zeros\n",
    "    nonzero = stored != 0\n",
    "    mape = (abs_diffs[nonzero] / stored[nonzero]).mean() if nonzero.any() else np.nan\n",
    "    mpe  = (diffs[nonzero] / stored[nonzero]).mean() if nonzero.any() else np.nan\n",
    "    # sMAPE: symmetric MAPE (robust when scale varies)\n",
    "    denom = (stored.abs() + model.abs())\n",
    "    smape = (2 * abs_diffs / denom.replace(0, np.nan)).mean()\n",
    "\n",
    "    r = stored.corr(model)\n",
    "    r2 = 0.0 if pd.isna(r) else r**2\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"count\":       [diffs.count()],\n",
    "        \"mean_diff\":   [diffs.mean()],\n",
    "        \"std_diff\":    [diffs.std()],\n",
    "        \"min_diff\":    [diffs.min()],\n",
    "        \"25%\":         [diffs.quantile(0.25)],\n",
    "        \"50%\":         [diffs.median()],\n",
    "        \"75%\":         [diffs.quantile(0.75)],\n",
    "        \"max_diff\":    [diffs.max()],\n",
    "        \"MAE\":         [abs_diffs.mean()],\n",
    "        \"MSE\":         [sq_diffs.mean()],\n",
    "        \"RMSE\":        [np.sqrt(sq_diffs.mean())],\n",
    "        \"MAPE\":        [mape],\n",
    "        \"sMAPE\":       [smape],\n",
    "        \"MPE_bias\":    [mpe],\n",
    "        \"R2\":          [r2],\n",
    "    }, index=[\"price\"])\n",
    "    return out\n",
    "\n",
    "# ——— Greeks vs Model+AAD (existing) ———\n",
    "delta_aad_vs_mc_aad = enhanced_stats(aad_mc,    model_aad, delta_cols)\n",
    "delta_aad_vs_mc_fd  = enhanced_stats(fd_mc,     model_aad, delta_cols)\n",
    "vega_aad_vs_mc_aad  = enhanced_stats(aad_mc,    model_aad, vega_cols)\n",
    "vega_aad_vs_mc_fd   = enhanced_stats(fd_mc,     model_aad, vega_cols)\n",
    "\n",
    "# ——— Greeks vs Model NN (added) ———\n",
    "delta_nn_vs_mc_aad = enhanced_stats(aad_mc,    model_nn, delta_cols)\n",
    "delta_nn_vs_mc_fd  = enhanced_stats(fd_mc,     model_nn, delta_cols)\n",
    "vega_nn_vs_mc_aad  = enhanced_stats(aad_mc,    model_nn, vega_cols)\n",
    "vega_nn_vs_mc_fd   = enhanced_stats(fd_mc,     model_nn, vega_cols)\n",
    "\n",
    "# ——— Price vs Model+AAD ———\n",
    "price_aad_vs_mc_aad = price_stats(aad_mc[PRICE_COL_AAD], model_aad[PRICE_COL_MAAD])\n",
    "price_aad_vs_mc_fd  = price_stats(fd_mc[PRICE_COL_FD],   model_aad[PRICE_COL_MAAD])\n",
    "\n",
    "# ——— Price vs Model NN ———\n",
    "price_nn_vs_mc_aad  = price_stats(aad_mc[PRICE_COL_AAD], model_nn[PRICE_COL_MNN])\n",
    "price_nn_vs_mc_fd   = price_stats(fd_mc[PRICE_COL_FD],   model_nn[PRICE_COL_MNN])\n",
    "\n",
    "# ——— display ———\n",
    "print(\"=== Delta: Model AAD vs MC AAD ===\")\n",
    "display(delta_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model AAD vs MC FD ===\")\n",
    "display(delta_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC AAD ===\")\n",
    "display(vega_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC FD ===\")\n",
    "display(vega_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC AAD ===\")\n",
    "display(delta_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC FD ===\")\n",
    "display(delta_nn_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC AAD ===\")\n",
    "display(vega_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC FD ===\")\n",
    "display(vega_nn_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== PRICE: Model AAD vs MC AAD ===\")\n",
    "display(price_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== PRICE: Model AAD vs MC FD ===\")\n",
    "display(price_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== PRICE: Model NN vs MC AAD ===\")\n",
    "display(price_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== PRICE: Model NN vs MC FD ===\")\n",
    "display(price_nn_vs_mc_fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7f7836",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1274da61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Columns in aad_mc ===\n",
      "['sigma_0', 'sigma_1', 'sigma_2', 'corr_0_1', 'corr_0_2', 'corr_1_2', 'r', 'T', 'S0_0/K', 'S0_1/K', 'S0_2/K', 'price/k', 'delta_0', 'delta_1', 'delta_2', 'vega_0', 'vega_1', 'vega_2'] \n",
      "\n",
      "=== Columns in fd_mc ===\n",
      "['sigma_0', 'sigma_1', 'sigma_2', 'corr_0_1', 'corr_0_2', 'corr_1_2', 'r', 'T', 'S0_0/K', 'S0_1/K', 'S0_2/K', 'price/k', 'delta_0', 'delta_1', 'delta_2', 'vega_0', 'vega_1', 'vega_2'] \n",
      "\n",
      "=== Columns in model_aad ===\n",
      "['delta_0', 'delta_1', 'delta_2', 'vega_0', 'vega_1', 'vega_2', 'price/k'] \n",
      "\n",
      "=== Columns in model_nn ===\n",
      "['price/k', 'delta_0', 'delta_1', 'delta_2', 'vega_0', 'vega_1', 'vega_2'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all the parquet files\n",
    "aad_mc     = pd.read_parquet(\"Test_clean_5k_aad_greeks.parquet\")\n",
    "fd_mc      = pd.read_parquet(\"Test_clean_5k_fd_greeks.parquet\")\n",
    "model_aad  = pd.read_parquet(\"Test_clean_5k_Model+AAD_greeks.parquet\")\n",
    "model_nn   = pd.read_parquet(\"Test_clean_5k_NN.parquet\")\n",
    "\n",
    "# Print column names\n",
    "print(\"=== Columns in aad_mc ===\")\n",
    "print(aad_mc.columns.tolist(), \"\\n\")\n",
    "\n",
    "print(\"=== Columns in fd_mc ===\")\n",
    "print(fd_mc.columns.tolist(), \"\\n\")\n",
    "\n",
    "print(\"=== Columns in model_aad ===\")\n",
    "print(model_aad.columns.tolist(), \"\\n\")\n",
    "\n",
    "print(\"=== Columns in model_nn ===\")\n",
    "print(model_nn.columns.tolist(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7446778c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Delta: Model AAD vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>-0.155182</td>\n",
       "      <td>-0.005033</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.111641</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.993985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.152339</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.161546</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.993185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>-0.122574</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.184779</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.993885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806  -0.000385  0.014825 -0.155182 -0.005033 -0.000296  0.004435   \n",
       "delta_1   4806   0.000685  0.016340 -0.152339 -0.004484  0.000105  0.004890   \n",
       "delta_2   4806  -0.000390  0.014958 -0.122574 -0.004973 -0.000209  0.004159   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.111641  0.008801  0.000220  0.014829  0.993985  \n",
       "delta_1  0.161546  0.009199  0.000267  0.016353  0.993185  \n",
       "delta_2  0.184779  0.008755  0.000224  0.014962  0.993885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model AAD vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>-0.155182</td>\n",
       "      <td>-0.005033</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.111640</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.993985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>-0.152339</td>\n",
       "      <td>-0.004483</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.161543</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.993185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>-0.122574</td>\n",
       "      <td>-0.004973</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.184780</td>\n",
       "      <td>0.008755</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>0.993885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806  -0.000385  0.014825 -0.155182 -0.005033 -0.000297  0.004435   \n",
       "delta_1   4806   0.000685  0.016340 -0.152339 -0.004483  0.000105  0.004890   \n",
       "delta_2   4806  -0.000390  0.014958 -0.122574 -0.004973 -0.000209  0.004159   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.111640  0.008801  0.000220  0.014829  0.993985  \n",
       "delta_1  0.161543  0.009199  0.000267  0.016353  0.993185  \n",
       "delta_2  0.184780  0.008755  0.000224  0.014962  0.993885  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model AAD vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>-0.177189</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.198514</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.985453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>-0.312705</td>\n",
       "      <td>-0.008494</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.249046</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.982299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.296425</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.982617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.000052  0.023025 -0.177189 -0.009515  0.000047  0.008979   \n",
       "vega_1   4806   0.000466  0.024213 -0.312705 -0.008494  0.000133  0.008970   \n",
       "vega_2   4806  -0.000751  0.024789 -0.296425 -0.009284 -0.000253  0.008677   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.198514  0.014845  0.000530  0.023022  0.985453  \n",
       "vega_1  0.249046  0.014796  0.000586  0.024215  0.982299  \n",
       "vega_2  0.200021  0.015019  0.000615  0.024798  0.982617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model AAD vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.023025</td>\n",
       "      <td>-0.177189</td>\n",
       "      <td>-0.009515</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>0.198510</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.985453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>-0.312705</td>\n",
       "      <td>-0.008493</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.249045</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.982299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000750</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>-0.296426</td>\n",
       "      <td>-0.009284</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.015019</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.024798</td>\n",
       "      <td>0.982617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.000052  0.023025 -0.177189 -0.009515  0.000047  0.008979   \n",
       "vega_1   4806   0.000466  0.024213 -0.312705 -0.008493  0.000133  0.008970   \n",
       "vega_2   4806  -0.000750  0.024789 -0.296426 -0.009284 -0.000253  0.008677   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.198510  0.014845  0.000530  0.023022  0.985453  \n",
       "vega_1  0.249045  0.014796  0.000586  0.024215  0.982299  \n",
       "vega_2  0.200021  0.015019  0.000615  0.024798  0.982617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model NN vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.108188</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.999558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>-0.113954</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.109329</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.999140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-0.045523</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806   0.000782  0.004059 -0.058500 -0.000192  0.000480  0.001433   \n",
       "delta_1   4806  -0.000553  0.005777 -0.113954 -0.001832 -0.000571  0.000260   \n",
       "delta_2   4806   0.000767  0.003752 -0.045523 -0.000206  0.000585  0.001585   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.108188  0.001932  0.000017  0.004133  0.999558  \n",
       "delta_1  0.109329  0.002547  0.000034  0.005803  0.999140  \n",
       "delta_2  0.061217  0.001995  0.000015  0.003829  0.999615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta: Model NN vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>delta_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>-0.058500</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.108188</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.999558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>-0.113954</td>\n",
       "      <td>-0.001832</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.109329</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.999140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-0.045524</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "delta_0   4806   0.000782  0.004059 -0.058500 -0.000192  0.000480  0.001433   \n",
       "delta_1   4806  -0.000553  0.005777 -0.113954 -0.001832 -0.000571  0.000260   \n",
       "delta_2   4806   0.000767  0.003752 -0.045524 -0.000205  0.000584  0.001585   \n",
       "\n",
       "         max_diff       MAE       MSE      RMSE        R2  \n",
       "delta_0  0.108188  0.001932  0.000017  0.004133  0.999558  \n",
       "delta_1  0.109329  0.002547  0.000034  0.005803  0.999140  \n",
       "delta_2  0.061217  0.001995  0.000015  0.003829  0.999615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model NN vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.999210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>-0.209940</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.998535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.143590</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.998876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.001093  0.005360 -0.079406 -0.000852  0.000774  0.002787   \n",
       "vega_1   4806   0.000312  0.006909 -0.209940 -0.001675 -0.000168  0.001805   \n",
       "vega_2   4806  -0.000766  0.006298 -0.143590 -0.002406 -0.000534  0.001242   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.115532  0.003029  0.000030  0.005470  0.999210  \n",
       "vega_1  0.162330  0.003273  0.000048  0.006915  0.998535  \n",
       "vega_2  0.071150  0.003396  0.000040  0.006344  0.998876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vega: Model NN vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vega_0</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>-0.079406</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.115532</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.999210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_1</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>-0.209942</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.162330</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.006915</td>\n",
       "      <td>0.998535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vega_2</th>\n",
       "      <td>4806</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>-0.143589</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.000534</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>0.003396</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.006344</td>\n",
       "      <td>0.998876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "vega_0   4806   0.001093  0.005360 -0.079406 -0.000852  0.000773  0.002787   \n",
       "vega_1   4806   0.000312  0.006909 -0.209942 -0.001675 -0.000168  0.001805   \n",
       "vega_2   4806  -0.000766  0.006298 -0.143589 -0.002406 -0.000534  0.001242   \n",
       "\n",
       "        max_diff       MAE       MSE      RMSE        R2  \n",
       "vega_0  0.115532  0.003029  0.000030  0.005470  0.999210  \n",
       "vega_1  0.162330  0.003273  0.000048  0.006915  0.998535  \n",
       "vega_2  0.071150  0.003396  0.000040  0.006344  0.998876  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRICE: Model AAD vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MPE_bias</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price/k</th>\n",
       "      <td>4806</td>\n",
       "      <td>-2.115864e-09</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>3.252345</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>-0.930328</td>\n",
       "      <td>0.999903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count     mean_diff  std_diff  min_diff       25%       50%  \\\n",
       "price/k   4806 -2.115864e-09  0.002282 -0.017784 -0.001099  0.000041   \n",
       "\n",
       "              75%  max_diff       MAE       MSE      RMSE      MAPE    sMAPE  \\\n",
       "price/k  0.001186  0.014469  0.001594  0.000005  0.002282  3.252345  0.06286   \n",
       "\n",
       "         MPE_bias        R2  \n",
       "price/k -0.930328  0.999903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRICE: Model AAD vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MPE_bias</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price/k</th>\n",
       "      <td>4806</td>\n",
       "      <td>-2.115864e-09</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>-0.017784</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>0.001594</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>3.252345</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>-0.930328</td>\n",
       "      <td>0.999903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count     mean_diff  std_diff  min_diff       25%       50%  \\\n",
       "price/k   4806 -2.115864e-09  0.002282 -0.017784 -0.001099  0.000041   \n",
       "\n",
       "              75%  max_diff       MAE       MSE      RMSE      MAPE    sMAPE  \\\n",
       "price/k  0.001186  0.014469  0.001594  0.000005  0.002282  3.252345  0.06286   \n",
       "\n",
       "         MPE_bias        R2  \n",
       "price/k -0.930328  0.999903  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRICE: Model NN vs MC AAD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MPE_bias</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price/k</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>-0.009787</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>7.744963</td>\n",
       "      <td>0.112067</td>\n",
       "      <td>7.744622</td>\n",
       "      <td>0.999901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "price/k   4806   0.004315  0.002367 -0.009787  0.003036  0.004169  0.005366   \n",
       "\n",
       "         max_diff     MAE       MSE      RMSE      MAPE     sMAPE  MPE_bias  \\\n",
       "price/k  0.028609  0.0044  0.000024  0.004921  7.744963  0.112067  7.744622   \n",
       "\n",
       "               R2  \n",
       "price/k  0.999901  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRICE: Model NN vs MC FD ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>std_diff</th>\n",
       "      <th>min_diff</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max_diff</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>MPE_bias</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>price/k</th>\n",
       "      <td>4806</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>-0.009787</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>7.744963</td>\n",
       "      <td>0.112067</td>\n",
       "      <td>7.744622</td>\n",
       "      <td>0.999901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count  mean_diff  std_diff  min_diff       25%       50%       75%  \\\n",
       "price/k   4806   0.004315  0.002367 -0.009787  0.003036  0.004169  0.005366   \n",
       "\n",
       "         max_diff     MAE       MSE      RMSE      MAPE     sMAPE  MPE_bias  \\\n",
       "price/k  0.028609  0.0044  0.000024  0.004921  7.744963  0.112067  7.744622   \n",
       "\n",
       "               R2  \n",
       "price/k  0.999901  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ——— load as before ———\n",
    "aad_mc     = pd.read_parquet(\"Test_clean_5k_aad_greeks.parquet\")\n",
    "fd_mc      = pd.read_parquet(\"Test_clean_5k_fd_greeks.parquet\")\n",
    "model_aad  = pd.read_parquet(\"Test_clean_5k_Model+AAD_greeks.parquet\")\n",
    "model_nn   = pd.read_parquet(\"Test_clean_5k_NN.parquet\")   # <-- added NN predictions\n",
    "\n",
    "delta_cols = [f\"delta_{i}\" for i in range(3)]\n",
    "vega_cols  = [f\"vega_{i}\"  for i in range(3)]\n",
    "price_col  = \"price/k\"   # fixed now\n",
    "\n",
    "# --- helpers ---\n",
    "def enhanced_stats(stored: pd.DataFrame, model: pd.DataFrame, cols):\n",
    "    diffs     = model[cols] - stored[cols]\n",
    "    abs_diffs = diffs.abs()\n",
    "    sq_diffs  = diffs ** 2\n",
    "\n",
    "    stats = pd.DataFrame(index=cols)\n",
    "    stats['count']     = diffs.count().values\n",
    "    stats['mean_diff'] = diffs.mean().values\n",
    "    stats['std_diff']  = diffs.std().values\n",
    "    stats['min_diff']  = diffs.min().values\n",
    "    stats['25%']       = diffs.quantile(0.25).values\n",
    "    stats['50%']       = diffs.median().values\n",
    "    stats['75%']       = diffs.quantile(0.75).values\n",
    "    stats['max_diff']  = diffs.max().values\n",
    "\n",
    "    # additional error metrics\n",
    "    stats['MAE']  = abs_diffs.mean().values\n",
    "    stats['MSE']  = sq_diffs.mean().values\n",
    "    stats['RMSE'] = np.sqrt(stats['MSE'])\n",
    "\n",
    "    # R^2 = (Pearson r)^2\n",
    "    r2_list = []\n",
    "    for col in cols:\n",
    "        r = stored[col].corr(model[col])\n",
    "        r2_list.append((0.0 if pd.isna(r) else r**2))\n",
    "    stats['R2'] = r2_list\n",
    "\n",
    "    return stats\n",
    "\n",
    "def price_stats(stored: pd.Series, model: pd.Series) -> pd.DataFrame:\n",
    "    diffs = model - stored\n",
    "    abs_diffs = diffs.abs()\n",
    "    sq_diffs = diffs**2\n",
    "\n",
    "    # Avoid divide-by-zero in MAPE: exclude zeros\n",
    "    nonzero = stored != 0\n",
    "    mape = (abs_diffs[nonzero] / stored[nonzero]).mean() if nonzero.any() else np.nan\n",
    "    mpe  = (diffs[nonzero] / stored[nonzero]).mean() if nonzero.any() else np.nan\n",
    "    # sMAPE\n",
    "    denom = (stored.abs() + model.abs())\n",
    "    smape = (2 * abs_diffs / denom.replace(0, np.nan)).mean()\n",
    "\n",
    "    r = stored.corr(model)\n",
    "    r2 = 0.0 if pd.isna(r) else r**2\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"count\":       [diffs.count()],\n",
    "        \"mean_diff\":   [diffs.mean()],\n",
    "        \"std_diff\":    [diffs.std()],\n",
    "        \"min_diff\":    [diffs.min()],\n",
    "        \"25%\":         [diffs.quantile(0.25)],\n",
    "        \"50%\":         [diffs.median()],\n",
    "        \"75%\":         [diffs.quantile(0.75)],\n",
    "        \"max_diff\":    [diffs.max()],\n",
    "        \"MAE\":         [abs_diffs.mean()],\n",
    "        \"MSE\":         [sq_diffs.mean()],\n",
    "        \"RMSE\":        [np.sqrt(sq_diffs.mean())],\n",
    "        \"MAPE\":        [mape],\n",
    "        \"sMAPE\":       [smape],\n",
    "        \"MPE_bias\":    [mpe],\n",
    "        \"R2\":          [r2],\n",
    "    }, index=[\"price/k\"])\n",
    "    return out\n",
    "\n",
    "# ——— Greeks vs Model+AAD ———\n",
    "delta_aad_vs_mc_aad = enhanced_stats(aad_mc,    model_aad, delta_cols)\n",
    "delta_aad_vs_mc_fd  = enhanced_stats(fd_mc,     model_aad, delta_cols)\n",
    "vega_aad_vs_mc_aad  = enhanced_stats(aad_mc,    model_aad, vega_cols)\n",
    "vega_aad_vs_mc_fd   = enhanced_stats(fd_mc,     model_aad, vega_cols)\n",
    "\n",
    "# ——— Greeks vs Model NN ———\n",
    "delta_nn_vs_mc_aad = enhanced_stats(aad_mc,    model_nn, delta_cols)\n",
    "delta_nn_vs_mc_fd  = enhanced_stats(fd_mc,     model_nn, delta_cols)\n",
    "vega_nn_vs_mc_aad  = enhanced_stats(aad_mc,    model_nn, vega_cols)\n",
    "vega_nn_vs_mc_fd   = enhanced_stats(fd_mc,     model_nn, vega_cols)\n",
    "\n",
    "# ——— Price vs Model+AAD ———\n",
    "price_aad_vs_mc_aad = price_stats(aad_mc[price_col], model_aad[price_col])\n",
    "price_aad_vs_mc_fd  = price_stats(fd_mc[price_col],   model_aad[price_col])\n",
    "\n",
    "# ——— Price vs Model NN ———\n",
    "price_nn_vs_mc_aad  = price_stats(aad_mc[price_col], model_nn[price_col])\n",
    "price_nn_vs_mc_fd   = price_stats(fd_mc[price_col],   model_nn[price_col])\n",
    "\n",
    "# ——— display ———\n",
    "print(\"=== Delta: Model AAD vs MC AAD ===\")\n",
    "display(delta_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model AAD vs MC FD ===\")\n",
    "display(delta_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC AAD ===\")\n",
    "display(vega_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model AAD vs MC FD ===\")\n",
    "display(vega_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC AAD ===\")\n",
    "display(delta_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Delta: Model NN vs MC FD ===\")\n",
    "display(delta_nn_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC AAD ===\")\n",
    "display(vega_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== Vega: Model NN vs MC FD ===\")\n",
    "display(vega_nn_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== PRICE: Model AAD vs MC AAD ===\")\n",
    "display(price_aad_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== PRICE: Model AAD vs MC FD ===\")\n",
    "display(price_aad_vs_mc_fd)\n",
    "\n",
    "print(\"\\n=== PRICE: Model NN vs MC AAD ===\")\n",
    "display(price_nn_vs_mc_aad)\n",
    "\n",
    "print(\"\\n=== PRICE: Model NN vs MC FD ===\")\n",
    "display(price_nn_vs_mc_fd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
